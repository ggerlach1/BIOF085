% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
]{scrbook}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Alegreya}
  \setmonofont[]{Source Code Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Introduction to Data Science using Python},
  pdfauthor={Abhijit Dasgupta, Ph.D.},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\title{Introduction to Data Science using Python}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{A Hands-On Guide}
\author{Abhijit Dasgupta, Ph.D.}
\date{Last updated: August 07, 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{about-this-guide}{%
\chapter{About this guide}\label{about-this-guide}}

Data science is a broad field that covers data storage, organization, analysis, visualization and reporting. In this guide, we start with a basic primer on the Python language and scientific programming, then progress through the main Python tools for data ingestion, cleaning, manipulation, analyses and presentation. These will primarily consist of the basic usage of the following Python packages:

\begin{itemize}
\tightlist
\item
  \href{https://pandas.pydata.org}{pandas}
\item
  \href{https://www.statsmodels.org}{statsmodels}
\item
  \href{https://scikit-learn.org}{scikit-learn}
\item
  \href{https://matplotlib.org}{matplotlib}
\item
  \href{https://seaborn.pydata.org}{seaborn}
\end{itemize}

In my mind this forms the core packages in Python for data analyses and data science work that is applicable to a wide variety of domains.

There are obvious topics that I am not covering here:

\begin{itemize}
\tightlist
\item
  Natural language processing (\texttt{nltk})
\item
  Deep neural networks (\texttt{tensorflow}, \texttt{keras}, \texttt{PyTorch})
\item
  Image analysis (\texttt{scikit-image}, \texttt{pillow})
\end{itemize}

To my mind these are intermediate to advanced topics, though they are widely used, and so not as foundational to understanding how to use Python for Data Science.

\hypertarget{how-to-use-this-manual}{%
\subsubsection*{How to use this manual}\label{how-to-use-this-manual}}
\addcontentsline{toc}{subsubsection}{How to use this manual}

This manual was originally developed to support a 3 day workshop on using Python for Data Science. Each chapter was covered over roughly half a day, using live coding through the examples.

\begin{itemize}
\tightlist
\item
  \textbf{Day 1: } Chapters 2, 3, 4
\item
  \textbf{Day 2: } Chapters 5, 6
\item
  \textbf{Day 3: } Chapters 7, 8, 9
\end{itemize}

Each chapter has a fair bit of didactic content describing
the methodology underlying the code, to help understand the
context for the code. Several datasets were used, which are
available in the \href{https://www.github.com/araastat/BIOF085.git}{Github repository} for the workshop. Since the workshop, I have discovered that many
of the data sets are available online through the Rdatasets package, and so could be loaded directly using \texttt{statsmodels}; the examples will slowly be modified accordingly.

Each chapter of this manual is also available as a Jupyter
notebook that can be run on your computer or on Binder, to
allow you to run and modify the code that is presented. These
notebooks are also available at the Github repository.

\hypertarget{license}{%
\section{License}\label{license}}

This work is licensed under a Creative Commons Attribution 4.0 International License. The code samples in this manual are licensed under the \href{https://mit-license.org}{MIT License}

\hypertarget{a-python-primer}{%
\chapter{A Python Primer}\label{a-python-primer}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Python is a popular, general purpose scripting language. The \href{https://www.tiobe.com/tiobe-index/}{TIOBE index} ranks Python as the third most popular programming language after C and Java, while this recent article in IEEE Computer Society says

\begin{quote}
``Python can be used for web and desktop applications, GUI-based desktop applications, machine learning, data science, and network servers. The programming language enjoys immense community support and offers several open-source libraries, frameworks, and modules that make application development a cakewalk.'' (\href{https://www.computer.org/publications/tech-news/trends/programming-languages-you-should-learn-in-2020}{Belani, 2020})
\end{quote}

\hypertarget{python-is-a-modular-language}{%
\subsection{Python is a modular language}\label{python-is-a-modular-language}}

Python is not a monolithic language but is comprised of a base programming language and numerous modules or libraries that add functionality to the language. Several of these libraries are installed with Python. The Anaconda Python Distribution adds more libraries that are useful for data science. Some libraries we will use include \texttt{numpy}, \texttt{pandas}, \texttt{seaborn}, \texttt{statsmodels} and \texttt{scikit-learn}. In the course of this workshop we will learn how to use Python libraries in your workflow.

\hypertarget{python-is-a-scripting-language}{%
\subsection{Python is a scripting language}\label{python-is-a-scripting-language}}

Using Python requires typing!! You write \emph{code} in Python that is then interpreted by the Python interpreter to make the computer implement your instructions. \textbf{Your code is like a recipe that you write for the computer}. Python is a \emph{high-level language} in that the code is English-like and human-readable and understandable, which reduces the time needed for a person to create the recipe. It is a language in that it has nouns (\emph{variables} or \emph{objects}), verbs (\emph{functions}) and a structure or grammar that allows the programmer to write recipes for different functionalities.

One thing that is important to note in Python: \textbf{case is important!}. If we have two objects named \texttt{data} and \texttt{Data}, they will refer to different things.

Scripting can be frustrating in the beginning. You will find that the code you wrote doesn't work ``for some reason'', though it looks like you wrote it fine. The first things I look for, in order, are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Did I spell all the variables and functions correctly
\item
  Did I close all the brackets I have opened
\item
  Did I finish all the quotes I started, and paired single- and double-quotes
\item
  Did I already import the right module for the function I'm trying to use.
\end{enumerate}

These may not make sense right now, but as we go into Python, I hope you will remember these to help debug your code.

\hypertarget{an-example}{%
\section{An example}\label{an-example}}

Let's consider the following piece of Python code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# set a splitting point}
\NormalTok{split_point }\OperatorTok{=} \DecValTok{3}

\CommentTok{# make two empty lists}
\NormalTok{lower }\OperatorTok{=}\NormalTok{ []}\OperatorTok{;}\NormalTok{ upper }\OperatorTok{=}\NormalTok{ []}

\CommentTok{# Split numbers from 0 to 9 into two groups, }
\CommentTok{# one lower or equal to the split point and }
\CommentTok{# one higher than the split point}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):  }\CommentTok{# count from 0 to 9}
    \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{<=}\NormalTok{ split_point:}
\NormalTok{        lower.append(i)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        upper.append(i)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"lower:"}\NormalTok{, lower)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
lower: [0, 1, 2, 3]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"upper:"}\NormalTok{, upper)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
upper: [4, 5, 6, 7, 8, 9]
\end{verbatim}

First note that any line (or part of a line) starting with \texttt{\#} is a \textbf{comment} in Python and is ignored by the interpreter. This makes it possible for us to write substantial text to remind us what each piece of our code does

The first piece of code that the Python interpreter actually reads is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split_point }\OperatorTok{=} \DecValTok{3}
\end{Highlighting}
\end{Shaded}

This takes the number 3 and stores it in the \textbf{variable} \texttt{split\_point}. Variables are just names where some Python object is stored. It really works as an address to some particular part of your computer's memory, telling the Python interpreter to look for the value stored at that particular part of memory. Variable names allow your code to be human-readable since it allows you to write expressive names to remind yourself what you are storing. The rules of variable names are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Variable names must start with a letter or underscore
\item
  The rest of the name can have letters, numbers or underscores
\item
  Names are case-sensitive
\end{enumerate}

The next piece of code initializes two \textbf{lists}, named \texttt{lower} and \texttt{upper}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OperatorTok{=}\NormalTok{ []}\OperatorTok{;}\NormalTok{ upper }\OperatorTok{=}\NormalTok{ []}
\end{Highlighting}
\end{Shaded}

The semi-colon tells Python that, even though written on the same line, a particular instruction ends at the semi-colon, then another piece of instruction is written.

Lists are a catch-all data structure that can store different kinds of things, In this case we'll use them to store numbers.

The next piece of code is a \textbf{for-loop} or a loop structure in Python.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):  }\CommentTok{# count from 0 to 9}
    \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{<=}\NormalTok{ split_point:}
\NormalTok{        lower.append(i)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        upper.append(i)}
\end{Highlighting}
\end{Shaded}

It basically works like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  State with the numbers 0-9 (this is achieved in \texttt{range(10)})
\item
  Loop through each number, naming it \texttt{i} each time

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Computer programs allow you to over-write a variable with a new value
  \end{enumerate}
\item
  If the number currently stored in \texttt{i} is less than or equal to the value of \texttt{split\_point}, i.e., 3 then add it to the list \texttt{lower}. Otherwise add it to the list \texttt{upper}
\end{enumerate}

Note the indentation in the code. \textbf{This is not by accident}. Python understands the extent of a particular block of code within a for-loop (or within a \texttt{if} statement) using the indentations. In this segment there are 3 code blocks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The for-loop as a whole (1st indentation)
\item
  The \texttt{if} statement testing if the number is less than or equal to the split point, telling Python what to do if the test is true
\item
  The \texttt{else} statement stating what to do if the test in the \texttt{if} statement is false
\end{enumerate}

Every time a code block starts, the previous line ends in a colon (:). The code block ends when the indentation ends. We'll go into these elements in a bit.

The last bit of code prints out the results

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"lower:"}\NormalTok{, lower)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
lower: [0, 1, 2, 3]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"upper:"}\NormalTok{, upper)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
upper: [4, 5, 6, 7, 8, 9]
\end{verbatim}

The \texttt{print} statement adds some text, and then prints out a representation of the object stored in the variable being printed. In this example, this is a list, and is printed as

\begin{verbatim}
lower: [0, 1, 2, 3]
upper: [4, 5, 6, 7, 8, 9]
\end{verbatim}

We will expand on these concepts in the next few sections.

\hypertarget{some-general-rules-on-python-syntax}{%
\subsection{Some general rules on Python syntax}\label{some-general-rules-on-python-syntax}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Comments are marked by \texttt{\#}
\item
  A statement is terminated by the end of a line, or by a \texttt{;}.
\item
  Indentation specifies blocks of code within particular structures. Whitespace at the beginning of lines matters. Typically you want to have 2 or 4 spaces to specify indentation, not a tab (\t) character. This can be set up in your IDE.
\item
  Whitespace within lines does not matter, so you can use spaces liberally to make your code more readable
\item
  Parentheses (\texttt{()}) are for grouping pieces of code or for calling functions.
\end{enumerate}

There are several conventions about code styling including the one in \href{https://www.python.org/dev/peps/pep-0008/\#function-and-variable-names}{PEP8} (PEP = Python Enhancement Proposal) and one proposed by \href{https://google.github.io/styleguide/pyguide.html\#316-naming}{Google}. We will typically be using lower case names, with words separated by underscores, in this workshop, basically following PEP8. Other conventions are of course allowed as long as they are within the basic rules stated above.

\hypertarget{data-types-in-python}{%
\section{Data types in Python}\label{data-types-in-python}}

We start with objects in Python. Objects can be of different types, including numbers (integers and floats), strings, arrays (vectors and matrices) and others. Any object can be assigned to a name, so that we can refer to the object in our code. We'll start with the basic types of objects.

\hypertarget{numeric-variables}{%
\subsection{Numeric variables}\label{numeric-variables}}

The following is a line of Python code, where we assign the value 1.2 to the variable \texttt{a}.

\begin{quote}
The act of assigning a name is done using the \texttt{=} sign. This is not equality in the mathematical sense, and has some non-mathematical behavior, as we'll see
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \FloatTok{1.2}
\end{Highlighting}
\end{Shaded}

This is an example of a \emph{floating-point number} or a decimal number, which in Python is called a \texttt{float}. We can verify this in Python itself.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'float'>
\end{verbatim}

Floating point numbers can be entered either as decimals or in scientific notation

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \FloatTok{0.0005}
\NormalTok{y }\OperatorTok{=} \FloatTok{5e-4} \CommentTok{# 5 x 10^(-4)}
\BuiltInTok{print}\NormalTok{(x }\OperatorTok{==}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
True
\end{verbatim}

You can also store integers in a variable. Integers are of course numbers, but can be stored more efficiently on your computer. They are stored as an \emph{integer} type, called \texttt{int}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=} \DecValTok{23}
\BuiltInTok{type}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'int'>
\end{verbatim}

These are the two primary numerical data types in Python. There are some others that we don't use as often, called \texttt{long} (for \emph{long integers}) and \texttt{complex} (for \emph{complex numbers})

\hypertarget{operations-on-numbers}{%
\subsubsection{Operations on numbers}\label{operations-on-numbers}}

There is an arithmetic and logic available to operate on elemental data types. For example, we do have addition, subtraction , multiplication and division available. For example, for numbers, we can do the following:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x + y & The sum of x and y\tabularnewline
x - y & The difference of x and y\tabularnewline
x * y & The product of x and y\tabularnewline
x / y & The quotient of x and y\tabularnewline
- x & The negative of x\tabularnewline
abs(x) & The absolute value of x\tabularnewline
x ** y & x raised to the power y\tabularnewline
int(x) & Convert a number to integer\tabularnewline
float(x) & Convert a number to floating point\tabularnewline
\bottomrule
\end{longtable}

Let's see some examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \DecValTok{5}
\NormalTok{y }\OperatorTok{=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{+}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{-}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{*}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{/}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{**}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
25
\end{verbatim}

\hypertarget{strings}{%
\subsection{Strings}\label{strings}}

Strings are how text is represented within Python. It is always represented as a quoted object using either single (\texttt{\textquotesingle{}\textquotesingle{}}) or double (\texttt{""}) quotes, as long as the types of quotes are matched. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first_name }\OperatorTok{=} \StringTok{"Abhijit"}
\NormalTok{last_name }\OperatorTok{=} \StringTok{"Dasgupta"}
\end{Highlighting}
\end{Shaded}

The data type that these are stored in is \texttt{str}.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(first_name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'str'>
\end{verbatim}

\hypertarget{operations}{%
\subsubsection{Operations}\label{operations}}

Strings also have some ``arithmetic'' associated with it, which involves, essentially, concatenation and repetition. Let's start by considering two character variables that we've initialized.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \StringTok{"a"}
\NormalTok{b }\OperatorTok{=} \StringTok{"b"}
\end{Highlighting}
\end{Shaded}

Then we get the following operations and results

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
a + b & `ab'\tabularnewline
a * 5 & `aaaaa'\tabularnewline
\bottomrule
\end{longtable}

We can also see if a particular character or character string is part of an exemplar string

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{last_name }\OperatorTok{=} \StringTok{"Dasgupta"}
\CommentTok{"gup"} \KeywordTok{in}\NormalTok{ last_name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
True
\end{verbatim}

String manipulation is one of the strong suites of Python.
There are several \emph{functions} that apply to strings, that we will look at throughout the workshop, and especially when we look at string manipulation. In particular, there are built-in functions in base Python and powerful \emph{regular expression} capabilities in the \texttt{re} module.

\hypertarget{truthiness}{%
\subsection{Truthiness}\label{truthiness}}

Truthiness means evaluating the truth of a statement. This typically results in a Boolean object, which can take values \texttt{True} and \texttt{False}, but Python has several equivalent representations. The following values are considered the same as False:

\begin{quote}
\texttt{None}, \texttt{False}, zero (\texttt{0}, \texttt{0L}, \texttt{0.0}), any empty sequence (\texttt{{[}{]}}, \texttt{\textquotesingle{}\textquotesingle{}}, \texttt{()}), and a few others
\end{quote}

All other values are considered True. Usually we'll denote truth by \texttt{True} and the number \texttt{1}.

\hypertarget{operations-1}{%
\subsubsection{Operations}\label{operations-1}}

We will typically test for the truth of some comparisons. For example, if we have two numbers stored in \texttt{x} and \texttt{y}, then we can perform the following comparisons

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x \textless{} y & x is strictly less than y\tabularnewline
x \textless= y & x is less than or equal to y\tabularnewline
x == y & x equals y (note, it's 2 = signs)\tabularnewline
x != y & x is not equal to y\tabularnewline
x \textgreater{} y & x is strictly greater than y\tabularnewline
x \textgreater= y & x is greater or equal to y\tabularnewline
\bottomrule
\end{longtable}

We can chain these comparisons using Boolean operations

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x \textbar{} y & Either x is true or y is true or both\tabularnewline
x \& y & Both x and y are true\tabularnewline
not x & if x is true, then false, and vice versa\tabularnewline
\bottomrule
\end{longtable}

For example, if we have a number stored in \texttt{x}, and want to find out if it is between 3 and 7, we could write

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(x }\OperatorTok{>=} \DecValTok{3}\NormalTok{) }\OperatorTok{&}\NormalTok{ (x }\OperatorTok{<=} \DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
True
\end{verbatim}

\hypertarget{a-note-about-variables-and-types}{%
\subsubsection{A note about variables and types}\label{a-note-about-variables-and-types}}

Some computer languages like C, C++ and Java require you to specify the type of data that will be held in a particular variable. For example,

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ x = }\DecValTok{4}\NormalTok{;}
\DataTypeTok{float}\NormalTok{ y = }\FloatTok{3.25}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

If you try later in the program to assign something of a different type to that variable, you will raise an error. For example, if I did, later in the program, \texttt{x\ =\ 3.95;}, that would be an error in C.

Python is \textbf{dynamically typed}, in that the same variable name can be assigned to different data types in different parts of the program, and the variable will simply be ``overwritten''. (This is not quite correct. What actually happens is that the variable name now ``points'' to a different part of the computer's memory where the new data is then stored in appropriate format). So the following is completely fine in Python:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \DecValTok{4}  \CommentTok{# An int}
\NormalTok{x }\OperatorTok{=} \FloatTok{3.5}  \CommentTok{# A float}
\NormalTok{x }\OperatorTok{=} \StringTok{"That's my mother"}  \CommentTok{# A str}
\NormalTok{x }\OperatorTok{=} \VariableTok{True}  \CommentTok{# A bool}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Variables are like individual ingredients in your recipe. It's \emph{mis en place} or setting the table for any operations (\emph{functions}) we want to do to them. In a language context, variables are like \emph{nouns}, which will be acted on by verbs (\emph{functions}). In the next section we'll look at collections of variables. These collections are important in that it allows us to organize our variables with some structure.
\end{quote}

\hypertarget{data-structures-in-python}{%
\section{Data structures in Python}\label{data-structures-in-python}}

Python has several in-built data structures. We'll describe the three most used ones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lists (\texttt{{[}{]}})
\item
  Tuples (\texttt{()})
\item
  Dictionaries or dicts (\texttt{\{\}})
\end{enumerate}

Note that there are three different kinds of brackets being used.

Lists are baskets that can contain different kinds of things. They are ordered, so that there is a first element, and a second element, and a last element, in order. However, the \emph{kinds} of things in a single list doesn't have to be the same type.

Tuples are basically like lists, except that they are \emph{immutable}, i.e., once they are created, individual values can't be changed. They are also ordered, so there is a first element, a second element and so on.

Dictionaries are \textbf{unordered} key-value pairs, which are very fast for looking up things. They work almost like hash tables. Dictionaries will be very useful to us as we progress towards the PyData stack. Elements need to be referred to by \emph{key}, not by position.

\hypertarget{lists}{%
\subsection{Lists}\label{lists}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list }\OperatorTok{=}\NormalTok{ [}\StringTok{"apple"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\VariableTok{True}\NormalTok{, }\StringTok{"Harvey"}\NormalTok{, }\DecValTok{48205}\NormalTok{]}
\NormalTok{test_list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['apple', 3, True, 'Harvey', 48205]
\end{verbatim}

There are various operations we can do on lists. First, we can determine the length (or size) of the list

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(test_list)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
5
\end{verbatim}

The list is a catch-all, but we're usually interested in extracting elements from the list. This can be done by \emph{position}, since lists are \emph{ordered}. We can extract the 1\textsuperscript{st} element of the list using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'apple'
\end{verbatim}

\begin{quote}
Wait!! The index is 0?

Yup. Python is based deep underneath on the C language, where counting starts at 0. So the first element has index 0, second has index 1, and so on. So you need to be careful if you're used to counting from 1, or, if you're used to R, which does start counting at 1.
\end{quote}

We can also extract a set of consecutive elements from a list, which is often convenient. The typical form is to write the index as \texttt{a:b}. The (somewhat confusing) rule is that \texttt{a:b} means that you start at index \texttt{a}, but continue until \textbf{before index \texttt{b}}. So the notation \texttt{2:5} means include elements with index 2, 3, and 4. In the Python world, this is called \textbf{slicing}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\DecValTok{2}\NormalTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[True, 'Harvey', 48205]
\end{verbatim}

If you want to start at the beginning or go to the end, there is a shortcut notation. The same rule holds, though. \texttt{:3} does \textbf{not} include the element at index 3, but \texttt{2:} \textbf{does} include the element at index 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['apple', 3, True]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\DecValTok{2}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[True, 'Harvey', 48205]
\end{verbatim}

The important thing here is if you provide an index \texttt{a:b}, then \texttt{a} is include but \texttt{b} \textbf{is not}.

You can also count \textbf{backwards} from the end. The last element in a Python list has index \texttt{-1}.

\begin{longtable}[]{@{}llllll@{}}
\toprule
\endhead
index & 0 & 1 & 2 & 3 & 4\tabularnewline
element & `apple' & 3 & True & `Harvey' & 48205\tabularnewline
counting backwards & -5 & -4 & -3 & -2 & -1\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
48205
\end{verbatim}

You can also use negative indices to denote sequences within the list, with the same indexing rule applying. Note that you count from the last element (-1) and go backwards.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[:}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['apple', 3, True, 'Harvey']
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\OperatorTok{-}\DecValTok{3}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[True, 'Harvey', 48205]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\OperatorTok{-}\DecValTok{3}\NormalTok{:}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[True, 'Harvey']
\end{verbatim}

You can also make a list of lists, or nested lists

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_nested_list }\OperatorTok{=}\NormalTok{ [[}\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{], [}\DecValTok{3}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\DecValTok{4}\NormalTok{, }\StringTok{"d"}\NormalTok{]]}
\NormalTok{test_nested_list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[[1, 'a', 2, 'b'], [3, 'c', 4, 'd']]
\end{verbatim}

This will come in useful when we talk about arrays and data frames.

You can also check if something is in the list, i.e.~is a member.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{"Harvey"} \KeywordTok{in}\NormalTok{ test_list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
True
\end{verbatim}

\begin{quote}
Lists have the following properties

\begin{itemize}
\tightlist
\item
  They can be heterogenous (each element can be a different type)
\item
  Lists can hold complex objects (lists, dicts, other objects) in addition to atomic objects (single numbers or words)
\item
  List have an ordering, so you can access list elements by position
\item
  List access can be done counting from the beginning or the end, and consecutive elements can be extracted using slices.
\end{itemize}
\end{quote}

\hypertarget{tuples}{%
\subsection{Tuples}\label{tuples}}

Tuples are like lists, except that once you create them, you can't change them.
This is why tuples are great if you want to store fixed parameters or entities
within your Python code, since they can't be over-written even by mistake. You
can extract elements of a tuple, but you can't over-write them. This is called
\emph{immutable}.

Note that, like lists, tuples can be heterogenous, which is also useful for coding purposes, as we will see.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_tuple }\OperatorTok{=}\NormalTok{ (}\StringTok{"apple"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\VariableTok{True}\NormalTok{, }\StringTok{"Harvey"}\NormalTok{, }\DecValTok{48205}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_tuple[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
('apple', 3, True)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list[}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \StringTok{"pear"}
\NormalTok{test_list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['pear', 3, True, 'Harvey', 48205]
\end{verbatim}

See what happens in the next bit of code

\begin{verbatim}
test_tuple[0] = "pear"
test_tuple
\end{verbatim}

(I'm not running this since it gives an error)

\begin{quote}
Tuples are like lists, but once created, they cannot be changed. They are ordered and can be sliced.
\end{quote}

\hypertarget{dictionaries}{%
\subsection{Dictionaries}\label{dictionaries}}

Dictionaries, or \texttt{dict}, are collections of key-value pairs. Each element is referred to by \emph{key}, not by \emph{index}. In a dictionary, the keys can be strings, numbers or tuples, but the values can be any Python object. So you could have a dictionary where one value is a string, another is a number and a third is a DataFrame (essentially a data set, using the pandas library). A simple example might be an entry in a list of contacts

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"first_name"}\NormalTok{: }\StringTok{"Abhijit"}\NormalTok{,}
    \StringTok{"last_name"}\NormalTok{: }\StringTok{"Dasgupta"}\NormalTok{,}
    \StringTok{"Age"}\NormalTok{: }\DecValTok{48}\NormalTok{,}
    \StringTok{"address"}\NormalTok{: }\StringTok{"124 Main St"}\NormalTok{,}
    \StringTok{"Employed"}\NormalTok{: }\VariableTok{True}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note the special syntax. You separate the key-value pairs by colons (\texttt{:}), and each key-value pair is separated by commas. If you get a syntax error creating a dict, look at these first.

If you try to get the first name out using an index, you run into an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 0

Detailed traceback: 
  File "<string>", line 1, in <module>
\end{verbatim}

You need to extract it by key

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\StringTok{"first_name"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'Abhijit'
\end{verbatim}

A dictionary is mutable, so you can change the value of any particular element

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\StringTok{"address"}\NormalTok{] }\OperatorTok{=} \StringTok{"123 Main St"}
\NormalTok{contact[}\StringTok{"Employed"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{contact}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'first_name': 'Abhijit', 'last_name': 'Dasgupta', 'Age': 48, 'address': '123 Main St', 'Employed': False}
\end{verbatim}

You can see all the keys and values in a dictionary using extractor functions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact.keys()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
dict_keys(['first_name', 'last_name', 'Age', 'address', 'Employed'])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact.values()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
dict_values(['Abhijit', 'Dasgupta', 48, '123 Main St', False])
\end{verbatim}

It turns out that dictionaries are really fast in terms of retrieving information, without having to count where an element it. So it is quite useful

We'll see that dictionaries are also one way to easily create pandas DataFrame objects on the fly.

There are a couple of other ways to create dict objects. One is using a list of tuples. Each key-value pair is represented by a tuple of length 2, where the 1st element is the key and the second element is the value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ [(}\StringTok{'first_name'}\NormalTok{,}\StringTok{'Abhijit'}\NormalTok{),(}\StringTok{'last_name'}\NormalTok{,}\StringTok{'Dasgupta'}\NormalTok{),(}\StringTok{'address'}\NormalTok{, }\StringTok{'124 Main St'}\NormalTok{)]}
\BuiltInTok{dict}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'first_name': 'Abhijit', 'last_name': 'Dasgupta', 'address': '124 Main St'}
\end{verbatim}

This actually can be utilized to create a dict from a pair of lists. There is a really neat function, \texttt{zip}, that inputs several lists of the same length and creates a list of tuples, where the i-th element of each tuple comes from the i-th list, in order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ [}\StringTok{'first_name'}\NormalTok{, }\StringTok{'last_name'}\NormalTok{,}\StringTok{'address'}\NormalTok{]}
\NormalTok{B }\OperatorTok{=}\NormalTok{ [}\StringTok{'Abhijit'}\NormalTok{,}\StringTok{'Dasgupta'}\NormalTok{,}\StringTok{'124 Main St'}\NormalTok{]}
\BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(A, B))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'first_name': 'Abhijit', 'last_name': 'Dasgupta', 'address': '124 Main St'}
\end{verbatim}

\begin{quote}
The \texttt{zip} function is quite powerful in putting several lists together with corresponding elements of each list into a tuple
\end{quote}

On a side note, there is a function \texttt{defaultdict} from the \texttt{collections} module that is probably better to use. We'll come back to it when we talk about modules.

\hypertarget{operational-structures-in-python}{%
\section{Operational structures in Python}\label{operational-structures-in-python}}

\hypertarget{loops-and-list-comprehensions}{%
\subsection{Loops and list comprehensions}\label{loops-and-list-comprehensions}}

Loops are a basic construct in computer programming. The basic idea is that you have a recipe that you want to repeatedly run on different entities that you have created. The crude option would be to copy and paste your code several times, changing whatever inputs change across the entities. This is not only error-prone, but inefficient given that loops are a standard element of all programming languages.

You can create a list of these entities, and, using a loop, run your recipe on each entity automatically. For example, you have a data about votes in the presidential election from all 50 states, and you want to figure out what the percent voting for each major party is. So you could write this recipe in pseudocode as

\begin{verbatim}
Start with a list of datasets, one for each state
for each state
    compute and store fraction of votes that are Republican
    compute and store fraction of votes that are Democratic
\end{verbatim}

This is just English, but it can be translated easily into actual code. We'll attempt that at the end of this section.

The basic idea of a list is that there is a list of things you want to iterate over. You create a dummy variable as stand-in for each element of that list. Then you create a for-loop. This works like a conveyor belt and basket, so to speak. You line up elements of the list on the conveyor belt, and as you run the loop, one element of the list is ``scooped up'' and processed. Once that processing is done, the next element is ``scooped up'', and so forth. The dummy variable is essentially the basket (so the same basket (variable name) is re-used over and over until the conveyor belt (list) is empty).

In the examples below, we are showing a common use of for loops where we are enumerating the elements of a list as 0, 1, 2, \ldots{} using \texttt{range(len(test\_list))}. So the dummy variable \texttt{i} takes values 0, 1, 2, \ldots{} until the length of the list is reached. For each value of \texttt{i}, this for loop prints the i-th element of \texttt{test\_list}.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(test_list)):}
    \BuiltInTok{print}\NormalTok{(test_list[i])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
pear
3
True
Harvey
48205
\end{verbatim}

Sometimes using the index number is easier to understand. However, we don't need to do this. We can just send the list itself into the for-loop (\texttt{u}) now is the dummy variable containing the actual element of \texttt{test\_list}. We'll get the same answer.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test_list:}
    \BuiltInTok{print}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
pear
3
True
Harvey
48205
\end{verbatim}

\begin{quote}
The general structure for a \texttt{for} loop is:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (element) }\KeywordTok{in}\NormalTok{ (}\BuiltInTok{list}\NormalTok{):}
\NormalTok{   	do some stuff}
\NormalTok{   	do more stuff}
\end{Highlighting}
\end{Shaded}
\end{quote}

As a more practical example, let's try and sum a set of numbers using a for-loop (we'll see much better ways of doing this later)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_list2 }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{]}
\NormalTok{mysum }\OperatorTok{=} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test_list2:}
\NormalTok{    mysum }\OperatorTok{=}\NormalTok{ mysum }\OperatorTok{+}\NormalTok{ u}
\BuiltInTok{print}\NormalTok{(mysum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
55
\end{verbatim}

\begin{quote}
There are two things to note here.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The code \texttt{mysum\ =\ mysum\ +\ u} is perfectly valid, once you realize that this isn't really math but an assignment or pointer to a location in memory. This code says that you find the current value stored in \texttt{mysum}, add the value of \texttt{u} to it, and then store it back into the storage that \texttt{mysum} points to
\item
  Indentation matters! Indent the last line and see what happens when you run this code
\end{enumerate}
\end{quote}

\hypertarget{a-little-deeper}{%
\subsubsection{A little deeper}\label{a-little-deeper}}

The entity to the right of the \texttt{in} in the for-loop can be an \textbf{iterator}, which is a generalization of a list. For example, we used \texttt{range(len(test\_list2))} above. If we just type

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
range(0, 10)
\end{verbatim}

nothing really happens. This is an example of an iterator, which is only evaluated when it is called, rather than being stored in memory. This is useful especially when you iterate over large numbers of things, in terms of preserving memory and speed. To see the corresponding list, you would do

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
\end{verbatim}

This \texttt{range} iterator is quite flexible:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{))  }\CommentTok{# range from 5 to 10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[5, 6, 7, 8, 9]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{# range from 0 to 10 by 2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[0, 2, 4, 6, 8]
\end{verbatim}

Note the rules here are very much like the slicing rules.

Other iterators that are often useful are the \texttt{enumerate} iterator and the \texttt{zip} iterator.

\texttt{enumerate} automatically creates both the index and the value for each element of a list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ i, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(L):}
    \BuiltInTok{print}\NormalTok{(i, val)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0 0
1 2
2 4
3 6
4 8
\end{verbatim}

\texttt{zip} puts multiple lists together and creates a composite iterator. You can have any number of iterators in zip, and the length of the result is determined by the length of the shortest iterator. We introduced an example of \texttt{zip} as a way to create a \texttt{dict}.

\begin{quote}
Technically, \texttt{zip} can take multiple \emph{iterators} as inputs, not just lists
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first }\OperatorTok{=}\NormalTok{ [}\StringTok{"Han"}\NormalTok{, }\StringTok{"Luke"}\NormalTok{, }\StringTok{"Leia"}\NormalTok{, }\StringTok{"Anakin"}\NormalTok{]}
\NormalTok{last }\OperatorTok{=}\NormalTok{ [}\StringTok{"Solo"}\NormalTok{, }\StringTok{"Skywalker"}\NormalTok{, }\StringTok{"Skywaker"}\NormalTok{, }\StringTok{"Skywalker"}\NormalTok{]}
\NormalTok{types }\OperatorTok{=}\NormalTok{ [}\StringTok{'light'}\NormalTok{,}\StringTok{'light'}\NormalTok{,}\StringTok{'light'}\NormalTok{,}\StringTok{'light/dark/light'}\NormalTok{]}

\ControlFlowTok{for}\NormalTok{ val1, val2, val3 }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(first, last, types):}
    \BuiltInTok{print}\NormalTok{(val1, val2, }\StringTok{' : '}\NormalTok{, val3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Han Solo  :  light
Luke Skywalker  :  light
Leia Skywaker  :  light
Anakin Skywalker  :  light/dark/light
\end{verbatim}

\hypertarget{controlling-loops}{%
\subsubsection{Controlling loops}\label{controlling-loops}}

There are two statements that can affect how loops run:

\begin{itemize}
\tightlist
\item
  The \texttt{break} statement breaks out of the loop
\item
  The \texttt{continue} statement skips the rest of the current loop and continues to the next element
\end{itemize}

For example

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{: }\CommentTok{# If u / 2 gives a remainder of 1}
        \ControlFlowTok{continue}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{>=} \DecValTok{8}\NormalTok{:}
        \ControlFlowTok{break}
    \BuiltInTok{print}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0
2
4
6
\end{verbatim}

In this loop, we don't print the odd numbers, and we stop the loop once it gets to 8.

\hypertarget{list-comprehensions}{%
\subsection{List comprehensions}\label{list-comprehensions}}

List comprehensions are quick ways of generating a list from another list by using some recipe. For example, if we wanted to create a list of the squares of all the numbers in \texttt{test\_list2}, we could write

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{squares }\OperatorTok{=}\NormalTok{ [u }\OperatorTok{**} \DecValTok{2} \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test_list2]}
\NormalTok{squares}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
\end{verbatim}

Similarly, if we wanted to find out what the types of each element of \texttt{test\_tuple} is, we could use

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{[}\BuiltInTok{type}\NormalTok{(u) }\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test_tuple]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[<class 'str'>, <class 'int'>, <class 'bool'>, <class 'str'>, <class 'int'>]
\end{verbatim}

\textbf{Exercise:} Can you use a list comprehension to find out the types of each element of the \texttt{contact} dict?

We can also use list comprehensions to extract arbitrary sets of elements of lists

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{,}\StringTok{'e'}\NormalTok{,}\StringTok{'f'}\NormalTok{,}\StringTok{'g'}\NormalTok{]}
\NormalTok{test1 }\OperatorTok{=}\NormalTok{ [test[i] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{]]}
\NormalTok{test1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['a', 'c', 'd', 'f']
\end{verbatim}

\hypertarget{conditional-evaluations}{%
\subsection{Conditional evaluations}\label{conditional-evaluations}}

The basic structure for conditional evaluation of code is an \textbf{if-then-else} structure.

\begin{verbatim}
if Condition 1 is true then
	do Recipe 1
else if (elif) Condition 2 is true then
  do Recipe 2
else
  do Recipe 3
\end{verbatim}

In Python, this is implemented as a \texttt{if-elif-else} structure. Let's take an example where we have a list of numbers, and we want to record whether the number is negative, odd, or even.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ [}\OperatorTok{-}\DecValTok{2}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{]}
\NormalTok{y }\OperatorTok{=}\NormalTok{ []  }\CommentTok{# an empty list}

\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{<} \DecValTok{0}\NormalTok{:}
\NormalTok{        y.append(}\StringTok{"Negative"}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ u }\OperatorTok{%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{:  }\CommentTok{# what is remainder when dividing by 2}
\NormalTok{        y.append(}\StringTok{"Odd"}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        y.append(}\StringTok{"Even"}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['Negative', 'Negative', 'Even', 'Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even']
\end{verbatim}

Note here that the indentation (leading whitespace) is crucial to this structure. The \texttt{if-elif-else} structure is embedded in a for-loop, so the entire structure in indented. Also, each particular recipe is also indented within the if-elif-else structure.

\begin{quote}
The \texttt{elif} is optional, in that if you have only 2 conditions, then an \texttt{if-else} structure is sufficient. However, you can have multiple \texttt{elif}'s if you have more conditions. This kind of structure has to start with an \texttt{if}, end with an \texttt{else} and can have 0 or more \texttt{elif} in the middle.
\end{quote}

\hypertarget{functions}{%
\section{Functions}\label{functions}}

We've already seen some examples of \textbf{functions}, such as the \texttt{print()} function. For example, if we write \texttt{print(y)}, the function name is \texttt{print} and the functions \emph{argument} is \texttt{y}. So what are functions?

Functions are basically encapsulated recipes. They are groups of code that are given a name and can be called with 0 or more arguments. In a cookbook, you might have a recipe for pasta primavera. This is the name of a recipe that has ingredients and a method to cook. In Python, a similar recipe for the mean might be as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my_mean(x):}
\NormalTok{    y }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
\NormalTok{        y }\OperatorTok{+=}\NormalTok{ u }
\NormalTok{    y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(x)}
    \ControlFlowTok{return}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

This takes a list of numbers \texttt{x}, loops over the elements of \texttt{x} to find their sum, and then divides by the length of \texttt{x} to compute the mean. It then returns this mean.

\begin{quote}
The notation \texttt{+=} is a shortcut often used in programming. The statement \texttt{y\ +=\ u} means, take the current value of \texttt{y}, add the value of \texttt{u} to it, and store it back in to \texttt{y}. This is a shorthand for \texttt{y\ =\ y\ +\ u}. In analogous fashion, you can use \texttt{-=}, \texttt{*=} and \texttt{/=} to do subtraction, multiplication and division respectively.
\end{quote}

A Python function must start with the keyword \texttt{def} followed by the name of the function, the arguments within parentheses, and then a colon. The actual code for the function is indented, just like in for-loops and if-elif-else structures. It ends with a \texttt{return} function which specifies the output of the function.

To use the \texttt{my\_mean} function,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}
\NormalTok{my_mean(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
4.5
\end{verbatim}

\hypertarget{documenting-your-functions}{%
\subsection{Documenting your functions}\label{documenting-your-functions}}

Python has an in-built documentation system that allows you to readily document your functions using \emph{docstrings}. Basically, right after the first line with \texttt{def}, you can create a (multi-line) string that documents the function and will be printed if the help system is used for that function. You can create a multi-line string by \textbf{bounding it with 3 quotation marks on each side}. For example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my_mean(x):}
    \CommentTok{"""}
\CommentTok{  A function to compute the mean of a list of numbers.}
\CommentTok{  }
\CommentTok{  INPUTS:}
\CommentTok{  x : a list containing numbers}
\CommentTok{  }
\CommentTok{  OUTPUT:}
\CommentTok{  The arithmetic mean of the list of numbers}
\CommentTok{  """}
\NormalTok{    y }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{+}\NormalTok{ u}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(x)}
    \ControlFlowTok{return}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(my_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Help on function my_mean in module __main__:

my_mean(x)
    A function to compute the mean of a list of numbers.
    
    INPUTS:
    x : a list containing numbers
    
    OUTPUT:
    The arithmetic mean of the list of numbers
\end{verbatim}

\hypertarget{modules-and-packages}{%
\section{Modules and Packages}\label{modules-and-packages}}

Python itself was built with the principle ``Batteries included'', in that it already comes with useful tools for a wide variety of tasks. On top of that, there is a large ecosystem of third-party tools and packages that can be added on to add more functionality. Almost all the data science functionality in Python comes from third-party packages.

\hypertarget{using-modules}{%
\subsection{Using modules}\label{using-modules}}

The Python standard library as well as third-party packages (which I'll use interchangeably with the term libraries) are structured as modules. In order to use a particular module you have to ``activate'' it in your Python session using the \texttt{import} statement.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\NormalTok{math.cos(math.pi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-1.0
\end{verbatim}

In these statements, we have imported the \texttt{math} module. This module has many functions, one of which is the cosine or \texttt{cos} function. We use the notation \texttt{math.cos} to let Python know that we want to use the \texttt{cos} function that is in the \texttt{math} module. The value of \(\pi\) is also stored in the \texttt{math} module as \texttt{math.pi}, ie. the element \texttt{pi} within the moduel \texttt{math}.

Modules can often have long names, so Python caters to our laziness by allowing us to create aliases for modules when we import them. In this workshop we will use the following statements quite often

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\end{Highlighting}
\end{Shaded}

These statements import 3 modules into the current Python session, namely \texttt{numpy}, \texttt{pandas} and a submodule of the \texttt{matplotlib} module called \texttt{pyplot}. In each case, we have provided an alias to the module that is imported. So, in subsequent calls, we can just use the aliases.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.cos(np.pi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-1.0
\end{verbatim}

If we only want some particular components of a module to be imported, we can specify them using the \texttt{from\ ...\ import\ ...} syntax. These imported components will not need the module specification when we subsequently use them.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ math }\ImportTok{import}\NormalTok{ pi, sin, cos}

\BuiltInTok{print}\NormalTok{(sin(pi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
1.2246467991473532e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(cos(pi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-1.0
\end{verbatim}

We had made reference to the \texttt{defaultdict} function from the \texttt{collections} module before. Using this instead of \texttt{dict} can be advantagous sometimes in data scientific work.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ defaultdict}

\NormalTok{A }\OperatorTok{=}\NormalTok{ defaultdict(}\BuiltInTok{list}\NormalTok{) }\CommentTok{# Specify each component will be a list}
\NormalTok{B }\OperatorTok{=}\NormalTok{ \{\}}

\NormalTok{s }\OperatorTok{=}\NormalTok{ [(}\StringTok{'yellow'}\NormalTok{, }\DecValTok{1}\NormalTok{), (}\StringTok{'blue'}\NormalTok{, }\DecValTok{2}\NormalTok{), (}\StringTok{'yellow'}\NormalTok{, }\DecValTok{3}\NormalTok{), (}\StringTok{'blue'}\NormalTok{, }\DecValTok{4}\NormalTok{), (}\StringTok{'red'}\NormalTok{, }\DecValTok{1}\NormalTok{)]}
\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ s: }\CommentTok{# k = key, v = value}
\NormalTok{    B[k].append(v)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 'yellow'

Detailed traceback: 
  File "<string>", line 2, in <module>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ s:}
\NormalTok{    A[k].append(v)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
defaultdict(<class 'list'>, {'yellow': [1, 3], 'blue': [2, 4], 'red': [1]})
\end{verbatim}

The \texttt{defaultdict} sees a new key, and adds it to the dict, initializing it with an empty list (since we specified \texttt{defaultdict(list)}. The normal dict requires the key to already be in place in the dict for any operations to take place on that key-value pair. So the \texttt{default} dict is safer for on-the-fly work and when we don't know beforehand what keys we will encounter when storing data into the dict.

\begin{quote}
There is a temptation to use this method to import everything in a module so you don't have to specify the module. This is a \textbf{bad practice} generally, both because you clutter up the namespace that Python reads from, and because you may unknowingly over-write and replace a function from one module with one from another module, and you will have a hard time debugging your code.

The code you do \textbf{NOT} want to use is

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ math }\ImportTok{import} \OperatorTok{*}
\end{Highlighting}
\end{Shaded}
\end{quote}

\hypertarget{useful-modules-in-pythons-standard-library}{%
\subsection{Useful modules in Python's standard library}\label{useful-modules-in-pythons-standard-library}}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Module\strut
\end{minipage} & \begin{minipage}[b]{0.72\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{os} and \texttt{sys}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Interfacing with the operating system, including files, directories, and executing shell commands\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{math} and \texttt{cmath}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Mathematical functions\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{itertools}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Constructing and using iterators\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{random}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Generate random numbers\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{collections}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
More general collections for objects, beyond lists, tuples and dicts\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{installing-third-party-packageslibraries}{%
\subsection{Installing third-party packages/libraries}\label{installing-third-party-packageslibraries}}

The Anaconda Python distribution comes with its own installer and package manager called \texttt{conda}. The Anaconda repository contains most of the useful packages for data science, and many come pre-installed with the distribution. However, you can easily install packages using the \texttt{conda} manager.

\begin{verbatim}
conda install pandas
\end{verbatim}

would install the \texttt{pandas} package into your Python installation. If you wanted a particular version of this package, you could use

\begin{verbatim}
conda install pandas=0.23
\end{verbatim}

to install version 0.23 of the \texttt{pandas} package.

Anaconda also provides a repository for user-created packages. For example, to install the Python package RISE which I use for creating slides from Jupyter notebooks, I use

\begin{verbatim}
conda install -c conda-forge rise
\end{verbatim}

Sometimes you may find a Python package that is not part of the Anaconda repositories. Then you can use the more general Python program \texttt{pip} to install packages

\begin{verbatim}
pip install supersmoother
\end{verbatim}

This goes looking in the general Python package repository \href{https://pypi.org}{PyPi}, which you can also search on a web browser.

\hypertarget{environments}{%
\section{Environments}\label{environments}}

One of the nice things about Python is that you can set up environments for particular projects, that have all the packages you need for that project, without having to install those packages system-wide. This practice is highly recommended, since it creates a sandbox for you to play in for a project without contaminating the code from another project.

The Anaconda distribution and the \texttt{conda} program make this quite easy. There are a couple of ways of doing this.

\hypertarget{command-lineshell}{%
\subsection{Command-line/shell}\label{command-lineshell}}

You can open up a command line terminal (any terminal on Mac and Linux, the Anaconda Terminal in Windows) to create a new environment. For example, I have an environment I call \textbf{ds} that is my data science environment. This will include the packages \texttt{numpy}, \texttt{scipy}, \texttt{pandas},\texttt{matplotlib}, \texttt{seaborn},\texttt{statsmodels} and \texttt{scikit-learn} in it. The quick way to do this is

\begin{verbatim}
conda create -n ds numpy scipy pandas matplotlib seaborn statsmodels scikit-learn
\end{verbatim}

To use this environment, at the command line, type

\begin{verbatim}
conda activate ds
\end{verbatim}

Once you're done using it, at the command line, type

\begin{verbatim}
conda deactivate
\end{verbatim}

When your environment is activated, you'll see the name of the environment before the command prompt

\begin{figure}
\centering
\includegraphics{graphs/conda_env.png}
\caption{image-20200511003754816}
\end{figure}

\hypertarget{using-anaconda-navigator}{%
\subsection{Using Anaconda Navigator}\label{using-anaconda-navigator}}

Open the Anaconda Navigator from your start menu or using Spotlight on a Mac. Within the app is a section named ``Environments''

\begin{figure}
\centering
\includegraphics{graphs/AN_env_1.png}
\caption{image-20200511004048781}
\end{figure}

At the bottom of the 2\textsuperscript{nd} pane, you can see a ``Create'' button. Clicking it creates a pop-up window.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_2.png}
\caption{image-20200511004259459}
\end{figure}

I've named this new environment \texttt{ds1} since I already have a \texttt{ds} environment. Click ``Create''. You'll have to wait a bit of time for the environment to be created. You can then add/install packages to this environment by clicking on packages on the right panel, making sure you changed the first drop-down menu from ``Installed'' to ``Not installed''.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_3.png}
\caption{image-20200511004530076}
\end{figure}

Once you've selected the packages you want to install, click ``Appy'' on the bottom right of the window.

To activate an environment, you can go to the Home pane for Anaconda Navigator and change the environment on the ``Applications on'' drop-down menu.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_4.png}
\caption{image-20200511004920105}
\end{figure}

\hypertarget{reproducing-environments}{%
\subsection{Reproducing environments}\label{reproducing-environments}}

Suppose you've got an environment set up the way you like it, and want to clone it on another machine that has Anaconda installed. There is an easy way to do this. You have to use the command line (Anaconda Prompt (Win) or a terminal) for this.

First activate the environment you want to export (I'll use \texttt{ds} as an example)

\begin{verbatim}
conda activate ds
\end{verbatim}

Then export the environment specifications which includes all the packages installed in that environment

\begin{verbatim}
conda env export > environment.yml
\end{verbatim}

You can take this \texttt{environment.yml} file to a new computer, or e-mail it to a collaborator to install the environment. This environment can be created on the new computer using

\begin{verbatim}
conda env create -f environment.yml
\end{verbatim}

where the first line of the \texttt{environment.yml} file creates the environment name.

You can also create the environment from an \texttt{environment.yml} file from Anaconda Navigator by using the Import button rather than the Create button in the instructions above.

\begin{quote}
If you are changing operating systems, create the \texttt{environment.yml} file using the command

\begin{verbatim}
conda env export --from-history > environment.yml
\end{verbatim}

This avoids potential issues with dependencies that may not be compatible across operating systems
\end{quote}

\hypertarget{seeking-help}{%
\section{Seeking help}\label{seeking-help}}

Most Python functions have some amount of documentation. As we saw when we created our own function, this documentation is part of the function definition. It can be accessed at the Python console in 2 ways:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(}\BuiltInTok{sum}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Help on built-in function sum in module builtins:

sum(iterable, /, start=0)
    Return the sum of a 'start' value (default: 0) plus an iterable of numbers
    
    When the iterable is empty, return the start value.
    This function is intended specifically for use with numeric values and may
    reject non-numeric types.
\end{verbatim}

or

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# sum?}
\end{Highlighting}
\end{Shaded}

You can see the documentation of the \texttt{my\_sum} function we created earlier in this way, as well.

Other resources that are your friends in the internet age are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://stackoverflow.com}{Stack Overflow}: This is a Q \& A site. To find Python-related questions, use the tag \texttt{python}.
\item
  Google: Of course.
\item
  \href{https://stats.stackexchange.com}{Cross-Validated}: A data science oriented Q \& A site. Once again, use the tag \texttt{python}.
\end{enumerate}

\hypertarget{python-tools-for-data-science}{%
\chapter{Python tools for data science}\label{python-tools-for-data-science}}

(last updated 2020-05-18)

\hypertarget{the-pydata-stack}{%
\section{The PyData Stack}\label{the-pydata-stack}}

The Python Data Stack comprises a set of packages that makes Python a powerful data science language. These include

\begin{itemize}
\tightlist
\item
  Numpy: provides arrays and matrix algebra
\item
  Scipy: provides scientific computing capabilities
\item
  matplotlib: provides graphing capabilities
\end{itemize}

These were the original stack that was meant to replace Matlab. However, these were meant to tackle purely numerical data, and the kinds of heterogeneous data we regularly face needed more tools. These were added more recently.

\begin{itemize}
\tightlist
\item
  Pandas: provides data analytic structures like the data frame, as well as basic descriptive statistical capabilities
\item
  statsmodels: provides a fairly comprehensive set of statistical functions
\item
  scikit-learn: provides machine learning capabilities
\end{itemize}

This is the basic stack of packages we will be using in this workshop. Additionally we will use a few packages that add some functionality to the data science process. These include

\begin{itemize}
\item
  seaborn: Better statistical graphs
\item
  plotly: Interactive graphics
\item
  biopython: Python for bioinformatics
\end{itemize}

We may also introduce the package \texttt{rpy2} which allows one to run R from within Python. This can be useful since many bioinformatic pipelines are already implemented in R.

\begin{quote}
The \href{https://scipy.org}{PyData stack} also includes \texttt{sympy}, a symbolic mathematics package emulating Maple
\end{quote}

\hypertarget{numpy-numerical-and-scientific-computing}{%
\section{Numpy (numerical and scientific computing)}\label{numpy-numerical-and-scientific-computing}}

We start by importing the Numpy package into Python using the alias \texttt{np}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\end{Highlighting}
\end{Shaded}

Numpy provides both arrays (vectors, matrices, higher dimensional arrays) and vectorized functions which are very fast. Let's see how this works.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\FloatTok{9.3}\NormalTok{,}\FloatTok{10.6}\NormalTok{] }\CommentTok{# This is a list}
\NormalTok{z_array }\OperatorTok{=}\NormalTok{ np.array(z)}
\NormalTok{z_array}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([ 1. ,  2. ,  3. ,  4. ,  5. ,  6. ,  7. ,  8. ,  9.3, 10.6])
\end{verbatim}

Now, we have already seen functions in Python earlier. In Numpy, there are functions that are optimized for arrays, that can be accessed directly from the array objects. This is an example of \emph{object-oriented programming} in Python, where functions are provided for particular \emph{classes} of objects, and which can be directly accessed from the objects. We will use several such functions over the course of this workshop, but we won't actually talk about how to do this program development here.

\begin{quote}
Numpy functions are often very fast, and are \emph{vectorized}, i.e., they are written to work on vectors of numbers rather than single numbers. This is an advantage in data science since we often want to do the same operation to all elements of a column of data, which is essentially a vector
\end{quote}

We apply the functions \texttt{sum}, \texttt{min} (minimum value) and \texttt{max} (maximum value) to \texttt{z\_array}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_array.}\BuiltInTok{sum}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
55.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_array.}\BuiltInTok{min}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
1.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_array.}\BuiltInTok{max}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
10.6
\end{verbatim}

The versions of these functions in Numpy are optimized for arrays and are quite a bit faster than the corresponding functions available in base Python. When doing data work, these are the preferred functions.

These functions can also be used in the usual function manner:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{max}\NormalTok{(z_array)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
10.6
\end{verbatim}

Calling \texttt{np.max} ensures that we are using the \texttt{max} function from numpy, and not the one in base Python.

\hypertarget{numpy-data-types}{%
\subsection{Numpy data types}\label{numpy-data-types}}

Numpy arrays are homogeneous in type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['a', 'b', 'c'], dtype='<U1')
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{29}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([ 1,  2,  3,  6,  8, 29])
\end{verbatim}

But, what if we provide a heterogeneous list?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\StringTok{'a'}\NormalTok{]}
\NormalTok{np.array(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['1', '3', 'a'], dtype='<U21')
\end{verbatim}

So what's going on here? Upon conversion from a heterogeneous list, numpy converted the numbers into strings. This is necessary since, by definition, numpy arrays can hold data of a single type. When one of the elements is a string, numpy casts all the other entities into strings as well. Think about what would happen if the opposite rule was used. The string `a' doesn't have a corresponding number, while both numbers 1 and 3 have corresponding string representations, so going from string to numeric would create all sorts of problems.

\begin{quote}
The advantage of numpy arrays is that the data is stored in a contiguous section of memory, and you can be very efficient with homogeneous arrays in terms of manipulating them, applying functions, etc. However, \texttt{numpy} does provide a ``catch-all'' \texttt{dtype} called \texttt{object}, which can be any Python object. This \texttt{dtype} essentially is an array of pointers to actual data stored in different parts of the memory. You can get to the actual objects by extracting them. So one could do
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\StringTok{'a'}\NormalTok{], dtype}\OperatorTok{=}\StringTok{'object'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([1, 3, 'a'], dtype=object)
\end{verbatim}

\begin{quote}
which would basically be a valid \texttt{numpy} array, but would go back to the actual objects when used, much like a list. We can see this later if we want to transform a heterogeneous \texttt{pandas} \texttt{DataFrame} into a \texttt{numpy} array. It's not particularly useful as is, but it prevents errors from popping up during transformations from \texttt{pandas} to \texttt{numpy}.
\end{quote}

\hypertarget{generating-data-in-numpy}{%
\subsection{Generating data in numpy}\label{generating-data-in-numpy}}

We had seen earlier how we could generate a sequence of numbers in a list using \texttt{range}. In numpy, you can generate a sequence of numbers in an array using \texttt{arange} (which actually creates the array rather than provide an iterator like \texttt{range}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.arange(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
\end{verbatim}

You can also generate regularly spaced sequences of numbers between particular values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.linspace(start}\OperatorTok{=}\DecValTok{0}\NormalTok{, stop}\OperatorTok{=}\DecValTok{1}\NormalTok{, num}\OperatorTok{=}\DecValTok{11}\NormalTok{) }\CommentTok{# or np.linspace(0, 1, 11)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])
\end{verbatim}

You can also do this with real numbers rather than integers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.linspace(start }\OperatorTok{=} \DecValTok{0}\NormalTok{, stop }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, num }\OperatorTok{=} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.        , 0.6981317 , 1.3962634 , 2.0943951 , 2.7925268 ,
       3.4906585 , 4.1887902 , 4.88692191, 5.58505361, 6.28318531])
\end{verbatim}

More generally, you can transform lists into \texttt{numpy} arrays. We saw this above for vectors. For matrices, you can provide a list of lists. Note the double \texttt{{[}} in front and back.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{],[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[1, 3, 5, 6],
       [4, 3, 9, 7]])
\end{verbatim}

You can generate an array of 0's

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
\end{verbatim}

This can easily be extended to a two-dimensional array (a matrix), by specifying the dimension of the matrix as a tuple.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros((}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
\end{verbatim}

You can also generate a matrix of 1s in a similar manner.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.ones((}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[1., 1., 1., 1.],
       [1., 1., 1., 1.],
       [1., 1., 1., 1.]])
\end{verbatim}

In matrix algebra, the identity matrix is important. It is a square matrix with 1's on the diagonal and 0's everywhere else.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.eye(}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[1., 0., 0., 0.],
       [0., 1., 0., 0.],
       [0., 0., 1., 0.],
       [0., 0., 0., 1.]])
\end{verbatim}

You can also create numpy vectors directly from lists, as long as lists are made up of atomic elements of the same type. This means a list of numbers or a list of strings. The elements can't be more composite structures, generally. One exception is a list of lists, where all the lists contain the same type of atomic data, which, as we will see, can be used to create a matrix or 2-dimensional array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{]}
\NormalTok{b }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{,}\StringTok{'3'}\NormalTok{]}

\NormalTok{np.array(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([1, 2, 3, 4, 5, 6, 7, 8])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['a', 'b', 'c', 'd', '3'], dtype='<U1')
\end{verbatim}

\hypertarget{random-numbers}{%
\subsubsection{Random numbers}\label{random-numbers}}

Generating random numbers is quite useful in many areas of data science. All computers don't produce truly random numbers but generate \emph{pseudo-random} sequences. These are completely deterministic sequences defined algorithmically that emulate the properties of random numbers. Since these are deterministic, we can set a \emph{seed} or starting value for the sequence, so that we can exactly reproduce this sequence to help debug our code. To actually see how things behave in simulations we will often run several sequences of random numbers starting at different seed values.

The seed is set by the \texttt{RandomState} function within the \texttt{random} submodule of numpy. Note that all Python names are case-sensitive.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{35}\NormalTok{) }\CommentTok{# set seed}
\NormalTok{rng.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[9, 7, 1, 0],
       [9, 8, 8, 8],
       [9, 7, 7, 8]])
\end{verbatim}

We have created a 3x4 matrix of random integers between 0 and 10 (in line with slicing rules, this includes 0 but not 10).

We can also create a random sample of numbers between 0 and 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng.random_sample((}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0.04580216, 0.91259827],
       [0.21381599, 0.3036373 ],
       [0.98906362, 0.1858815 ],
       [0.98872484, 0.75008423],
       [0.22238605, 0.14790391]])
\end{verbatim}

We'll see later how to generate random numbers from particular probability distributions.

\hypertarget{vectors-and-matrices}{%
\subsection{Vectors and matrices}\label{vectors-and-matrices}}

Numpy generates arrays, which can be of arbitrary dimension. However the most useful are vectors (1-d arrays) and matrices (2-d arrays).

In these examples, we will generate samples from the Normal (Gaussian) distribution, with mean 0 and variance 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We can compute some characteristics of this matrix's dimensions. The number of rows and columns are given by \texttt{shape}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(4, 5)
\end{verbatim}

The total number of elements are given by \texttt{size}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.size}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
20
\end{verbatim}

If we want to create a matrix of 0's with the same dimensions as \texttt{A}, we don't actually have to compute its dimensions. We can use the \texttt{zeros\_like} function to figure it out.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros_like(A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]])
\end{verbatim}

We can also create vectors by only providing the number of rows to the random sampling function. The number of columns will be assumed to be 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,))}
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-0.45495378,  1.04307172,  0.70451207, -0.6171649 ])
\end{verbatim}

\hypertarget{extracting-elements-from-arrays}{%
\subsubsection{Extracting elements from arrays}\label{extracting-elements-from-arrays}}

The syntax for extracting elements from arrays is almost exactly the same as for lists, with the same rules for slices.

\textbf{Exercise:} State what elements of B are extracted by each of the following statements

\begin{verbatim}
B[:3]
B[:-1]
B[[0,2,4]]
B[[0,2,5]]
\end{verbatim}

For matrices, we have two dimensions, so you can slice by rows, or columns or both.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-2.45677354,  0.36686697, -0.20453263, -0.54380446,  0.09524207],
       [ 1.06236144,  1.03937554,  0.01247733, -0.35427727, -1.18997812],
       [ 0.95554288,  0.30781478,  0.7328766 , -1.28670314, -1.03870027],
       [-0.81398211, -1.02506031,  0.12407205,  1.21491023, -1.44645123]])
\end{verbatim}

We can extract the first column by specifying \texttt{:} (meaning everything) for the rows, and the index for the column (reminder, Python starts counting at 0)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-2.45677354,  1.06236144,  0.95554288, -0.81398211])
\end{verbatim}

Similarly the 4th row can be extracted by putting the row index, and \texttt{:} for the column index.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[}\DecValTok{3}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-0.81398211, -1.02506031,  0.12407205,  1.21491023, -1.44645123])
\end{verbatim}

All slicing operations work for rows and columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:}\DecValTok{2}\NormalTok{,:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-2.45677354,  0.36686697],
       [ 1.06236144,  1.03937554]])
\end{verbatim}

\hypertarget{array-operations}{%
\subsubsection{Array operations}\label{array-operations}}

We can do a variety of vector and matrix operations in \texttt{numpy}.

First, all usual arithmetic operations work on arrays, like adding or multiplying an array with a scalar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randn(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-0.15367796,  2.50215522,  0.19420725,  0.54928294, -1.1737166 ],
       [ 1.11456557,  0.07447758,  1.58518354,  1.61986225, -0.24616333],
       [-0.02682273,  0.2196577 ,  0.41680351, -0.86319929,  0.50355595]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{+} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 9.84632204, 12.50215522, 10.19420725, 10.54928294,  8.8262834 ],
       [11.11456557, 10.07447758, 11.58518354, 11.61986225,  9.75383667],
       [ 9.97317727, 10.2196577 , 10.41680351,  9.13680071, 10.50355595]])
\end{verbatim}

We can also add and multiply arrays \textbf{element-wise} as long as they are the same shape.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[6, 2, 3, 9, 8],
       [5, 9, 3, 9, 7],
       [0, 4, 2, 5, 0]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{+}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 5.84632204,  4.50215522,  3.19420725,  9.54928294,  6.8262834 ],
       [ 6.11456557,  9.07447758,  4.58518354, 10.61986225,  6.75383667],
       [-0.02682273,  4.2196577 ,  2.41680351,  4.13680071,  0.50355595]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{*}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-0.92206775,  5.00431043,  0.58262175,  4.94354649, -9.38973278],
       [ 5.57282784,  0.67029821,  4.75555061, 14.57876027, -1.72314331],
       [-0.        ,  0.8786308 ,  0.83360701, -4.31599644,  0.        ]])
\end{verbatim}

You can also do \textbf{matrix multiplication}. Recall what this is.

If you have a matrix \(A_{m x n}\) and another matrix \(B_{n x p}\), as long as the number of columns of \(A\) and rows of \(B\) are the same, you can multiply them (\(C_{m x p} = A_{m x n}B_{n x p}\)), with the (i,j)-th element of C being

\[ c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}, i= 1, \dots, m; j = 1, \dots, p\]

In \texttt{numpy} the operant for matrix multiplication is \texttt{@}.

In the above examples, \texttt{A} and \texttt{B} cannot be multiplied since they have incompatible dimensions. However, we can take the \emph{transpose} of \texttt{B}, i.e.~flip the rows and columns, to make it compatible with \texttt{A} for matrix multiplication.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{@}\NormalTok{ np.transpose(B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 0.21867814, 19.0611592 , 13.14345008],
       [24.20135281, 23.85429363, 11.56758865],
       [-2.21155643, -1.15068575, -2.60375863]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.transpose(A) }\OperatorTok{@}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[  4.65076009,   9.61644327,   2.82901737,   8.51387483,
          6.57253531],
       [ 15.38531919,   6.55323945,   8.16921379,  24.28798365,
         20.53858478],
       [  9.09116118,  16.32228035,   6.17177937,  18.0985346 ,
         12.64994275],
       [ 11.39500892,  12.22452901,   4.78103701,  15.20631032,
         15.73329932],
       [ -8.27311623,  -2.54867934,  -3.25252787, -10.26113957,
        -11.11287609]])
\end{verbatim}

More generally, you can \emph{reshape} a \texttt{numpy} array into a new shape, provided it is compatible with the number of elements in the original array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\NormalTok{D}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0, 2, 0, 0],
       [4, 0, 0, 4],
       [0, 3, 2, 0],
       [3, 0, 0, 3]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D.reshape(}\DecValTok{8}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0, 2],
       [0, 0],
       [4, 0],
       [0, 4],
       [0, 3],
       [2, 0],
       [3, 0],
       [0, 3]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D.reshape(}\DecValTok{1}\NormalTok{,}\DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0, 2, 0, 0, 4, 0, 0, 4, 0, 3, 2, 0, 3, 0, 0, 3]])
\end{verbatim}

This can also be used to cast a vector into a matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{20}\NormalTok{)}
\NormalTok{E }\OperatorTok{=}\NormalTok{ e.reshape(}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\NormalTok{E}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15],
       [16, 17, 18, 19]])
\end{verbatim}

\begin{quote}
One thing to note in all the reshaping operations above is that the new array takes elements of the old array \textbf{by row}. See the examples above to convince yourself of that.
\end{quote}

\hypertarget{statistical-operations-on-arrays}{%
\subsubsection{Statistical operations on arrays}\label{statistical-operations-on-arrays}}

You can sum all the elements of a matrix using \texttt{sum}. You can also sum along rows or along columns by adding an argument to the \texttt{sum} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-1.60798054, -0.05162306],
       [-0.49218049, -0.1262316 ],
       [ 0.56927597,  0.05438786],
       [ 0.33120322, -0.81820729]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-2.141355938226197
\end{verbatim}

You can sum along rows (i.e., down columns) with the option \texttt{axis\ =\ 0}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-1.19968185, -0.94167409])
\end{verbatim}

You can sum along columns (i.e., across rows) with \texttt{axis\ =\ 1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-1.6596036 , -0.61841209,  0.62366383, -0.48700407])
\end{verbatim}

\begin{quote}
Of course, you can use the usual function calls: \texttt{np.sum(A,\ axis\ =\ 1)}
\end{quote}

We can also find the minimum and maximum values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{min}\NormalTok{(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([-1.60798054, -0.81820729])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{max}\NormalTok{(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.56927597, 0.05438786])
\end{verbatim}

We can also find the \textbf{position} where the minimum and maximum values occur.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.argmin(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0, 3])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.argmax(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([2, 2])
\end{verbatim}

We can sort arrays and also find the indices which will result in the sorted array. I'll demonstrate this for a vector, where it is more relevant

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([9, 2, 6, 6, 4, 4, 3, 4])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.sort(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([2, 3, 4, 4, 4, 6, 6, 9])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.argsort(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([1, 6, 4, 5, 7, 2, 3, 0])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[np.argsort(a)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([2, 3, 4, 4, 4, 6, 6, 9])
\end{verbatim}

\texttt{np.argsort} can also help you find the 2nd smallest or 3rd largest value in an array, too.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind_2nd_smallest }\OperatorTok{=}\NormalTok{ np.argsort(a)[}\DecValTok{1}\NormalTok{]}
\NormalTok{a[ind_2nd_smallest]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind_3rd_largest }\OperatorTok{=}\NormalTok{ np.argsort(a)[}\OperatorTok{-}\DecValTok{3}\NormalTok{]}
\NormalTok{a[ind_3rd_largest]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
6
\end{verbatim}

You can also sort strings in this way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OperatorTok{=}\NormalTok{ np.array([}\StringTok{'Aram'}\NormalTok{,}\StringTok{'Raymond'}\NormalTok{,}\StringTok{'Elizabeth'}\NormalTok{,}\StringTok{'Donald'}\NormalTok{,}\StringTok{'Harold'}\NormalTok{])}
\NormalTok{np.sort(m)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['Aram', 'Donald', 'Elizabeth', 'Harold', 'Raymond'], dtype='<U9')
\end{verbatim}

If you want to sort arrays \textbf{in place}, you can use the \texttt{sort} function in a different way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m.sort()}
\NormalTok{m}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['Aram', 'Donald', 'Elizabeth', 'Harold', 'Raymond'], dtype='<U9')
\end{verbatim}

\hypertarget{putting-arrays-together}{%
\subsubsection{Putting arrays together}\label{putting-arrays-together}}

We can put arrays together by row or column, provided the corresponding axes have compatible lengths.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{'A = '}\NormalTok{, A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
A =  [[3 4 2 1 3]
 [0 3 1 1 1]
 [4 0 2 0 4]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{'B = '}\NormalTok{, B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
B =  [[1 4 2 1 3]
 [2 0 3 2 0]
 [4 0 2 3 3]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.hstack((A,B))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[3, 4, 2, 1, 3, 1, 4, 2, 1, 3],
       [0, 3, 1, 1, 1, 2, 0, 3, 2, 0],
       [4, 0, 2, 0, 4, 4, 0, 2, 3, 3]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.vstack((A,B))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[3, 4, 2, 1, 3],
       [0, 3, 1, 1, 1],
       [4, 0, 2, 0, 4],
       [1, 4, 2, 1, 3],
       [2, 0, 3, 2, 0],
       [4, 0, 2, 3, 3]])
\end{verbatim}

Note that both \texttt{hstack} and \texttt{vstack} take a \textbf{tuple} of arrays as input.

\hypertarget{logicalboolean-operations}{%
\subsubsection{Logical/Boolean operations}\label{logicalboolean-operations}}

You can query a matrix to see which elements meet some criterion. In this example, we'll see which elements are negative.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{<} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[False, False, False, False, False],
       [False, False, False, False, False],
       [False, False, False, False, False]])
\end{verbatim}

This is called \textbf{masking}, and is useful in many contexts.

We can extract all the negative elements of A using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[A}\OperatorTok{<}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([], dtype=int64)
\end{verbatim}

This forms a 1-d array. You can also count the number of elements that meet the criterion

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{sum}\NormalTok{(A}\OperatorTok{<}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0
\end{verbatim}

Since the entity \texttt{A\textless{}0} is a matrix as well, we can do row-wise and column-wise operations as well.

\hypertarget{beware-of-copies}{%
\subsection{Beware of copies}\label{beware-of-copies}}

One has to be a bit careful with copying objects in Python. By default, if you just assign one object to a new name, it does a \emph{shallow copy}, which means that both names point to the same memory. So if you change something in the original, it also changes in the new copy.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[}\DecValTok{0}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([3, 4, 2, 1, 3])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A1 }\OperatorTok{=}\NormalTok{ A}
\NormalTok{A1[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{4}
\NormalTok{A[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
4
\end{verbatim}

To actually create a copy that is not linked back to the original, you have to make a \emph{deep copy}, which creates a new space in memory and a new pointer, and copies the original object to the new memory location

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A1 }\OperatorTok{=}\NormalTok{ A.copy()}
\NormalTok{A1[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{6}
\NormalTok{A[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
4
\end{verbatim}

You can also replace sub-matrices of a matrix with new data, provided that the dimensions are compatible. (Make sure that the sub-matrix we are replacing below truly has 2 rows and 2 columns, which is what \texttt{np.eye(2)} will produce)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:}\DecValTok{2}\NormalTok{,:}\DecValTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.eye(}\DecValTok{2}\NormalTok{)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[1, 0, 2, 1, 3],
       [0, 1, 1, 1, 1],
       [4, 0, 2, 0, 4]])
\end{verbatim}

\hypertarget{reducing-matrix-dimensions}{%
\subsubsection{Reducing matrix dimensions}\label{reducing-matrix-dimensions}}

Sometimes the output of some operation ends up being a matrix of one column or one row. We can reduce it to become a vector. There are two functions that can do that, \texttt{flatten} and \texttt{ravel}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[2],
       [1],
       [4],
       [2],
       [4]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.flatten()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([2, 1, 4, 2, 4])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.ravel()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([2, 1, 4, 2, 4])
\end{verbatim}

So why two functions? I'm not sure, but they do different things behind the scenes. \texttt{flatten} creates a \textbf{copy}, i.e.~a new array disconnected from \texttt{A}. \texttt{ravel} creates a \textbf{view}, so a representation of the original array. If you then changed a value after a \texttt{ravel} operation, you would also change it in the original array; if you did this after a \texttt{flatten} operation, you would not.

\hypertarget{broadcasting-in-python}{%
\subsection{Broadcasting in Python}\label{broadcasting-in-python}}

Python deals with arrays in an interesting way, in terms of matching up dimensions of arrays for arithmetic operations. There are 3 rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If two arrays differ in the number of dimensions, the shape of the smaller array is padded with 1s on its \emph{left} side
\item
  If the shape doesn't match in any dimension, the array with shape = 1 in that dimension is stretched to match the others' shape
\item
  If in any dimension the sizes disagree and none of the sizes are 1, then an error is generated
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(4, 5)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(5,)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{-}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 0.25410957,  1.89009891, -0.87300221, -0.17852271, -0.64735645],
       [ 0.72991872,  4.58821268, -0.03379553, -1.67352398,  1.43345867],
       [-1.51421293,  1.69993003,  1.81140727, -1.71622014,  0.52276992],
       [-1.30611819,  3.29767231,  0.91060221,  0.29490453,  1.24919619]])
\end{verbatim}

B is 1-d, A is 2-d, so B's shape is made into (1,5) (added to the left). Then it is repeated into 4 rows to make it's shape (4,5), then the operation is performed. This means that we subtract the first element of B from the first column of A, the second element of B from the second column of A, and so on.

You can be explicit about adding dimensions for broadcasting by using \texttt{np.newaxis}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B[np.newaxis,:].shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(1, 5)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B[:,np.newaxis].shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(5, 1)
\end{verbatim}

\hypertarget{an-example-optional-intermediateadvanced}{%
\subsubsection{An example (optional, intermediate/advanced))}\label{an-example-optional-intermediateadvanced}}

This can be very useful, since these operations are faster than for loops. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OperatorTok{=}\NormalTok{ rng.random_sample((}\DecValTok{10}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{d}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0.9497432 , 0.22672332],
       [0.96319737, 0.61011348],
       [0.2542308 , 0.60550727],
       [0.64054935, 0.85273037],
       [0.19747218, 0.45957414],
       [0.41571736, 0.9902779 ],
       [0.33720945, 0.30637872],
       [0.15139082, 0.30126537],
       [0.72158605, 0.3560211 ],
       [0.86288412, 0.66608767]])
\end{verbatim}

We want to find the Euclidean distance (the sum of squared differences) between the points defined by the rows. This should result in a 10x10 distance matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(10, 2)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[np.newaxis,:,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[[0.9497432 , 0.22672332],
        [0.96319737, 0.61011348],
        [0.2542308 , 0.60550727],
        [0.64054935, 0.85273037],
        [0.19747218, 0.45957414],
        [0.41571736, 0.9902779 ],
        [0.33720945, 0.30637872],
        [0.15139082, 0.30126537],
        [0.72158605, 0.3560211 ],
        [0.86288412, 0.66608767]]])
\end{verbatim}

creates a 3-d array with the first dimension being of length 1

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[np.newaxis,:,:].shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(1, 10, 2)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[:, np.newaxis,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[[0.9497432 , 0.22672332]],

       [[0.96319737, 0.61011348]],

       [[0.2542308 , 0.60550727]],

       [[0.64054935, 0.85273037]],

       [[0.19747218, 0.45957414]],

       [[0.41571736, 0.9902779 ]],

       [[0.33720945, 0.30637872]],

       [[0.15139082, 0.30126537]],

       [[0.72158605, 0.3560211 ]],

       [[0.86288412, 0.66608767]]])
\end{verbatim}

creates a 3-d array with the 2nd dimension being of length 1

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[:,np.newaxis,:].shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(10, 1, 2)
\end{verbatim}

Now for the trick, using broadcasting of arrays. These two arrays are incompatible without broadcasting, but with broadcasting, the right things get repeated to make things compatible

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((d[:,np.newaxis,:] }\OperatorTok{-}\NormalTok{ d[np.newaxis,:,:]) }\OperatorTok{**} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
29.512804540441067
\end{verbatim}

Whoops! we wanted a 10x10 matrix, not a scalar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(d[:,np.newaxis,:] }\OperatorTok{-}\NormalTok{ d[np.newaxis,:,:]).shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(10, 10, 2)
\end{verbatim}

What we really want is the 10x10 distance matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((d[:,np.newaxis,:] }\OperatorTok{-}\NormalTok{ d[np.newaxis,:,:]) }\OperatorTok{**} \DecValTok{2}\NormalTok{, axis}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can verify what is happening by creating \texttt{D\ =\ d{[}:,np.newaxis,:{]}-d{[}np.newaxis,:,:{]}} and then looking at \texttt{D{[}:,:,0{]}} and \texttt{D{[}:,:,1{]}}. These are the difference between each combination in the first and second columns of d, respectively. Squaring and summing along the 3rd axis then gives the sum of squared differences.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[0.        , 0.14716903, 0.62721478, 0.48748566, 0.6201312 ,
        0.8681992 , 0.38154258, 0.64292305, 0.0687736 , 0.20058553],
       [0.14716903, 0.        , 0.5026548 , 0.16296469, 0.60899716,
        0.44425934, 0.48411568, 0.75441703, 0.12293897, 0.01319586],
       [0.62721478, 0.5026548 , 0.        , 0.21036128, 0.02451802,
        0.17412634, 0.09636334, 0.1031392 , 0.28066428, 0.37412884],
       [0.48748566, 0.16296469, 0.21036128, 0.        , 0.35088921,
        0.06946875, 0.39051522, 0.54338972, 0.25328705, 0.08426824],
       [0.6201312 , 0.60899716, 0.02451802, 0.35088921, 0.        ,
        0.32927744, 0.04299534, 0.02718516, 0.28541859, 0.48542089],
       [0.8681992 , 0.44425934, 0.17412634, 0.06946875, 0.32927744,
        0.        , 0.47388157, 0.54460678, 0.49583735, 0.30505741],
       [0.38154258, 0.48411568, 0.09636334, 0.39051522, 0.04299534,
        0.47388157, 0.        , 0.03455471, 0.15020974, 0.40572438],
       [0.64292305, 0.75441703, 0.1031392 , 0.54338972, 0.02718516,
        0.54460678, 0.03455471, 0.        , 0.3281208 , 0.63931803],
       [0.0687736 , 0.12293897, 0.28066428, 0.25328705, 0.28541859,
        0.49583735, 0.15020974, 0.3281208 , 0.        , 0.11610642],
       [0.20058553, 0.01319586, 0.37412884, 0.08426824, 0.48542089,
        0.30505741, 0.40572438, 0.63931803, 0.11610642, 0.        ]])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(10, 10)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist_sq.diagonal()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
\end{verbatim}

\hypertarget{conclusions-moving-forward}{%
\subsection{Conclusions moving forward}\label{conclusions-moving-forward}}

It's important to understand numpy and arrays, since most data sets we encounter are rectangular. The notations and operations we saw in numpy will translate to data, except for the fact that data is typically heterogeneous, i.e., of different types. The problem with using numpy for modern data analysis is that if you have mixed data types, it will all be coerced to strings, and then you can't actually do any data analysis.

The solution to this issue (which is also present in Matlab) came about with the \texttt{pandas} package, which is the main workhorse of data science in Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reticulate}\OperatorTok{::}\KeywordTok{use_condaenv}\NormalTok{(}\StringTok{'ds'}\NormalTok{, }\DataTypeTok{required=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\hypertarget{pandas}{%
\chapter{Pandas}\label{pandas}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\texttt{pandas} is the Python Data Analysis package. It allows for data ingestion, transformation and cleaning, and creates objects that can then be passed on to analytic packages like \texttt{statsmodels} and \texttt{scikit-learn} for modeling and packages like \texttt{matplotlib}, \texttt{seaborn}, and \texttt{plotly} for visualization.

\texttt{pandas} is built on top of numpy, so many numpy functions are commonly used in manipulating \texttt{pandas} objects.

\begin{quote}
\texttt{pandas} is a pretty extensive package, and we'll only be able to cover some of its features. For more details, there is free online documentation at \href{https://pandas.pydata.org}{pandas.pydata.org}. You can also look at the book \href{https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython-dp-1491957662/dp/1491957662/}{``Python for Data Analysis (2nd edition)''} by Wes McKinney, the original developer of the pandas package, for more details.
\end{quote}

\hypertarget{starting-pandas}{%
\section{Starting pandas}\label{starting-pandas}}

As with any Python module, you have to ``activate'' \texttt{pandas} by using \texttt{import}. The ``standard'' alias for \texttt{pandas} is \texttt{pd}. We will also import \texttt{numpy}, since \texttt{pandas} uses some \texttt{numpy} functions in the workflows.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-import-and-export}{%
\section{Data import and export}\label{data-import-and-export}}

Most data sets you will work with are set up in tables, so are rectangular in shape. Think Excel spreadsheets. In \texttt{pandas} the structure that will hold this kind of data is a \texttt{DataFrame}. We can read external data into a \texttt{DataFrame} using one of many \texttt{read\_*} functions. We can also write from a \texttt{DataFrame} to a variety of formats using \texttt{to\_*} functions. The most common of these are listed below:

\begin{longtable}[]{@{}llll@{}}
\toprule
Format type & Description & reader & writer\tabularnewline
\midrule
\endhead
text & CSV & read\_csv & to\_csv\tabularnewline
& Excel & read\_excel & to\_excel\tabularnewline
text & JSON & read\_json & to\_json\tabularnewline
binary & Feather & read\_feather & to\_feather\tabularnewline
binary & SAS & read\_sas &\tabularnewline
SQL & SQL & read\_sql & to\_sql\tabularnewline
\bottomrule
\end{longtable}

We'll start by reading in the \texttt{mtcars} dataset stored as a CSV file

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.read_csv(}\StringTok{'data/mtcars.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   make   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb
0             Mazda RX4  21.0    6  160.0  110  ...  16.46   0   1     4     4
1         Mazda RX4 Wag  21.0    6  160.0  110  ...  17.02   0   1     4     4
2            Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1
3        Hornet 4 Drive  21.4    6  258.0  110  ...  19.44   1   0     3     1
4     Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0   0     3     2
5               Valiant  18.1    6  225.0  105  ...  20.22   1   0     3     1
6            Duster 360  14.3    8  360.0  245  ...  15.84   0   0     3     4
7             Merc 240D  24.4    4  146.7   62  ...  20.00   1   0     4     2
8              Merc 230  22.8    4  140.8   95  ...  22.90   1   0     4     2
9              Merc 280  19.2    6  167.6  123  ...  18.30   1   0     4     4
10            Merc 280C  17.8    6  167.6  123  ...  18.90   1   0     4     4
11           Merc 450SE  16.4    8  275.8  180  ...  17.40   0   0     3     3
12           Merc 450SL  17.3    8  275.8  180  ...  17.60   0   0     3     3
13          Merc 450SLC  15.2    8  275.8  180  ...  18.00   0   0     3     3
14   Cadillac Fleetwood  10.4    8  472.0  205  ...  17.98   0   0     3     4
15  Lincoln Continental  10.4    8  460.0  215  ...  17.82   0   0     3     4
16    Chrysler Imperial  14.7    8  440.0  230  ...  17.42   0   0     3     4
17             Fiat 128  32.4    4   78.7   66  ...  19.47   1   1     4     1
18          Honda Civic  30.4    4   75.7   52  ...  18.52   1   1     4     2
19       Toyota Corolla  33.9    4   71.1   65  ...  19.90   1   1     4     1
20        Toyota Corona  21.5    4  120.1   97  ...  20.01   1   0     3     1
21     Dodge Challenger  15.5    8  318.0  150  ...  16.87   0   0     3     2
22          AMC Javelin  15.2    8  304.0  150  ...  17.30   0   0     3     2
23           Camaro Z28  13.3    8  350.0  245  ...  15.41   0   0     3     4
24     Pontiac Firebird  19.2    8  400.0  175  ...  17.05   0   0     3     2
25            Fiat X1-9  27.3    4   79.0   66  ...  18.90   1   1     4     1
26        Porsche 914-2  26.0    4  120.3   91  ...  16.70   0   1     5     2
27         Lotus Europa  30.4    4   95.1  113  ...  16.90   1   1     5     2
28       Ford Pantera L  15.8    8  351.0  264  ...  14.50   0   1     5     4
29         Ferrari Dino  19.7    6  145.0  175  ...  15.50   0   1     5     6
30        Maserati Bora  15.0    8  301.0  335  ...  14.60   0   1     5     8
31           Volvo 142E  21.4    4  121.0  109  ...  18.60   1   1     4     2

[32 rows x 12 columns]
\end{verbatim}

This just prints out the data, but then it's lost. To use this data, we have to give it a name, so it's stored in Python's memory

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/mtcars.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
One of the big differences between a spreadsheet program and a programming language from the data science perspective is that you have to load data into the programming language. It's not ``just there'' like Excel. This is a good thing, since it allows the common functionality of the programming language to work across multiple data sets, and also keeps the original data set pristine. Excel users can run into problems and \href{https://nature.berkeley.edu/garbelottoat/?p=1488}{corrupt their data} if they are not careful.
\end{quote}

If we wanted to write this data set back out into an Excel file, say, we could do

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.to_excel(}\StringTok{'data/mtcars.xlsx'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
You may get an error if you don't have the \texttt{openpyxl} package installed. You can easily install it from the Anaconda prompt using \texttt{conda\ install\ openpyxl} and following the prompts.
\end{quote}

\hypertarget{exploring-a-data-set}{%
\section{Exploring a data set}\label{exploring-a-data-set}}

We would like to get some idea about this data set. There are a bunch of functions linked to the \texttt{DataFrame} object that help us in this. First we will use \texttt{head} to see the first 8 rows of this data set

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.head(}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                make   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb
0          Mazda RX4  21.0    6  160.0  110  ...  16.46   0   1     4     4
1      Mazda RX4 Wag  21.0    6  160.0  110  ...  17.02   0   1     4     4
2         Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1
3     Hornet 4 Drive  21.4    6  258.0  110  ...  19.44   1   0     3     1
4  Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0   0     3     2
5            Valiant  18.1    6  225.0  105  ...  20.22   1   0     3     1
6         Duster 360  14.3    8  360.0  245  ...  15.84   0   0     3     4
7          Merc 240D  24.4    4  146.7   62  ...  20.00   1   0     4     2

[8 rows x 12 columns]
\end{verbatim}

This is our first look into this data. We notice a few things. Each column has a name, and each row has an \emph{index}, starting at 0.

\begin{quote}
If you're interested in the last N rows, there is a corresponding \texttt{tail} function
\end{quote}

Let's look at the data types of each of the columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.dtypes}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
make     object
mpg     float64
cyl       int64
disp    float64
hp        int64
drat    float64
wt      float64
qsec    float64
vs        int64
am        int64
gear      int64
carb      int64
dtype: object
\end{verbatim}

This tells us that some of the variables, like \texttt{mpg} and \texttt{disp}, are floating point (decimal) numbers, several are integers, and \texttt{make} is an ``object''. The \texttt{dtypes} function borrows from \texttt{numpy}, where there isn't really a type for character or categorical variables. So most often, when you see ``object'' in the output of \texttt{dtypes}, you think it's a character or categorical variable.

We can also look at the data structure in a bit more detail.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 32 entries, 0 to 31
Data columns (total 12 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   make    32 non-null     object 
 1   mpg     32 non-null     float64
 2   cyl     32 non-null     int64  
 3   disp    32 non-null     float64
 4   hp      32 non-null     int64  
 5   drat    32 non-null     float64
 6   wt      32 non-null     float64
 7   qsec    32 non-null     float64
 8   vs      32 non-null     int64  
 9   am      32 non-null     int64  
 10  gear    32 non-null     int64  
 11  carb    32 non-null     int64  
dtypes: float64(5), int64(6), object(1)
memory usage: 3.1+ KB
\end{verbatim}

This tells us that this is indeed a \texttt{DataFrame}, wth 12 columns, each with 32 valid observations. Each row has an index value ranging from 0 to 11. We also get the approximate size of this object in memory.

You can also quickly find the number of rows and columns of a data set by using \texttt{shape}, which is borrowed from numpy.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(32, 12)
\end{verbatim}

More generally, we can get a summary of each variable using the \texttt{describe} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.describe()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             mpg        cyl        disp  ...         am       gear     carb
count  32.000000  32.000000   32.000000  ...  32.000000  32.000000  32.0000
mean   20.090625   6.187500  230.721875  ...   0.406250   3.687500   2.8125
std     6.026948   1.785922  123.938694  ...   0.498991   0.737804   1.6152
min    10.400000   4.000000   71.100000  ...   0.000000   3.000000   1.0000
25%    15.425000   4.000000  120.825000  ...   0.000000   3.000000   2.0000
50%    19.200000   6.000000  196.300000  ...   0.000000   4.000000   2.0000
75%    22.800000   8.000000  326.000000  ...   1.000000   4.000000   4.0000
max    33.900000   8.000000  472.000000  ...   1.000000   5.000000   8.0000

[8 rows x 11 columns]
\end{verbatim}

These are usually the first steps in exploring the data.

\hypertarget{data-structures-and-types}{%
\section{Data structures and types}\label{data-structures-and-types}}

pandas has two main data types: \texttt{Series} and \texttt{DataFrame}. These are analogous to vectors and matrices, in that a \texttt{Series} is 1-dimensional while a \texttt{DataFrame} is 2-dimensional.

\hypertarget{pandas.series}{%
\subsection{pandas.Series}\label{pandas.series}}

The \texttt{Series} object holds data from a single input variable, and is required, much like numpy arrays, to be homogeneous in type. You can create \texttt{Series} objects from lists or numpy arrays quite easily

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,np.nan, }\DecValTok{9}\NormalTok{, }\DecValTok{13}\NormalTok{])}
\NormalTok{s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0     1.0
1     3.0
2     5.0
3     NaN
4     9.0
5    13.0
dtype: float64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2 }\OperatorTok{=}\NormalTok{ pd.Series(np.arange(}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{))}
\NormalTok{s2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0      1
1      2
2      3
3      4
4      5
5      6
6      7
7      8
8      9
9     10
10    11
11    12
12    13
13    14
14    15
15    16
16    17
17    18
18    19
dtype: int64
\end{verbatim}

You can access elements of a \texttt{Series} much like a \texttt{dict}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2[}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
5
\end{verbatim}

There is no requirement that the index of a \texttt{Series} has to be numeric. It can be any kind of scalar object

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3 }\OperatorTok{=}\NormalTok{ pd.Series(np.random.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{5}\NormalTok{,)), index }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{,}\StringTok{'e'}\NormalTok{])}
\NormalTok{s3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    1.093475
b    0.418402
c    0.573609
d   -0.305674
e    1.415458
dtype: float64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3[}\StringTok{'d'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-0.3056742348547295
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3[}\StringTok{'a'}\NormalTok{:}\StringTok{'d'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    1.093475
b    0.418402
c    0.573609
d   -0.305674
dtype: float64
\end{verbatim}

Well, slicing worked, but it gave us something different than expected. It gave us both the start \textbf{and} end of the slice, which is unlike what we've encountered so far!!

It turns out that in \texttt{pandas}, slicing by index actually does this. It is a discrepancy from \texttt{numpy} and Python in general that we have to be careful about.

You can extract the actual values into a numpy array

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3.to_numpy()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([ 1.09347482,  0.418402  ,  0.5736094 , -0.30567423,  1.41545834])
\end{verbatim}

In fact, you'll see that much of \texttt{pandas}' structures are build on top of \texttt{numpy} arrays. This is a good thing, since you can take advantage of the powerful numpy functions that are built for fast, efficient scientific computing.

Making the point about slicing again,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3.to_numpy()[}\DecValTok{0}\NormalTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([1.09347482, 0.418402  , 0.5736094 ])
\end{verbatim}

This is different from index-based slicing done earlier.

\hypertarget{pandas.dataframe}{%
\subsection{pandas.DataFrame}\label{pandas.dataframe}}

The \texttt{DataFrame} object holds a rectangular data set. Each column of a \texttt{DataFrame} is a \texttt{Series} object. This means that each column of a \texttt{DataFrame} must be comprised of data of the same type, but different columns can hold data of different types. This structure is extremely useful in practical data science. The invention of this structure was, in my opinion, transformative in making Python an effective data science tool.

\hypertarget{creating-a-dataframe}{%
\subsubsection{Creating a DataFrame}\label{creating-a-dataframe}}

The \texttt{DataFrame} can be created by importing data, as we saw in the previous section. It can also be created by a few methods within Python.

First, it can be created from a 2-dimensional \texttt{numpy} array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{25}\NormalTok{)}
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)))}
\NormalTok{d1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0  0.228273  1.026890 -0.839585 -0.591182 -0.956888
1 -0.222326 -0.619915  1.837905 -2.053231  0.868583
2 -0.920734 -0.232312  2.152957 -1.334661  0.076380
3 -1.246089  1.202272 -1.049942  1.056610 -0.419678
\end{verbatim}

You will notice that it creates default column names, that are merely the column number, starting from 0. We can also create the column names and row index (similar to the \texttt{Series} index we saw earlier) directly during creation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)), }
\NormalTok{                  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'A'}\NormalTok{,}\StringTok{'B'}\NormalTok{,}\StringTok{'C'}\NormalTok{,}\StringTok{'D'}\NormalTok{,}\StringTok{'E'}\NormalTok{], }
\NormalTok{                  index }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{])}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          A         B         C         D         E
a  2.294842 -2.594487  2.822756  0.680889 -1.577693
b -1.976254  0.533340 -0.290870 -0.513520  1.982626
c  0.226001 -1.839905  1.607671  0.388292  0.399732
d  0.405477  0.217002 -0.633439  0.246622 -1.939546
\end{verbatim}

\begin{quote}
We could also create a \texttt{DataFrame} from a list of lists, as long as things line up, just as we showed for \texttt{numpy} arrays. However, to me, other ways, including the \texttt{dict} method below, make more sense.
\end{quote}

We can change the column names (which can be extracted and replaced with the \texttt{columns} attribute) and the index values (using the \texttt{index} attribute).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.columns}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Index(['A', 'B', 'C', 'D', 'E'], dtype='object')
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.columns }\OperatorTok{=}\NormalTok{ pd.Index([}\StringTok{'V'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{)]) }\CommentTok{# Index creates the right objects for both column names and row names, which can be extracted and changed with the `index` attribute}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         V1        V2        V3        V4        V5
a  2.294842 -2.594487  2.822756  0.680889 -1.577693
b -1.976254  0.533340 -0.290870 -0.513520  1.982626
c  0.226001 -1.839905  1.607671  0.388292  0.399732
d  0.405477  0.217002 -0.633439  0.246622 -1.939546
\end{verbatim}

\textbf{Exercise:} Can you explain what I did in the list comprehension above? The key points are understanding \texttt{str} and how I constructed the \texttt{range}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.index }\OperatorTok{=}\NormalTok{ [}\StringTok{'o1'}\NormalTok{,}\StringTok{'o2'}\NormalTok{,}\StringTok{'o3'}\NormalTok{,}\StringTok{'o4'}\NormalTok{]}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          V1        V2        V3        V4        V5
o1  2.294842 -2.594487  2.822756  0.680889 -1.577693
o2 -1.976254  0.533340 -0.290870 -0.513520  1.982626
o3  0.226001 -1.839905  1.607671  0.388292  0.399732
o4  0.405477  0.217002 -0.633439  0.246622 -1.939546
\end{verbatim}

You can also extract data from a homogeneous \texttt{DataFrame} to a \texttt{numpy} array

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d1.to_numpy()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[ 0.22827309,  1.0268903 , -0.83958485, -0.59118152, -0.9568883 ],
       [-0.22232569, -0.61991511,  1.83790458, -2.05323076,  0.86858305],
       [-0.92073444, -0.23231186,  2.1529569 , -1.33466147,  0.07637965],
       [-1.24608928,  1.20227231, -1.04994158,  1.05661011, -0.41967767]])
\end{verbatim}

\begin{quote}
It turns out that you can use \texttt{to\_numpy} for a non-homogeneous \texttt{DataFrame} as well. \texttt{numpy} just makes it homogeneous by assigning each column the data type \texttt{object}. This also limits what you can do in \texttt{numpy} with the array and may require changing data types using the \href{https://numpy.org/devdocs/reference/generated/numpy.ndarray.astype.html}{\texttt{astype} function}. There is some more detail about the \texttt{object} data type in the Python Tools for Data Science (\href{01_python_tools_ds.ipynb\#object}{notebook}, \href{01_python_tools_ds.pdf}{PDF}) document.
\end{quote}

The other easy way to create a \texttt{DataFrame} is from a \texttt{dict} object, where each component object is either a list or a numpy array, and is homogeneous in type. One exception is if a component is of size 1; then it is repeated to meet the needs of the \texttt{DataFrame}'s dimensions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{'A'}\NormalTok{:}\FloatTok{3.}\NormalTok{,}
    \StringTok{'B'}\NormalTok{:rng.random_sample(}\DecValTok{5}\NormalTok{),}
    \StringTok{'C'}\NormalTok{: pd.Timestamp(}\StringTok{'20200512'}\NormalTok{),}
    \StringTok{'D'}\NormalTok{: np.array([}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{5}\NormalTok{),}
    \StringTok{'E'}\NormalTok{: pd.Categorical([}\StringTok{'yes'}\NormalTok{,}\StringTok{'no'}\NormalTok{,}\StringTok{'no'}\NormalTok{,}\StringTok{'yes'}\NormalTok{,}\StringTok{'no'}\NormalTok{]),}
    \StringTok{'F'}\NormalTok{: }\StringTok{'NIH'}\NormalTok{\})}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A         B          C  D    E    F
0  3.0  0.958092 2020-05-12  6  yes  NIH
1  3.0  0.883201 2020-05-12  6   no  NIH
2  3.0  0.295432 2020-05-12  6   no  NIH
3  3.0  0.512376 2020-05-12  6  yes  NIH
4  3.0  0.088702 2020-05-12  6   no  NIH
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5 entries, 0 to 4
Data columns (total 6 columns):
 #   Column  Non-Null Count  Dtype         
---  ------  --------------  -----         
 0   A       5 non-null      float64       
 1   B       5 non-null      float64       
 2   C       5 non-null      datetime64[ns]
 3   D       5 non-null      int64         
 4   E       5 non-null      category      
 5   F       5 non-null      object        
dtypes: category(1), datetime64[ns](1), float64(2), int64(1), object(1)
memory usage: 429.0+ bytes
\end{verbatim}

We note that C is a date object, E is a category object, and F is a text/string object. pandas has excellent time series capabilities (having origins in FinTech), and the \texttt{TimeStamp} function creates datetime objects which can be queried and manipulated in Python. We'll describe category data in the next section.

You can also create a \texttt{DataFrame} where each column is composed of composite objects, like lists and dicts, as well. This might have limited value in some settings, but may be useful in others. In particular, this allows capabilities like the \href{https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html}{\emph{list-column} construct in R tibbles}. For example,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.DataFrame(\{}\StringTok{'list'}\NormalTok{ :[[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{]],}
             \StringTok{'tuple'}\NormalTok{ : [(}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{), (}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{), (}\StringTok{'e'}\NormalTok{,}\StringTok{'f'}\NormalTok{)],}
              \StringTok{'set'}\NormalTok{ : [\{}\StringTok{'A'}\NormalTok{,}\StringTok{'B'}\NormalTok{,}\StringTok{'C'}\NormalTok{\}, \{}\StringTok{'D'}\NormalTok{,}\StringTok{'E'}\NormalTok{\}, \{}\StringTok{'F'}\NormalTok{\}], }
            \StringTok{'dicts'}\NormalTok{ : [\{}\StringTok{'A'}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]\}, \{}\StringTok{'B'}\NormalTok{:[}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{]\}, \{}\StringTok{'C'}\NormalTok{: [}\DecValTok{3}\NormalTok{,}\DecValTok{9}\NormalTok{]\}]\})}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     list   tuple        set             dicts
0  [1, 2]  (a, b)  {B, A, C}  {'A': [1, 2, 3]}
1  [3, 4]  (c, d)     {E, D}  {'B': [5, 6, 8]}
2  [5, 6]  (e, f)        {F}     {'C': [3, 9]}
\end{verbatim}

\hypertarget{working-with-a-dataframe}{%
\subsubsection{Working with a DataFrame}\label{working-with-a-dataframe}}

You can extract particular columns of a \texttt{DataFrame} by name

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{'E'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    yes
1     no
2     no
3    yes
4     no
Name: E, dtype: category
Categories (2, object): [no, yes]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{'B'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    0.958092
1    0.883201
2    0.295432
3    0.512376
4    0.088702
Name: B, dtype: float64
\end{verbatim}

\begin{quote}
There is also a shortcut for accessing single columns, using Python's dot (\texttt{.}) notation.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    0.958092
1    0.883201
2    0.295432
3    0.512376
4    0.088702
Name: B, dtype: float64
\end{verbatim}

\begin{quote}
This notation can be more convenient if we need to perform operations on a single column. If we want to extract multiple columns, this notation will not work. Also, if we want to create new columns or replace existing columns, we need to use the array notation with the column name in quotes.
\end{quote}

Let's look at slicing a \texttt{DataFrame}

\hypertarget{extracting-rows-and-columns}{%
\subsubsection{Extracting rows and columns}\label{extracting-rows-and-columns}}

There are two extractor functions in \texttt{pandas}:

\begin{itemize}
\tightlist
\item
  \texttt{loc} extracts by label (index label, column label, slice of labels, etc.
\item
  \texttt{iloc} extracts by index (integers, slice objects, etc.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, (}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{)), }
\NormalTok{                  index }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{,}\StringTok{'e'}\NormalTok{],}
\NormalTok{                  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'one'}\NormalTok{,}\StringTok{'two'}\NormalTok{,}\StringTok{'three'}\NormalTok{,}\StringTok{'four'}\NormalTok{])}
\NormalTok{df2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
e    6    7      8     7
\end{verbatim}

First, let's see what naively slicing this \texttt{DataFrame} does.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\StringTok{'one'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    5
b    9
c    8
d    5
e    6
Name: one, dtype: int64
\end{verbatim}

Ok, that works. It grabs one column from the dataset. How about the dot notation?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    5
b    9
c    8
d    5
e    6
Name: one, dtype: int64
\end{verbatim}

Let's see what this produces.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(df2.one)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.series.Series'>
\end{verbatim}

So this is a series, so we can potentially do slicing of this series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[}\StringTok{'b'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[}\StringTok{'b'}\NormalTok{:}\StringTok{'d'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
b    9
c    8
d    5
Name: one, dtype: int64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    5
b    9
c    8
Name: one, dtype: int64
\end{verbatim}

Ok, so we have all the \texttt{Series} slicing available. The problem here is in semantics, in that we are grabbing one column and then slicing the rows. That doesn't quite work with our sense that a \texttt{DataFrame} is a rectangle with rows and columns, and we tend to think of rows, then columns.

Let's see if we can do column slicing with this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[:}\StringTok{'two'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
e    6    7      8     7
\end{verbatim}

That's not what we want, of course. It's giving back the entire data frame. We'll come back to this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[[}\StringTok{'one'}\NormalTok{,}\StringTok{'three'}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  three
a    5      2
b    9      0
c    8      3
d    5      7
e    6      8
\end{verbatim}

That works correctly though. We can give a list of column names. Ok.

How about row slices?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#df2['a'] # Doesn't work}
\NormalTok{df2[}\StringTok{'a'}\NormalTok{:}\StringTok{'c'}\NormalTok{] }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
\end{verbatim}

Ok, that works. It slices rows, but includes the largest index, like a \texttt{Series} but unlike \texttt{numpy} arrays.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\DecValTok{0}\NormalTok{:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
\end{verbatim}

Slices by location work too, but use the \texttt{numpy} slicing rules.

This entire extraction method becomes confusing. Let's simplify things for this, and then move on to more consistent ways to extract elements of a \texttt{DataFrame}. Let's agree on two things. If we're going the direct extraction route,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We will extract single columns of a \texttt{DataFrame} with \texttt{{[}{]}} or \texttt{.}, i.e., \texttt{df2{[}\textquotesingle{}one\textquotesingle{}{]}} or \texttt{df2.one}
\item
  We will extract slices of rows of a \texttt{DataFrame} using location only, i.e., \texttt{df2{[}:3{]}}.
\end{enumerate}

For everything else, we'll use two functions, \texttt{loc} and \texttt{iloc}.

\begin{itemize}
\tightlist
\item
  \texttt{loc} extracts elements like a matrix, using index and columns
\item
  \texttt{iloc} extracts elements like a matrix, using location
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[:,}\StringTok{'one'}\NormalTok{:}\StringTok{'three'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three
a    5    3      2
b    9    3      0
c    8    4      3
d    5    2      7
e    6    7      8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[}\StringTok{'a'}\NormalTok{:}\StringTok{'d'}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[}\StringTok{'b'}\NormalTok{, }\StringTok{'three'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0
\end{verbatim}

So \texttt{loc} works just like a matrix, but with \texttt{pandas} slicing rules (include largest index)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[:,}\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   two  three  four
a    3      2     8
b    3      0     5
c    4      3     3
d    2      7     1
e    7      8     7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
b    9    3      0     5
c    8    4      3     3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   two  three  four
b    3      0     5
c    4      3     3
\end{verbatim}

\texttt{iloc} slices like a matrix, but uses \texttt{numpy} slicing conventions (does \textbf{not} include highest index)

If we want to extract a single element from a dataset, there are two functions available, \texttt{iat} and \texttt{at}, with behavior corresponding to \texttt{iloc} and \texttt{loc}, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iat[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.at[}\StringTok{'b'}\NormalTok{,}\StringTok{'three'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0
\end{verbatim}

\hypertarget{boolean-selection}{%
\subsubsection{Boolean selection}\label{boolean-selection}}

We can also use tests to extract data from a \texttt{DataFrame}. For example, we can extract only rows where column labeled \texttt{one} is greater than 3.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[df2.one }\OperatorTok{>} \DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
e    6    7      8     7
\end{verbatim}

We can also do composite tests. Here we ask for rows where \texttt{one} is greater than 3 and \texttt{three} is less than 9

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[(df2.one }\OperatorTok{>} \DecValTok{3}\NormalTok{) }\OperatorTok{&}\NormalTok{ (df2.three }\OperatorTok{<} \DecValTok{9}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
e    6    7      8     7
\end{verbatim}

\hypertarget{query}{%
\subsubsection{\texorpdfstring{\texttt{query}}{query}}\label{query}}

\texttt{DataFrame}'s have a \texttt{query} method allowing selection using a Python expression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OperatorTok{=} \DecValTok{10}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.rand(n, }\DecValTok{3}\NormalTok{), columns }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\StringTok{'abc'}\NormalTok{))}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          a         b         c
0  0.228986  0.643473  0.625953
1  0.552219  0.924672  0.064286
2  0.306005  0.344830  0.037890
3  0.879955  0.243659  0.721381
4  0.027672  0.019287  0.955531
5  0.045356  0.356428  0.038147
6  0.412487  0.658460  0.005777
7  0.092048  0.765786  0.904160
8  0.630849  0.061601  0.081946
9  0.796370  0.026373  0.874386
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[(df.a }\OperatorTok{<}\NormalTok{ df.b) }\OperatorTok{&}\NormalTok{ (df.b }\OperatorTok{<}\NormalTok{ df.c)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          a         b        c
7  0.092048  0.765786  0.90416
\end{verbatim}

We can equivalently write this query as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.query(}\StringTok{'(a < b) & (b < c)'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          a         b        c
7  0.092048  0.765786  0.90416
\end{verbatim}

\hypertarget{replacing-values-in-a-dataframe}{%
\subsubsection{Replacing values in a DataFrame}\label{replacing-values-in-a-dataframe}}

We can replace values within a DataFrame either by position or using a query.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    5    3      2     8
b    9    3      0     5
c    8    4      3     3
d    5    2      7     1
e    6    7      8     7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\StringTok{'one'}\NormalTok{] }\OperatorTok{=}\NormalTok{ [}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{]}
\NormalTok{df2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    2    3      2     8
b    5    3      0     5
c    2    4      3     3
d    5    2      7     1
e    2    7      8     7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iat[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{] }\OperatorTok{=} \DecValTok{-9} \CommentTok{# missing value}
\NormalTok{df2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    2    3      2     8
b    5    3      0     5
c    2    4      3    -9
d    5    2      7     1
e    2    7      8     7
\end{verbatim}

Let's now replace values using \texttt{replace} which is more flexible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.replace(}\DecValTok{0}\NormalTok{, }\DecValTok{-9}\NormalTok{) }\CommentTok{# replace 0 with -9}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    2    3      2     8
b    5    3     -9     5
c    2    4      3    -9
d    5    2      7     1
e    2    7      8     7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.replace(\{}\DecValTok{2}\NormalTok{: }\FloatTok{2.5}\NormalTok{, }\DecValTok{8}\NormalTok{: }\FloatTok{6.5}\NormalTok{\}) }\CommentTok{# multiple replacements}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a  2.5  3.0    2.5   6.5
b  5.0  3.0    0.0   5.0
c  2.5  4.0    3.0  -9.0
d  5.0  2.5    7.0   1.0
e  2.5  7.0    6.5   7.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.replace(\{}\StringTok{'one'}\NormalTok{: \{}\DecValTok{5}\NormalTok{: }\DecValTok{500}\NormalTok{\}, }\StringTok{'three'}\NormalTok{: \{}\DecValTok{0}\NormalTok{: }\DecValTok{-9}\NormalTok{, }\DecValTok{8}\NormalTok{: }\DecValTok{800}\NormalTok{\}\}) }
\CommentTok{# different replacements in different columns}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   one  two  three  four
a    2    3      2     8
b  500    3     -9     5
c    2    4      3    -9
d  500    2      7     1
e    2    7    800     7
\end{verbatim}

See more examples in the \href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html?highlight=replace\#pandas.DataFrame.replace}{documentation}

\hypertarget{categorical-data}{%
\subsection{Categorical data}\label{categorical-data}}

\texttt{pandas} provides a \texttt{Categorical} function and a \texttt{category} object type to Python. This type is analogous to the \texttt{factor} data type in R. It is meant to address categorical or discrete variables, where we need to use them in analyses. Categorical variables typically take on a small number of unique values, like gender, blood type, country of origin, race, etc.

You can create categorical \texttt{Series} in a couple of ways:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{], dtype}\OperatorTok{=}\StringTok{'category'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{'A'}\NormalTok{:}\FloatTok{3.}\NormalTok{,}
    \StringTok{'B'}\NormalTok{:rng.random_sample(}\DecValTok{5}\NormalTok{),}
    \StringTok{'C'}\NormalTok{: pd.Timestamp(}\StringTok{'20200512'}\NormalTok{),}
    \StringTok{'D'}\NormalTok{: np.array([}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{5}\NormalTok{),}
    \StringTok{'E'}\NormalTok{: pd.Categorical([}\StringTok{'yes'}\NormalTok{,}\StringTok{'no'}\NormalTok{,}\StringTok{'no'}\NormalTok{,}\StringTok{'yes'}\NormalTok{,}\StringTok{'no'}\NormalTok{]),}
    \StringTok{'F'}\NormalTok{: }\StringTok{'NIH'}\NormalTok{\})}
\NormalTok{df[}\StringTok{'F'}\NormalTok{].astype(}\StringTok{'category'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    NIH
1    NIH
2    NIH
3    NIH
4    NIH
Name: F, dtype: category
Categories (1, object): [NIH]
\end{verbatim}

You can also create \texttt{DataFrame}'s where each column is categorical

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{'A'}\NormalTok{: }\BuiltInTok{list}\NormalTok{(}\StringTok{'abcd'}\NormalTok{), }\StringTok{'B'}\NormalTok{: }\BuiltInTok{list}\NormalTok{(}\StringTok{'bdca'}\NormalTok{)\})}
\NormalTok{df_cat }\OperatorTok{=}\NormalTok{ df.astype(}\StringTok{'category'}\NormalTok{)}
\NormalTok{df_cat.dtypes}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
A    category
B    category
dtype: object
\end{verbatim}

You can explore categorical data in a variety of ways

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_cat[}\StringTok{'A'}\NormalTok{].describe()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
count     4
unique    4
top       d
freq      1
Name: A, dtype: object
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{'A'}\NormalTok{].value_counts()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
d    1
b    1
a    1
c    1
Name: A, dtype: int64
\end{verbatim}

One issue with categories is that, if a particular level of a category is not seen before, it can create an error. So you can pre-specify the categories you expect

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_cat[}\StringTok{'B'}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.Categorical(}\BuiltInTok{list}\NormalTok{(}\StringTok{'aabb'}\NormalTok{), categories }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{])}
\NormalTok{df_cat[}\StringTok{'B'}\NormalTok{].value_counts()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
b    2
a    2
d    0
c    0
Name: B, dtype: int64
\end{verbatim}

\hypertarget{re-organizing-categories}{%
\subsubsection{Re-organizing categories}\label{re-organizing-categories}}

In categorical data, there is often the concept of a ``first'' or ``reference'' category, and an ordering of categories. This tends to be important in both visualization as well as in regression modeling. Both aspects of a category can be addressed using the \texttt{reorder\_categories} function.

In our earlier example, we can see that the \texttt{A} variable has 4 categories, with the ``first'' category being ``a''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_cat.A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    a
1    b
2    c
3    d
Name: A, dtype: category
Categories (4, object): [a, b, c, d]
\end{verbatim}

Suppose we want to change this ordering to the reverse ordering, where
``d'' is the ``first'' category, and then it goes in reverse order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_cat[}\StringTok{'A'}\NormalTok{] }\OperatorTok{=}\NormalTok{ df_cat.A.cat.reorder_categories([}\StringTok{'d'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'a'}\NormalTok{])}
\NormalTok{df_cat.A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    a
1    b
2    c
3    d
Name: A, dtype: category
Categories (4, object): [d, c, b, a]
\end{verbatim}

\hypertarget{missing-data}{%
\subsection{Missing data}\label{missing-data}}

Both \texttt{numpy} and \texttt{pandas} allow for missing values, which are a reality in data science. The missing values are coded as \texttt{np.nan}. Let's create some data and force some missing values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{), index }\OperatorTok{=}\NormalTok{ [}\StringTok{'a'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'e'}\NormalTok{, }\StringTok{'f'}\NormalTok{,}\StringTok{'g'}\NormalTok{], columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'one'}\NormalTok{,}\StringTok{'two'}\NormalTok{,}\StringTok{'three'}\NormalTok{]) }\CommentTok{# pre-specify index and column names}
\NormalTok{df[}\StringTok{'four'}\NormalTok{] }\OperatorTok{=} \DecValTok{20} \CommentTok{# add a column named "four", which will all be 20}
\NormalTok{df[}\StringTok{'five'}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{'one'}\NormalTok{] }\OperatorTok{>} \DecValTok{0}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        one       two     three  four   five
a -0.570970  0.772226  0.650859    20  False
c  0.304783 -0.661686 -0.010700    20   True
e  1.552048  1.371941 -1.036313    20   True
f  0.260336 -0.878120 -0.958219    20   True
g  1.215470 -1.761208 -2.179038    20   True
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 }\OperatorTok{=}\NormalTok{ df.reindex([}\StringTok{'a'}\NormalTok{,}\StringTok{'b'}\NormalTok{,}\StringTok{'c'}\NormalTok{,}\StringTok{'d'}\NormalTok{,}\StringTok{'e'}\NormalTok{,}\StringTok{'f'}\NormalTok{,}\StringTok{'g'}\NormalTok{])}
\NormalTok{df2.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{'background-color:yellow'}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{'b'}\NormalTok{,}\StringTok{'d'}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.io.formats.style.Styler object at 0x11d01ea30>
\end{verbatim}

The code above is creating new blank rows based on the new index values, some of which are present in the existing data and some of which are missing.

We can create \emph{masks} of the data indicating where missing values reside in a data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.isna()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     one    two  three   four   five
a  False  False  False  False  False
b   True   True   True   True   True
c  False  False  False  False  False
d   True   True   True   True   True
e  False  False  False  False  False
f  False  False  False  False  False
g  False  False  False  False  False
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\StringTok{'one'}\NormalTok{].notna()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a     True
b    False
c     True
d    False
e     True
f     True
g     True
Name: one, dtype: bool
\end{verbatim}

We can obtain complete data by dropping any row that has any missing value. This is called \emph{complete case analysis}, and you should be very careful using it. It is \emph{only} valid if we belive that the missingness is missing at random, and not related to some characteristic of the data or the data gathering process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.dropna(how}\OperatorTok{=}\StringTok{'any'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        one       two     three  four   five
a -0.570970  0.772226  0.650859  20.0  False
c  0.304783 -0.661686 -0.010700  20.0   True
e  1.552048  1.371941 -1.036313  20.0   True
f  0.260336 -0.878120 -0.958219  20.0   True
g  1.215470 -1.761208 -2.179038  20.0   True
\end{verbatim}

You can also fill in, or \emph{impute}, missing values. This can be done using a single value..

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out1 }\OperatorTok{=}\NormalTok{ df2.fillna(value }\OperatorTok{=} \DecValTok{5}\NormalTok{)}

\NormalTok{out1.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{'background-color:yellow'}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{'b'}\NormalTok{,}\StringTok{'d'}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.io.formats.style.Styler object at 0x11cf6c490>
\end{verbatim}

or a computed value like a column mean

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df3 }\OperatorTok{=}\NormalTok{ df2.copy()}
\NormalTok{df3 }\OperatorTok{=}\NormalTok{ df3.select_dtypes(exclude}\OperatorTok{=}\NormalTok{[}\BuiltInTok{object}\NormalTok{])   }\CommentTok{# remove non-numeric columns}
\NormalTok{out2 }\OperatorTok{=}\NormalTok{ df3.fillna(df3.mean())  }\CommentTok{# df3.mean() computes column-wise means}

\NormalTok{out2.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{'background-color:yellow'}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{'b'}\NormalTok{,}\StringTok{'d'}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.io.formats.style.Styler object at 0x11cf5feb0>
\end{verbatim}

You can also impute based on the principle of \emph{last value carried forward} which is common in time series. This means that the missing value is imputed with the previous recorded value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out3 }\OperatorTok{=}\NormalTok{ df2.fillna(method }\OperatorTok{=} \StringTok{'ffill'}\NormalTok{) }\CommentTok{# Fill forward}

\NormalTok{out3.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{'background-color:yellow'}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{'b'}\NormalTok{,}\StringTok{'d'}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.io.formats.style.Styler object at 0x12e2900a0>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out4 }\OperatorTok{=}\NormalTok{ df2.fillna(method }\OperatorTok{=} \StringTok{'bfill'}\NormalTok{) }\CommentTok{# Fill backward}

\NormalTok{out4.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{'background-color:yellow'}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{'b'}\NormalTok{,}\StringTok{'d'}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.io.formats.style.Styler object at 0x11cc19220>
\end{verbatim}

\hypertarget{data-transformation}{%
\section{Data transformation}\label{data-transformation}}

\hypertarget{arithmetic-operations}{%
\subsection{Arithmetic operations}\label{arithmetic-operations}}

If you have a \texttt{Series} or \texttt{DataFrame} that is all numeric, you can add or multiply single numbers to all the elements together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0 -1.027030  1.129586 -1.165263 -0.449381 -0.497638
1  0.623238  1.268891  0.653153  0.196225  0.692473
2  0.054955  0.984919 -0.491696  0.651569  0.143342
3 -0.143202 -0.142364  0.644854  0.632380  0.377440
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0  4.972970  7.129586  4.834737  5.550619  5.502362
1  6.623238  7.268891  6.653153  6.196225  6.692473
2  6.054955  6.984919  5.508304  6.651569  6.143342
3  5.856798  5.857636  6.644854  6.632380  6.377440
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*} \DecValTok{-10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           0          1          2         3         4
0  10.270298 -11.295858  11.652629  4.493806  4.976376
1  -6.232381 -12.688910  -6.531532 -1.962251 -6.924728
2  -0.549551  -9.849190   4.916965 -6.515694 -1.433416
3   1.432023   1.423638  -6.448540 -6.323803 -3.774401
\end{verbatim}

If you have two compatible (same dimension) numeric \texttt{DataFrame}s, you can add, subtract, multiply and divide elementwise

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{) }\OperatorTok{+} \DecValTok{4}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+}\NormalTok{ B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0  4.699883  4.400758  2.270430  4.950605  3.732538
1  4.178055  3.584381  6.130914  5.751293  4.875132
2  5.968319  4.146095  4.399237  5.001782  5.143214
3  2.346237  3.013034  3.686613  4.279198  5.429027
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*}\NormalTok{ B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0 -5.881710  3.695069 -4.003486 -2.426649 -2.105094
1  2.215498  2.938105  3.577817  1.090044  2.896378
2  0.324969  3.113503 -2.404855  2.834466  0.716690
3 -0.356493 -0.449215  1.961490  2.306176  1.906672
\end{verbatim}

If you have a \texttt{Series} with the same number of elements as the number of columns of a \texttt{DataFrame}, you can do arithmetic operations, with each element of the \texttt{Series} acting upon each column of the \texttt{DataFrame}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OperatorTok{=}\NormalTok{ pd.Series([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+}\NormalTok{ c)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0 -0.027030  3.129586  1.834737  3.550619  4.502362
1  1.623238  3.268891  3.653153  4.196225  5.692473
2  1.054955  2.984919  2.508304  4.651569  5.143342
3  0.856798  1.857636  3.644854  4.632380  5.377440
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*}\NormalTok{ c)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0 -1.027030  2.259172 -3.495789 -1.797522 -2.488188
1  0.623238  2.537782  1.959460  0.784900  3.462364
2  0.054955  1.969838 -1.475089  2.606278  0.716708
3 -0.143202 -0.284728  1.934562  2.529521  1.887201
\end{verbatim}

This idea can be used to standardize a dataset, i.e.~make each column have mean 0 and standard deviation 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{means }\OperatorTok{=}\NormalTok{ A.mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{stds }\OperatorTok{=}\NormalTok{ A.std(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}

\NormalTok{(A }\OperatorTok{-}\NormalTok{ means)}\OperatorTok{/}\NormalTok{stds}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          0         1         2         3         4
0 -1.320421  0.494639 -1.200017 -1.369886 -1.342262
1  1.089977  0.710423  0.828881 -0.119098  1.018922
2  0.259937  0.270550 -0.448485  0.763080 -0.070556
3 -0.029493 -1.475613  0.819621  0.725904  0.393896
\end{verbatim}

\hypertarget{concatenation-of-data-sets}{%
\subsection{Concatenation of data sets}\label{concatenation-of-data-sets}}

Let's create some example data sets

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1 }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{'A'}\NormalTok{: [}\StringTok{'a'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{'B'}\NormalTok{: [}\StringTok{'b'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{'C'}\NormalTok{: [}\StringTok{'c'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{'D'}\NormalTok{: [}\StringTok{'d'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)]\})}

\NormalTok{df2 }\OperatorTok{=}\NormalTok{  pd.DataFrame(\{}\StringTok{'A'}\NormalTok{: [}\StringTok{'a'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{'B'}\NormalTok{: [}\StringTok{'b'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{'C'}\NormalTok{: [}\StringTok{'c'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{'D'}\NormalTok{: [}\StringTok{'d'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)]\})}
\NormalTok{df3 }\OperatorTok{=}\NormalTok{  pd.DataFrame(\{}\StringTok{'A'}\NormalTok{: [}\StringTok{'a'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{'B'}\NormalTok{: [}\StringTok{'b'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{'C'}\NormalTok{: [}\StringTok{'c'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{'D'}\NormalTok{: [}\StringTok{'d'}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)]\})}
\end{Highlighting}
\end{Shaded}

We can concatenate these \texttt{DataFrame} objects by row

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{row_concatenate }\OperatorTok{=}\NormalTok{ pd.concat([df1, df2, df3])}
\BuiltInTok{print}\NormalTok{(row_concatenate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A    B    C    D
0   a0   b0   c0   d0
1   a1   b1   c1   d1
2   a2   b2   c2   d2
3   a3   b3   c3   d3
0   a4   b4   c4   d4
1   a5   b5   c5   d5
2   a6   b6   c6   d6
3   a7   b7   c7   d7
0   a8   b8   c8   d8
1   a9   b9   c9   d9
2  a10  b10  c10  d10
3  a11  b11  c11  d11
\end{verbatim}

This stacks the dataframes together. They are literally stacked, as is evidenced by the index values being repeated.

This same exercise can be done by the \texttt{append} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1.append(df2).append(df3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A    B    C    D
0   a0   b0   c0   d0
1   a1   b1   c1   d1
2   a2   b2   c2   d2
3   a3   b3   c3   d3
0   a4   b4   c4   d4
1   a5   b5   c5   d5
2   a6   b6   c6   d6
3   a7   b7   c7   d7
0   a8   b8   c8   d8
1   a9   b9   c9   d9
2  a10  b10  c10  d10
3  a11  b11  c11  d11
\end{verbatim}

Suppose we want to append a new row to \texttt{df1}. Lets create a new row.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_row }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{'n1'}\NormalTok{,}\StringTok{'n2'}\NormalTok{,}\StringTok{'n3'}\NormalTok{,}\StringTok{'n4'}\NormalTok{])}
\NormalTok{pd.concat([df1, new_row])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A    B    C    D    0
0   a0   b0   c0   d0  NaN
1   a1   b1   c1   d1  NaN
2   a2   b2   c2   d2  NaN
3   a3   b3   c3   d3  NaN
0  NaN  NaN  NaN  NaN   n1
1  NaN  NaN  NaN  NaN   n2
2  NaN  NaN  NaN  NaN   n3
3  NaN  NaN  NaN  NaN   n4
\end{verbatim}

That's a lot of missing values. The issue is that the we don't have column names in the \texttt{new\_row}, and the indices are the same, so pandas tries to append it my making a new column. The solution is to make it a \texttt{DataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_row }\OperatorTok{=}\NormalTok{ pd.DataFrame([[}\StringTok{'n1'}\NormalTok{,}\StringTok{'n2'}\NormalTok{,}\StringTok{'n3'}\NormalTok{,}\StringTok{'n4'}\NormalTok{]], columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'A'}\NormalTok{,}\StringTok{'B'}\NormalTok{,}\StringTok{'C'}\NormalTok{,}\StringTok{'D'}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(new_row)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    A   B   C   D
0  n1  n2  n3  n4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1, new_row])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    A   B   C   D
0  a0  b0  c0  d0
1  a1  b1  c1  d1
2  a2  b2  c2  d2
3  a3  b3  c3  d3
0  n1  n2  n3  n4
\end{verbatim}

or

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1.append(new_row)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    A   B   C   D
0  a0  b0  c0  d0
1  a1  b1  c1  d1
2  a2  b2  c2  d2
3  a3  b3  c3  d3
0  n1  n2  n3  n4
\end{verbatim}

\hypertarget{adding-columns}{%
\subsubsection{Adding columns}\label{adding-columns}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1,df2,df3], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    A   B   C   D   A   B   C   D    A    B    C    D
0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8
1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9
2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10
3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11
\end{verbatim}

The option \texttt{axis=1} ensures that concatenation happens by columns. The default value \texttt{axis\ =\ 0} concatenates by rows.

Let's play a little game. Let's change the column names of \texttt{df2} and \texttt{df3} so they are not the same as \texttt{df1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{]}
\NormalTok{df3.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'A'}\NormalTok{,}\StringTok{'D'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'H'}\NormalTok{]}
\NormalTok{pd.concat([df1,df2,df3])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A    B    C    D    E    F    G    H
0   a0   b0   c0   d0  NaN  NaN  NaN  NaN
1   a1   b1   c1   d1  NaN  NaN  NaN  NaN
2   a2   b2   c2   d2  NaN  NaN  NaN  NaN
3   a3   b3   c3   d3  NaN  NaN  NaN  NaN
0  NaN  NaN  NaN  NaN   a4   b4   c4   d4
1  NaN  NaN  NaN  NaN   a5   b5   c5   d5
2  NaN  NaN  NaN  NaN   a6   b6   c6   d6
3  NaN  NaN  NaN  NaN   a7   b7   c7   d7
0   a8  NaN  NaN   b8  NaN   c8  NaN   d8
1   a9  NaN  NaN   b9  NaN   c9  NaN   d9
2  a10  NaN  NaN  b10  NaN  c10  NaN  d10
3  a11  NaN  NaN  b11  NaN  c11  NaN  d11
\end{verbatim}

Now pandas ensures that all column names are represented in the new data frame, but with missing values where the row indices and column indices are mismatched. Some of this can be avoided by only joining on common columns. This is done using the \texttt{join} option ir \texttt{concat}. The default value is 'outer`, which is what you see. above

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1, df3], join }\OperatorTok{=} \StringTok{'inner'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     A    D
0   a0   d0
1   a1   d1
2   a2   d2
3   a3   d3
0   a8   b8
1   a9   b9
2  a10  b10
3  a11  b11
\end{verbatim}

You can do the same thing when joining by rows, using \texttt{axis\ =\ 0} and \texttt{join="inner"} to only join on rows with matching indices. Reminder that the indices are just labels and happen to be the row numbers by default.

\hypertarget{merging-data-sets}{%
\subsection{Merging data sets}\label{merging-data-sets}}

For this section we'll use a set of data from a survey, also used by Daniel Chen in ``Pandas for Everyone''

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{person }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/survey_person.csv'}\NormalTok{)}
\NormalTok{site }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/survey_site.csv'}\NormalTok{)}
\NormalTok{survey }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/survey_survey.csv'}\NormalTok{)}
\NormalTok{visited }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/survey_visited.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(person)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      ident   personal    family
0      dyer    William      Dyer
1        pb      Frank   Pabodie
2      lake   Anderson      Lake
3       roe  Valentina   Roerich
4  danforth      Frank  Danforth
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(site)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    name    lat    long
0   DR-1 -49.85 -128.57
1   DR-3 -47.15 -126.72
2  MSK-4 -48.87 -123.40
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(survey)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    taken person quant  reading
0     619   dyer   rad     9.82
1     619   dyer   sal     0.13
2     622   dyer   rad     7.80
3     622   dyer   sal     0.09
4     734     pb   rad     8.41
5     734   lake   sal     0.05
6     734     pb  temp   -21.50
7     735     pb   rad     7.22
8     735    NaN   sal     0.06
9     735    NaN  temp   -26.00
10    751     pb   rad     4.35
11    751     pb  temp   -18.50
12    751   lake   sal     0.10
13    752   lake   rad     2.19
14    752   lake   sal     0.09
15    752   lake  temp   -16.00
16    752    roe   sal    41.60
17    837   lake   rad     1.46
18    837   lake   sal     0.21
19    837    roe   sal    22.50
20    844    roe   rad    11.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(visited)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   ident   site       dated
0    619   DR-1  1927-02-08
1    622   DR-1  1927-02-10
2    734   DR-3  1939-01-07
3    735   DR-3  1930-01-12
4    751   DR-3  1930-02-26
5    752   DR-3         NaN
6    837  MSK-4  1932-01-14
7    844   DR-1  1932-03-22
\end{verbatim}

There are basically four kinds of joins:

\begin{longtable}[]{@{}llll@{}}
\toprule
pandas & R & SQL & Description\tabularnewline
\midrule
\endhead
left & left\_join & left outer & keep all rows on left\tabularnewline
right & right\_join & right outer & keep all rows on right\tabularnewline
outer & outer\_join & full outer & keep all rows from both\tabularnewline
inner & inner\_join & inner & keep only rows with common keys\tabularnewline
\bottomrule
\end{longtable}

\includegraphics{graphs/joins.png}

The terms \texttt{left} and \texttt{right} refer to which data set you call first and second respectively.

We start with an left join

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2v_merge }\OperatorTok{=}\NormalTok{ survey.merge(visited, left_on }\OperatorTok{=} \StringTok{'taken'}\NormalTok{,right_on }\OperatorTok{=} \StringTok{'ident'}\NormalTok{, how }\OperatorTok{=} \StringTok{'left'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(s2v_merge)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    taken person quant  reading  ident   site       dated
0     619   dyer   rad     9.82    619   DR-1  1927-02-08
1     619   dyer   sal     0.13    619   DR-1  1927-02-08
2     622   dyer   rad     7.80    622   DR-1  1927-02-10
3     622   dyer   sal     0.09    622   DR-1  1927-02-10
4     734     pb   rad     8.41    734   DR-3  1939-01-07
5     734   lake   sal     0.05    734   DR-3  1939-01-07
6     734     pb  temp   -21.50    734   DR-3  1939-01-07
7     735     pb   rad     7.22    735   DR-3  1930-01-12
8     735    NaN   sal     0.06    735   DR-3  1930-01-12
9     735    NaN  temp   -26.00    735   DR-3  1930-01-12
10    751     pb   rad     4.35    751   DR-3  1930-02-26
11    751     pb  temp   -18.50    751   DR-3  1930-02-26
12    751   lake   sal     0.10    751   DR-3  1930-02-26
13    752   lake   rad     2.19    752   DR-3         NaN
14    752   lake   sal     0.09    752   DR-3         NaN
15    752   lake  temp   -16.00    752   DR-3         NaN
16    752    roe   sal    41.60    752   DR-3         NaN
17    837   lake   rad     1.46    837  MSK-4  1932-01-14
18    837   lake   sal     0.21    837  MSK-4  1932-01-14
19    837    roe   sal    22.50    837  MSK-4  1932-01-14
20    844    roe   rad    11.25    844   DR-1  1932-03-22
\end{verbatim}

Here, the left dataset is \texttt{survey} and the right one is \texttt{visited}. Since we're doing a left join, we keed all the rows from \texttt{survey} and add columns from \texttt{visited}, matching on the common key, called ``taken'' in one dataset and ``ident'' in the other. Note that the rows of \texttt{visited} are repeated as needed to line up with all the rows with common ``taken'' values.

We can now add location information, where the common key is the site code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2v2loc_merge }\OperatorTok{=}\NormalTok{ s2v_merge.merge(site, how }\OperatorTok{=} \StringTok{'left'}\NormalTok{, left_on }\OperatorTok{=} \StringTok{'site'}\NormalTok{, right_on }\OperatorTok{=} \StringTok{'name'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(s2v2loc_merge)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    taken person quant  reading  ident   site       dated   name    lat    long
0     619   dyer   rad     9.82    619   DR-1  1927-02-08   DR-1 -49.85 -128.57
1     619   dyer   sal     0.13    619   DR-1  1927-02-08   DR-1 -49.85 -128.57
2     622   dyer   rad     7.80    622   DR-1  1927-02-10   DR-1 -49.85 -128.57
3     622   dyer   sal     0.09    622   DR-1  1927-02-10   DR-1 -49.85 -128.57
4     734     pb   rad     8.41    734   DR-3  1939-01-07   DR-3 -47.15 -126.72
5     734   lake   sal     0.05    734   DR-3  1939-01-07   DR-3 -47.15 -126.72
6     734     pb  temp   -21.50    734   DR-3  1939-01-07   DR-3 -47.15 -126.72
7     735     pb   rad     7.22    735   DR-3  1930-01-12   DR-3 -47.15 -126.72
8     735    NaN   sal     0.06    735   DR-3  1930-01-12   DR-3 -47.15 -126.72
9     735    NaN  temp   -26.00    735   DR-3  1930-01-12   DR-3 -47.15 -126.72
10    751     pb   rad     4.35    751   DR-3  1930-02-26   DR-3 -47.15 -126.72
11    751     pb  temp   -18.50    751   DR-3  1930-02-26   DR-3 -47.15 -126.72
12    751   lake   sal     0.10    751   DR-3  1930-02-26   DR-3 -47.15 -126.72
13    752   lake   rad     2.19    752   DR-3         NaN   DR-3 -47.15 -126.72
14    752   lake   sal     0.09    752   DR-3         NaN   DR-3 -47.15 -126.72
15    752   lake  temp   -16.00    752   DR-3         NaN   DR-3 -47.15 -126.72
16    752    roe   sal    41.60    752   DR-3         NaN   DR-3 -47.15 -126.72
17    837   lake   rad     1.46    837  MSK-4  1932-01-14  MSK-4 -48.87 -123.40
18    837   lake   sal     0.21    837  MSK-4  1932-01-14  MSK-4 -48.87 -123.40
19    837    roe   sal    22.50    837  MSK-4  1932-01-14  MSK-4 -48.87 -123.40
20    844    roe   rad    11.25    844   DR-1  1932-03-22   DR-1 -49.85 -128.57
\end{verbatim}

Lastly, we add the person information to this dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged }\OperatorTok{=}\NormalTok{ s2v2loc_merge.merge(person, how }\OperatorTok{=} \StringTok{'left'}\NormalTok{, left_on }\OperatorTok{=} \StringTok{'person'}\NormalTok{, right_on }\OperatorTok{=} \StringTok{'ident'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(merged.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   taken person quant  reading  ...    long ident_y personal   family
0    619   dyer   rad     9.82  ... -128.57    dyer  William     Dyer
1    619   dyer   sal     0.13  ... -128.57    dyer  William     Dyer
2    622   dyer   rad     7.80  ... -128.57    dyer  William     Dyer
3    622   dyer   sal     0.09  ... -128.57    dyer  William     Dyer
4    734     pb   rad     8.41  ... -126.72      pb    Frank  Pabodie

[5 rows x 13 columns]
\end{verbatim}

You can merge based on multiple columns as long as they match up.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ps }\OperatorTok{=}\NormalTok{ person.merge(survey, left_on }\OperatorTok{=} \StringTok{'ident'}\NormalTok{, right_on }\OperatorTok{=} \StringTok{'person'}\NormalTok{)}
\NormalTok{vs }\OperatorTok{=}\NormalTok{ visited.merge(survey, left_on }\OperatorTok{=} \StringTok{'ident'}\NormalTok{, right_on }\OperatorTok{=} \StringTok{'taken'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(ps)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   ident   personal   family  taken person quant  reading
0   dyer    William     Dyer    619   dyer   rad     9.82
1   dyer    William     Dyer    619   dyer   sal     0.13
2   dyer    William     Dyer    622   dyer   rad     7.80
3   dyer    William     Dyer    622   dyer   sal     0.09
4     pb      Frank  Pabodie    734     pb   rad     8.41
5     pb      Frank  Pabodie    734     pb  temp   -21.50
6     pb      Frank  Pabodie    735     pb   rad     7.22
7     pb      Frank  Pabodie    751     pb   rad     4.35
8     pb      Frank  Pabodie    751     pb  temp   -18.50
9   lake   Anderson     Lake    734   lake   sal     0.05
10  lake   Anderson     Lake    751   lake   sal     0.10
11  lake   Anderson     Lake    752   lake   rad     2.19
12  lake   Anderson     Lake    752   lake   sal     0.09
13  lake   Anderson     Lake    752   lake  temp   -16.00
14  lake   Anderson     Lake    837   lake   rad     1.46
15  lake   Anderson     Lake    837   lake   sal     0.21
16   roe  Valentina  Roerich    752    roe   sal    41.60
17   roe  Valentina  Roerich    837    roe   sal    22.50
18   roe  Valentina  Roerich    844    roe   rad    11.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(vs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    ident   site       dated  taken person quant  reading
0     619   DR-1  1927-02-08    619   dyer   rad     9.82
1     619   DR-1  1927-02-08    619   dyer   sal     0.13
2     622   DR-1  1927-02-10    622   dyer   rad     7.80
3     622   DR-1  1927-02-10    622   dyer   sal     0.09
4     734   DR-3  1939-01-07    734     pb   rad     8.41
5     734   DR-3  1939-01-07    734   lake   sal     0.05
6     734   DR-3  1939-01-07    734     pb  temp   -21.50
7     735   DR-3  1930-01-12    735     pb   rad     7.22
8     735   DR-3  1930-01-12    735    NaN   sal     0.06
9     735   DR-3  1930-01-12    735    NaN  temp   -26.00
10    751   DR-3  1930-02-26    751     pb   rad     4.35
11    751   DR-3  1930-02-26    751     pb  temp   -18.50
12    751   DR-3  1930-02-26    751   lake   sal     0.10
13    752   DR-3         NaN    752   lake   rad     2.19
14    752   DR-3         NaN    752   lake   sal     0.09
15    752   DR-3         NaN    752   lake  temp   -16.00
16    752   DR-3         NaN    752    roe   sal    41.60
17    837  MSK-4  1932-01-14    837   lake   rad     1.46
18    837  MSK-4  1932-01-14    837   lake   sal     0.21
19    837  MSK-4  1932-01-14    837    roe   sal    22.50
20    844   DR-1  1932-03-22    844    roe   rad    11.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ps_vs }\OperatorTok{=}\NormalTok{ ps.merge(vs, }
\NormalTok{                left_on }\OperatorTok{=}\NormalTok{ [}\StringTok{'ident'}\NormalTok{,}\StringTok{'taken'}\NormalTok{, }\StringTok{'quant'}\NormalTok{,}\StringTok{'reading'}\NormalTok{],}
\NormalTok{                right_on }\OperatorTok{=}\NormalTok{ [}\StringTok{'person'}\NormalTok{,}\StringTok{'ident'}\NormalTok{,}\StringTok{'quant'}\NormalTok{,}\StringTok{'reading'}\NormalTok{]) }\CommentTok{# The keys need to correspond}
\NormalTok{ps_vs.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  ident_x personal   family  taken_x  ...  site       dated  taken_y  person_y
0    dyer  William     Dyer      619  ...  DR-1  1927-02-08      619      dyer
1    dyer  William     Dyer      619  ...  DR-1  1927-02-08      619      dyer
2    dyer  William     Dyer      622  ...  DR-1  1927-02-10      622      dyer
3    dyer  William     Dyer      622  ...  DR-1  1927-02-10      622      dyer
4      pb    Frank  Pabodie      734  ...  DR-3  1939-01-07      734        pb

[5 rows x 12 columns]
\end{verbatim}

Note that since there are common column names, the merge appends \texttt{\_x} and \texttt{\_y} to denote which column came from the left and right, respectively.

\hypertarget{tidy-data-principles-and-reshaping-datasets}{%
\subsection{Tidy data principles and reshaping datasets}\label{tidy-data-principles-and-reshaping-datasets}}

The tidy data principle is a principle espoused by Dr.~Hadley Wickham, one of the foremost R developers. \href{http://vita.had.co.nz/papers/tidy-data.pdf}{Tidy data} is a structure for datasets to make them more easily analyzed on computers. The basic principles are

\begin{itemize}
\tightlist
\item
  Each row is an observation
\item
  Each column is a variable
\item
  Each type of observational unit forms a table
\end{itemize}

\begin{quote}
Tidy data is tidy in one way. Untidy data can be untidy in many ways
\end{quote}

Let's look at some examples.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ glob }\ImportTok{import}\NormalTok{ glob}
\NormalTok{filenames }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(glob(}\StringTok{'data/table*.csv'}\NormalTok{)) }\CommentTok{# find files matching pattern. I know there are 6 of them}
\NormalTok{table1, table2, table3, table4a, table4b, table5 }\OperatorTok{=}\NormalTok{ [pd.read_csv(f) }\ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ filenames] }\CommentTok{# Use a list comprehension}
\end{Highlighting}
\end{Shaded}

This code imports data from 6 files matching a pattern. Python allows multiple assignments on the left of the \texttt{=}, and as each dataset is imported, it gets assigned in order to the variables on the left. In the second line I sort the file names so that they match the order in which I'm storing them in the 3rd line. The function \texttt{glob} does pattern-matching of file names.

The following tables refer to the number of TB cases and population in Afghanistan, Brazil and China in 1999 and 2000

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country  year   cases  population
0  Afghanistan  1999     745    19987071
1  Afghanistan  2000    2666    20595360
2       Brazil  1999   37737   172006362
3       Brazil  2000   80488   174504898
4        China  1999  212258  1272915272
5        China  2000  213766  1280428583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        country  year        type       count
0   Afghanistan  1999       cases         745
1   Afghanistan  1999  population    19987071
2   Afghanistan  2000       cases        2666
3   Afghanistan  2000  population    20595360
4        Brazil  1999       cases       37737
5        Brazil  1999  population   172006362
6        Brazil  2000       cases       80488
7        Brazil  2000  population   174504898
8         China  1999       cases      212258
9         China  1999  population  1272915272
10        China  2000       cases      213766
11        China  2000  population  1280428583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country  year               rate
0  Afghanistan  1999       745/19987071
1  Afghanistan  2000      2666/20595360
2       Brazil  1999    37737/172006362
3       Brazil  2000    80488/174504898
4        China  1999  212258/1272915272
5        China  2000  213766/1280428583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table4a) }\CommentTok{# cases}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country    1999    2000
0  Afghanistan     745    2666
1       Brazil   37737   80488
2        China  212258  213766
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table4b) }\CommentTok{# population}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country        1999        2000
0  Afghanistan    19987071    20595360
1       Brazil   172006362   174504898
2        China  1272915272  1280428583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country  century  year               rate
0  Afghanistan       19    99       745/19987071
1  Afghanistan       20     0      2666/20595360
2       Brazil       19    99    37737/172006362
3       Brazil       20     0    80488/174504898
4        China       19    99  212258/1272915272
5        China       20     0  213766/1280428583
\end{verbatim}

\textbf{Exercise:} Describe why and why not each of these datasets are tidy.

\hypertarget{melting-unpivoting-data}{%
\subsection{Melting (unpivoting) data}\label{melting-unpivoting-data}}

Melting is the operation of collapsing multiple columns into 2 columns, where one column is formed by the old column names, and the other by the corresponding values. Some columns may be kept fixed and their data are repeated to maintain the interrelationships between the variables.

We'll start with loading some data on income and religion in the US from the Pew Research Center.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pew }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/pew.csv'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(pew.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             religion  <$10k  $10-20k  ...  $100-150k  >150k  Don't know/refused
0            Agnostic     27       34  ...        109     84                  96
1             Atheist     12       27  ...         59     74                  76
2            Buddhist     27       21  ...         39     53                  54
3            Catholic    418      617  ...        792    633                1489
4  Dont know/refused     15       14  ...         17     18                 116

[5 rows x 11 columns]
\end{verbatim}

This dataset is considered in ``wide'' format. There are several issues with it, including the fact that column headers have data. Those column headers are income groups, that should be a column by tidy principles. Our job is to turn this dataset into ``long'' format with a column for income group.

We will use the function \texttt{melt} to achieve this. This takes a few parameters:

\begin{itemize}
\tightlist
\item
  \textbf{id\_vars} is a list of variables that will remain as is
\item
  \textbf{value\_vars} is a list of column nmaes that we will melt (or unpivot). By default, it will melt all columns not mentioned in id\_vars
\item
  \textbf{var\_name} is a string giving the name of the new column created by the headers (default: \texttt{variable})
\item
  \textbf{value\_name} is a string giving the name of the new column created by the values (default: \texttt{value})
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pew_long }\OperatorTok{=}\NormalTok{ pew.melt(id_vars }\OperatorTok{=}\NormalTok{ [}\StringTok{'religion'}\NormalTok{], var_name }\OperatorTok{=} \StringTok{'income_group'}\NormalTok{, value_name }\OperatorTok{=} \StringTok{'count'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(pew_long.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             religion income_group  count
0            Agnostic        <$10k     27
1             Atheist        <$10k     12
2            Buddhist        <$10k     27
3            Catholic        <$10k    418
4  Dont know/refused        <$10k     15
\end{verbatim}

\hypertarget{separating-columns-containing-multiple-variables}{%
\subsection{Separating columns containing multiple variables}\label{separating-columns-containing-multiple-variables}}

We will use an Ebola dataset to illustrate this principle

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/country_timeseries.csv'}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(ebola.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         Date  Day  ...  Deaths_Spain  Deaths_Mali
0    1/5/2015  289  ...           NaN          NaN
1    1/4/2015  288  ...           NaN          NaN
2    1/3/2015  287  ...           NaN          NaN
3    1/2/2015  286  ...           NaN          NaN
4  12/31/2014  284  ...           NaN          NaN

[5 rows x 18 columns]
\end{verbatim}

Note that for each country we have two columns -- one for cases (number infected) and one for deaths. Ideally we want one column for country, one for cases and one for deaths.

The first step will be to melt this data sets so that the column headers in question from a column and the corresponding data forms a second column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola_long }\OperatorTok{=}\NormalTok{ ebola.melt(id_vars }\OperatorTok{=}\NormalTok{ [}\StringTok{'Date'}\NormalTok{,}\StringTok{'Day'}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(ebola_long.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         Date  Day      variable   value
0    1/5/2015  289  Cases_Guinea  2776.0
1    1/4/2015  288  Cases_Guinea  2775.0
2    1/3/2015  287  Cases_Guinea  2769.0
3    1/2/2015  286  Cases_Guinea     NaN
4  12/31/2014  284  Cases_Guinea  2730.0
\end{verbatim}

We now need to split the data in the \texttt{variable} column to make two columns. One will contain the country name and the other either Cases or Deaths. We will use some string manipulation functions that we will see later to achieve this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable_split }\OperatorTok{=}\NormalTok{ ebola_long[}\StringTok{'variable'}\NormalTok{].}\BuiltInTok{str}\NormalTok{.split(}\StringTok{'_'}\NormalTok{, expand}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\CommentTok{# split on the `_` character}
\BuiltInTok{print}\NormalTok{(variable_split[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       0       1
0  Cases  Guinea
1  Cases  Guinea
2  Cases  Guinea
3  Cases  Guinea
4  Cases  Guinea
\end{verbatim}

The \texttt{expand=True} option forces the creation of an \texttt{DataFrame} rather than a list

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(variable_split)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
\end{verbatim}

We can now concatenate this to the original data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable_split.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{'status'}\NormalTok{,}\StringTok{'country'}\NormalTok{]}

\NormalTok{ebola_parsed }\OperatorTok{=}\NormalTok{ pd.concat([ebola_long, variable_split], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}

\NormalTok{ebola_parsed.drop(}\StringTok{'variable'}\NormalTok{, axis }\OperatorTok{=} \DecValTok{1}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\CommentTok{# Remove the column named "variable" and replace the old data with the new one in the same location}

\BuiltInTok{print}\NormalTok{(ebola_parsed.head())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         Date  Day   value status country
0    1/5/2015  289  2776.0  Cases  Guinea
1    1/4/2015  288  2775.0  Cases  Guinea
2    1/3/2015  287  2769.0  Cases  Guinea
3    1/2/2015  286     NaN  Cases  Guinea
4  12/31/2014  284  2730.0  Cases  Guinea
\end{verbatim}

\hypertarget{pivotspread-datasets}{%
\subsection{Pivot/spread datasets}\label{pivotspread-datasets}}

If we wanted to, we could also make two columns based on cases and deaths, so for each country and date you could easily read off the cases and deaths. This is achieved using the \texttt{pivot\_table} function.

In the \texttt{pivot\_table} syntax, \texttt{index} refers to the columns we don't want to change, \texttt{columns} refers to the column whose values will form the column names of the new columns, and \texttt{values} is the name of the column that will form the values in the pivoted dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola_parsed.pivot_table(index }\OperatorTok{=}\NormalTok{ [}\StringTok{'Date'}\NormalTok{,}\StringTok{'Day'}\NormalTok{, }\StringTok{'country'}\NormalTok{], columns }\OperatorTok{=} \StringTok{'status'}\NormalTok{, values }\OperatorTok{=} \StringTok{'value'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
status                     Cases  Deaths
Date     Day country                    
1/2/2015 286 Liberia      8157.0  3496.0
1/3/2015 287 Guinea       2769.0  1767.0
             Liberia      8166.0  3496.0
             SierraLeone  9722.0  2915.0
1/4/2015 288 Guinea       2775.0  1781.0
...                          ...     ...
9/7/2014 169 Liberia      2081.0  1137.0
             Nigeria        21.0     8.0
             Senegal         3.0     0.0
             SierraLeone  1424.0   524.0
9/9/2014 171 Liberia      2407.0     NaN

[375 rows x 2 columns]
\end{verbatim}

This creates something called \texttt{MultiIndex} in the \texttt{pandas} \texttt{DataFrame}. This is useful in some advanced cases, but here, we just want a normal \texttt{DataFrame} back. We can achieve that by using the \texttt{reset\_index} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola_parsed.pivot_table(index }\OperatorTok{=}\NormalTok{ [}\StringTok{'Date'}\NormalTok{,}\StringTok{'Day'}\NormalTok{,}\StringTok{'country'}\NormalTok{], columns }\OperatorTok{=} \StringTok{'status'}\NormalTok{, values }\OperatorTok{=} \StringTok{'value'}\NormalTok{).reset_index()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
status      Date  Day      country   Cases  Deaths
0       1/2/2015  286      Liberia  8157.0  3496.0
1       1/3/2015  287       Guinea  2769.0  1767.0
2       1/3/2015  287      Liberia  8166.0  3496.0
3       1/3/2015  287  SierraLeone  9722.0  2915.0
4       1/4/2015  288       Guinea  2775.0  1781.0
..           ...  ...          ...     ...     ...
370     9/7/2014  169      Liberia  2081.0  1137.0
371     9/7/2014  169      Nigeria    21.0     8.0
372     9/7/2014  169      Senegal     3.0     0.0
373     9/7/2014  169  SierraLeone  1424.0   524.0
374     9/9/2014  171      Liberia  2407.0     NaN

[375 rows x 5 columns]
\end{verbatim}

Pivoting is a 2-column to many-column operation, with the number of columns formed depending on the number of unique values present in the column of the original data that is entered into the \texttt{columns} argument of \texttt{pivot\_table}

\textbf{Exercise:} Load the file \texttt{weather.csv} into Python and work on making it a tidy dataset. It requires melting and pivoting. The dataset comprises of the maximun and minimum temperatures recorded each day in 2010. There are lots of missing value. Ultimately we want columns for days of the month, maximum temperature and minimum tempearture along with the location ID, the year and the month.

\hypertarget{data-aggregation-and-split-apply-combine}{%
\section{Data aggregation and split-apply-combine}\label{data-aggregation-and-split-apply-combine}}

We'll use the Gapminder dataset for this section

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/gapminder.tsv'}\NormalTok{, sep }\OperatorTok{=} \StringTok{'}\CharTok{\textbackslash{}t}\StringTok{'}\NormalTok{) }\CommentTok{# data is tab-separated, so we use `\textbackslash{}t` to specify that}
\end{Highlighting}
\end{Shaded}

The paradigm we will be exploring is often called \emph{split-apply-combine} or MapReduce or grouped aggregation. The basic idea is that you split a data set up by some feature, apply a recipe to each piece, compute the result, and then put the results back together into a dataset. This can be described in teh following schematic.

\includegraphics{graphs/split-apply-combine.png}

\texttt{pandas} is set up for this. It features the \texttt{groupby} function that allows the ``split'' part of the operation. We can then apply a function to each part and put it back together. Let's see how.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       country continent  year  lifeExp       pop   gdpPercap
0  Afghanistan      Asia  1952   28.801   8425333  779.445314
1  Afghanistan      Asia  1957   30.332   9240934  820.853030
2  Afghanistan      Asia  1962   31.997  10267083  853.100710
3  Afghanistan      Asia  1967   34.020  11537966  836.197138
4  Afghanistan      Asia  1972   36.088  13079460  739.981106
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{f"This dataset has }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(df[}\StringTok{'country'}\NormalTok{].unique())}\SpecialCharTok{\}}\SpecialStringTok{ countries in it"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'This dataset has 142 countries in it'
\end{verbatim}

One of the variables in this dataset is life expectancy at birth, \texttt{lifeExp}. Suppose we want to find the average life expectancy of each country over the period of study.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{)[}\StringTok{'lifeExp'}\NormalTok{].mean()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
country
Afghanistan           37.478833
Albania               68.432917
Algeria               59.030167
Angola                37.883500
Argentina             69.060417
                        ...    
Vietnam               57.479500
West Bank and Gaza    60.328667
Yemen, Rep.           46.780417
Zambia                45.996333
Zimbabwe              52.663167
Name: lifeExp, Length: 142, dtype: float64
\end{verbatim}

So what's going on here? First, we use the \texttt{groupby} function, telling \texttt{pandas} to split the dataset up by values of the column \texttt{country}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x1314cc8b0>
\end{verbatim}

\texttt{pandas} won't show you the actual data, but will tell you that it is a grouped dataframe object. This means that each element of this object is a \texttt{DataFrame} with data from one country.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{).ngroups}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
142
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{).get_group(}\StringTok{'United Kingdom'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             country continent  year  lifeExp       pop     gdpPercap
1596  United Kingdom    Europe  1952   69.180  50430000   9979.508487
1597  United Kingdom    Europe  1957   70.420  51430000  11283.177950
1598  United Kingdom    Europe  1962   70.760  53292000  12477.177070
1599  United Kingdom    Europe  1967   71.360  54959000  14142.850890
1600  United Kingdom    Europe  1972   72.010  56079000  15895.116410
1601  United Kingdom    Europe  1977   72.760  56179000  17428.748460
1602  United Kingdom    Europe  1982   74.040  56339704  18232.424520
1603  United Kingdom    Europe  1987   75.007  56981620  21664.787670
1604  United Kingdom    Europe  1992   76.420  57866349  22705.092540
1605  United Kingdom    Europe  1997   77.218  58808266  26074.531360
1606  United Kingdom    Europe  2002   78.471  59912431  29478.999190
1607  United Kingdom    Europe  2007   79.425  60776238  33203.261280
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(df.groupby(}\StringTok{'country'}\NormalTok{).get_group(}\StringTok{'United Kingdom'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg_lifeexp_country }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{'country'}\NormalTok{).lifeExp.mean()}
\NormalTok{avg_lifeexp_country[}\StringTok{'United Kingdom'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
73.92258333333332
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{).get_group(}\StringTok{'United Kingdom'}\NormalTok{).lifeExp.mean()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
73.92258333333332
\end{verbatim}

Let's look at if life expectancy has gone up over time, by continent

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby([}\StringTok{'continent'}\NormalTok{,}\StringTok{'year'}\NormalTok{]).lifeExp.mean()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
continent  year
Africa     1952    39.135500
           1957    41.266346
           1962    43.319442
           1967    45.334538
           1972    47.450942
           1977    49.580423
           1982    51.592865
           1987    53.344788
           1992    53.629577
           1997    53.598269
           2002    53.325231
           2007    54.806038
Americas   1952    53.279840
           1957    55.960280
           1962    58.398760
           1967    60.410920
           1972    62.394920
           1977    64.391560
           1982    66.228840
           1987    68.090720
           1992    69.568360
           1997    71.150480
           2002    72.422040
           2007    73.608120
Asia       1952    46.314394
           1957    49.318544
           1962    51.563223
           1967    54.663640
           1972    57.319269
           1977    59.610556
           1982    62.617939
           1987    64.851182
           1992    66.537212
           1997    68.020515
           2002    69.233879
           2007    70.728485
Europe     1952    64.408500
           1957    66.703067
           1962    68.539233
           1967    69.737600
           1972    70.775033
           1977    71.937767
           1982    72.806400
           1987    73.642167
           1992    74.440100
           1997    75.505167
           2002    76.700600
           2007    77.648600
Oceania    1952    69.255000
           1957    70.295000
           1962    71.085000
           1967    71.310000
           1972    71.910000
           1977    72.855000
           1982    74.290000
           1987    75.320000
           1992    76.945000
           1997    78.190000
           2002    79.740000
           2007    80.719500
Name: lifeExp, dtype: float64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg_lifeexp_continent_yr }\OperatorTok{=}\NormalTok{ df.groupby([}\StringTok{'continent'}\NormalTok{,}\StringTok{'year'}\NormalTok{]).lifeExp.mean().reset_index()}
\NormalTok{avg_lifeexp_continent_yr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   continent  year    lifeExp
0     Africa  1952  39.135500
1     Africa  1957  41.266346
2     Africa  1962  43.319442
3     Africa  1967  45.334538
4     Africa  1972  47.450942
5     Africa  1977  49.580423
6     Africa  1982  51.592865
7     Africa  1987  53.344788
8     Africa  1992  53.629577
9     Africa  1997  53.598269
10    Africa  2002  53.325231
11    Africa  2007  54.806038
12  Americas  1952  53.279840
13  Americas  1957  55.960280
14  Americas  1962  58.398760
15  Americas  1967  60.410920
16  Americas  1972  62.394920
17  Americas  1977  64.391560
18  Americas  1982  66.228840
19  Americas  1987  68.090720
20  Americas  1992  69.568360
21  Americas  1997  71.150480
22  Americas  2002  72.422040
23  Americas  2007  73.608120
24      Asia  1952  46.314394
25      Asia  1957  49.318544
26      Asia  1962  51.563223
27      Asia  1967  54.663640
28      Asia  1972  57.319269
29      Asia  1977  59.610556
30      Asia  1982  62.617939
31      Asia  1987  64.851182
32      Asia  1992  66.537212
33      Asia  1997  68.020515
34      Asia  2002  69.233879
35      Asia  2007  70.728485
36    Europe  1952  64.408500
37    Europe  1957  66.703067
38    Europe  1962  68.539233
39    Europe  1967  69.737600
40    Europe  1972  70.775033
41    Europe  1977  71.937767
42    Europe  1982  72.806400
43    Europe  1987  73.642167
44    Europe  1992  74.440100
45    Europe  1997  75.505167
46    Europe  2002  76.700600
47    Europe  2007  77.648600
48   Oceania  1952  69.255000
49   Oceania  1957  70.295000
50   Oceania  1962  71.085000
51   Oceania  1967  71.310000
52   Oceania  1972  71.910000
53   Oceania  1977  72.855000
54   Oceania  1982  74.290000
55   Oceania  1987  75.320000
56   Oceania  1992  76.945000
57   Oceania  1997  78.190000
58   Oceania  2002  79.740000
59   Oceania  2007  80.719500
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(avg_lifeexp_continent_yr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
\end{verbatim}

The aggregation function, in this case \texttt{mean}, does both the ``apply'' and ``combine'' parts of the process.

We can do quick aggregations with \texttt{pandas}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'continent'}\NormalTok{).lifeExp.describe()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           count       mean        std  ...      50%       75%     max
continent                               ...                           
Africa     624.0  48.865330   9.150210  ...  47.7920  54.41150  76.442
Americas   300.0  64.658737   9.345088  ...  67.0480  71.69950  80.653
Asia       396.0  60.064903  11.864532  ...  61.7915  69.50525  82.603
Europe     360.0  71.903686   5.433178  ...  72.2410  75.45050  81.757
Oceania     24.0  74.326208   3.795611  ...  73.6650  77.55250  81.235

[5 rows x 8 columns]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'continent'}\NormalTok{).nth(}\DecValTok{10}\NormalTok{) }\CommentTok{# Tenth observation in each group}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
               country  year  lifeExp       pop     gdpPercap
continent                                                    
Africa         Algeria  2002   70.994  31287142   5288.040382
Americas     Argentina  2002   74.340  38331121   8797.640716
Asia       Afghanistan  2002   42.129  25268405    726.734055
Europe         Albania  2002   75.651   3508512   4604.211737
Oceania      Australia  2002   80.370  19546792  30687.754730
\end{verbatim}

You can also use functions from other modules, or your own functions in this aggregation work.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'continent'}\NormalTok{).lifeExp.agg(np.mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
continent
Africa      48.865330
Americas    64.658737
Asia        60.064903
Europe      71.903686
Oceania     74.326208
Name: lifeExp, dtype: float64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my_mean(values):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(values)}
    \BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ value }\KeywordTok{in}\NormalTok{ values:}
        \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ value}
    \ControlFlowTok{return}\NormalTok{(}\BuiltInTok{sum}\OperatorTok{/}\NormalTok{n)}

\NormalTok{df.groupby(}\StringTok{'continent'}\NormalTok{).lifeExp.agg(my_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
continent
Africa      48.865330
Americas    64.658737
Asia        60.064903
Europe      71.903686
Oceania     74.326208
Name: lifeExp, dtype: float64
\end{verbatim}

You can do many functions at once

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'year'}\NormalTok{).lifeExp.agg([np.count_nonzero, np.mean, np.std])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      count_nonzero       mean        std
year                                     
1952          142.0  49.057620  12.225956
1957          142.0  51.507401  12.231286
1962          142.0  53.609249  12.097245
1967          142.0  55.678290  11.718858
1972          142.0  57.647386  11.381953
1977          142.0  59.570157  11.227229
1982          142.0  61.533197  10.770618
1987          142.0  63.212613  10.556285
1992          142.0  64.160338  11.227380
1997          142.0  65.014676  11.559439
2002          142.0  65.694923  12.279823
2007          142.0  67.007423  12.073021
\end{verbatim}

You can also aggregate on different columns at the same time by passing a \texttt{dict} to the \texttt{agg} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'year'}\NormalTok{).agg(\{}\StringTok{'lifeExp'}\NormalTok{: np.mean,}\StringTok{'pop'}\NormalTok{: np.median,}\StringTok{'gdpPercap'}\NormalTok{: np.median\}).reset_index()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    year    lifeExp         pop    gdpPercap
0   1952  49.057620   3943953.0  1968.528344
1   1957  51.507401   4282942.0  2173.220291
2   1962  53.609249   4686039.5  2335.439533
3   1967  55.678290   5170175.5  2678.334741
4   1972  57.647386   5877996.5  3339.129407
5   1977  59.570157   6404036.5  3798.609244
6   1982  61.533197   7007320.0  4216.228428
7   1987  63.212613   7774861.5  4280.300366
8   1992  64.160338   8688686.5  4386.085502
9   1997  65.014676   9735063.5  4781.825478
10  2002  65.694923  10372918.5  5319.804524
11  2007  67.007423  10517531.0  6124.371109
\end{verbatim}

\hypertarget{transformation}{%
\subsubsection{Transformation}\label{transformation}}

You can do grouped transformations using this same method. We will compute the z-score for each year, i.e.~we will substract the average life expectancy and divide by the standard deviation

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my_zscore(values):}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ np.mean(values)}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ np.std(values)}
    \ControlFlowTok{return}\NormalTok{((values }\OperatorTok{-}\NormalTok{ m)}\OperatorTok{/}\NormalTok{s)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'year'}\NormalTok{).lifeExp.transform(my_zscore)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0      -1.662719
1      -1.737377
2      -1.792867
3      -1.854699
4      -1.900878
          ...   
1699   -0.081910
1700   -0.338167
1701   -1.580537
1702   -2.100756
1703   -1.955077
Name: lifeExp, Length: 1704, dtype: float64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{'lifeExp_z'}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{'year'}\NormalTok{).lifeExp.transform(my_zscore)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'year'}\NormalTok{).lifeExp_z.mean()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
year
1952   -5.165078e-16
1957    2.902608e-17
1962    2.404180e-16
1967   -6.108181e-16
1972    1.784566e-16
1977   -9.456442e-16
1982   -1.623310e-16
1987    6.687725e-16
1992    5.457293e-16
1997    8.787963e-16
2002    5.254013e-16
2007    4.925637e-16
Name: lifeExp_z, dtype: float64
\end{verbatim}

\hypertarget{filter}{%
\subsubsection{Filter}\label{filter}}

We can split the dataset by values of one variable, and filter out those splits that fail some criterion. The following code only keeps countries with a population of at least 10 million at some point during the study period

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{'country'}\NormalTok{).}\BuiltInTok{filter}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ d: d[}\StringTok{'pop'}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{>} \DecValTok{10000000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          country continent  year  lifeExp       pop   gdpPercap  lifeExp_z
0     Afghanistan      Asia  1952   28.801   8425333  779.445314  -1.662719
1     Afghanistan      Asia  1957   30.332   9240934  820.853030  -1.737377
2     Afghanistan      Asia  1962   31.997  10267083  853.100710  -1.792867
3     Afghanistan      Asia  1967   34.020  11537966  836.197138  -1.854699
4     Afghanistan      Asia  1972   36.088  13079460  739.981106  -1.900878
...           ...       ...   ...      ...       ...         ...        ...
1699     Zimbabwe    Africa  1987   62.351   9216418  706.157306  -0.081910
1700     Zimbabwe    Africa  1992   60.377  10704340  693.420786  -0.338167
1701     Zimbabwe    Africa  1997   46.809  11404948  792.449960  -1.580537
1702     Zimbabwe    Africa  2002   39.989  11926563  672.038623  -2.100756
1703     Zimbabwe    Africa  2007   43.487  12311143  469.709298  -1.955077

[924 rows x 7 columns]
\end{verbatim}

\hypertarget{data-visualization-using-python}{%
\chapter{Data visualization using Python}\label{data-visualization-using-python}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Data visualization is a basic task in data exploration and understanding. Humans are mainly visual creatures, and data visualization provides an opportunity to enhance communication of the story within the data. Often we find that data and the data-generating process is complex, and a visual representation of the data and our innate ability at pattern recognition can help reveal the complexities in a cognitively accessible way.

\hypertarget{an-example-gallery}{%
\subsection{An example gallery}\label{an-example-gallery}}

Data visualization has a long and storied history, from Florence Nightangle onwards. Dr.~Nightangle was a pioneer in data visualization and developed the \emph{rose plot} to represent causes of death in hospitals during the Crimean War.

\includegraphics{graphs/rose.jpg}

John Snow, in 1854, famously visualized the cholera outbreak in London, which showed the geographic proximity of cholera prevalence with particular water wells.

\includegraphics{graphs/snow_map.png}

In one of the more famous visualizations, considered by many to be an optimal use of display ink and space, Minard visualized Napoleon's disastrous campaign to Russia

\includegraphics{graphs/map-full-size1.png}

In more recent times, an employee at Facebook visualized all connections between users across the world, which clearly showed geographical associations with particular countries and regions.

\includegraphics{graphs/facebook-high-res-friendship-world-map-paul-butler.png}

\hypertarget{why-visualize-data}{%
\subsection{Why visualize data?}\label{why-visualize-data}}

We often rely on numerical summaries to help understand and distinguish datasets. In 1973, Anscombe published an influential set of 4 datasets, each with two variables and with the means, variances and correlations being identical. When you graphed these data, the differences in the datasets were clearly visible. This set is popularly known as Anscombe's quartet.

\includegraphics{graphs/anscombe.png}

A more recent experiment in data construction by Matejka and Fitzmaurice (2017) started with a representation of a dinosaur and created 10 more bivariate datasets which all shared the same univariate means and variances and the same pairwise correlations.

\includegraphics{graphs/datasaurus.png}

These examples clarify the need for visualization to better understand relationships between variables.

Even when using statistical visualization techniques, one has to be careful. Not all visualizations can discriminate between statistical characteristics. This was also explored by Matejka and Fitzmaurice.

\begin{longtable}[]{@{}ccc@{}}
\toprule
Strip plot & Boxplot & Violin plot\tabularnewline
\midrule
\endhead
\includegraphics{graphs/box1.png} & \includegraphics{graphs/box2.png} & \includegraphics{graphs/box3.png}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{conceptual-ideas}{%
\subsection{Conceptual ideas}\label{conceptual-ideas}}

\hypertarget{begin-with-the-consumer-in-mind}{%
\subsubsection{Begin with the consumer in mind}\label{begin-with-the-consumer-in-mind}}

\begin{itemize}
\tightlist
\item
  You have a deep understanding of the data you're presenting
\item
  The person seeing the visualization \textbf{doesn't}
\item
  Develop simpler visualizations first that are easier to explain
\end{itemize}

\hypertarget{tell-a-story}{%
\subsubsection{Tell a story}\label{tell-a-story}}

\begin{itemize}
\tightlist
\item
  Make sure the graphic is clear
\item
  Make sure the main point you want to make ``pops''
\end{itemize}

\hypertarget{a-matter-of-perception}{%
\subsubsection{A matter of perception}\label{a-matter-of-perception}}

\begin{itemize}
\tightlist
\item
  Color (including awareness of color deficiencies)
\item
  Shape
\item
  Fonts
\end{itemize}

\hypertarget{some-principles}{%
\subsubsection{Some principles}\label{some-principles}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data-ink ratio
\item
  No mental gymnastics

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    The graphic should be self-evident
  \item
    Context should be clear
  \end{enumerate}
\item
  Is a graph the wrong choice?
\item
  Focus on the consumer
\end{enumerate}

\begin{quote}
See \href{http://araastat.com/BIOF439/slides/lectures/01-DataViz.pdf}{my slides} for some more opinionated ideas
\end{quote}

\hypertarget{plotting-in-python}{%
\section{Plotting in Python}\label{plotting-in-python}}

Let's take a very quick tour before we get into the weeds. We'll use the mtcars dataset as an exemplar dataset that we can import using \texttt{pandas}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.set_context(}\StringTok{'paper'}\NormalTok{)}
\NormalTok{sns.set_style(}\StringTok{'white'}\NormalTok{, \{}\StringTok{'font.family'}\NormalTok{:}\StringTok{'Futura'}\NormalTok{, }\StringTok{'text.color'}\NormalTok{:}\StringTok{'1'}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/mtcars.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{static-plots}{%
\subsection{Static plots}\label{static-plots}}

We will demonstrate plotting in what I'll call the \texttt{matplotlib} ecosystem. \texttt{matplotlib} is the venerable and powerful visualization package that was originally designed to emulate the Matlab plotting paradigm. It has since evolved and as become a bit more user-friendly. It is still quite granular and can facilitate a lot of custom plots once you become familiar with it. However, as a starting point, I think it's a bit much. We'll see a bit of what it can offer later.

We will consider two other options which are built on top of \texttt{matplotlib}, but are much more accessible. These are \texttt{pandas} and \texttt{seaborn}. The two packages have some different approaches, but both wrap \texttt{matplotlib} in higher-level code and decent choices so we don't need to get into the \texttt{matplotlib} trenches quite so much. We'll still call \texttt{matplotlib} in our code, since both these packages need it for some fine tuning. Both packages are also very much aligned to the \texttt{DataFrame} construct in \texttt{pandas}, so makes plotting a much more seamless experience.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.plot.scatter(x }\OperatorTok{=} \StringTok{'hp'}\NormalTok{, y }\OperatorTok{=} \StringTok{'mpg'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = self.plt.figure(figsize=self.figsize)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\CommentTok{# mtcars.plot(x = 'hp', y = 'mpg', kind = 'scatter');}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ mtcars, x }\OperatorTok{=} \StringTok{'hp'}\NormalTok{, y }\OperatorTok{=} \StringTok{'mpg'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-3-1} \end{center}

There are of course some other choices based on your background and preferences. For static plots, there are a couple of emulators of the popular R package \texttt{ggplot2}. These are \texttt{plotnine} and \texttt{ggplot}. \texttt{plotnine} seems a bit more developed and uses the \texttt{ggplot2} semantics of aesthetics and layers, with almost identical code syntax.

\begin{quote}
You can install \texttt{plotnine} using \texttt{conda}:

\begin{verbatim}
conda install -c conda-forge plotnine
\end{verbatim}
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ plotnine }\ImportTok{import} \OperatorTok{*}

\NormalTok{(ggplot(mtcars) }\OperatorTok{+} 
\NormalTok{  aes(x }\OperatorTok{=} \StringTok{'hp'}\NormalTok{, y }\OperatorTok{=} \StringTok{'mpg'}\NormalTok{) }\OperatorTok{+}
\NormalTok{  geom_point())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<ggplot: (318501401)>

/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/plotnine/ggplot.py:363: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  figure = plt.figure()
\end{verbatim}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-4-1} \end{center}

\hypertarget{dynamic-or-interactive-plots}{%
\subsection{Dynamic or interactive plots}\label{dynamic-or-interactive-plots}}

There are several Python packages that wrap around Javascript plotting libraries that are so popular in web-based graphics like D3 and Vega. Three that deserve mention are \texttt{plotly}, \texttt{bokeh}, and \texttt{altair}.

\begin{quote}
If you actually want to experience the interactivity of the plots, please use the ``Live notebooks'' link in Canvas to run these notebooks. Otherwise, you can download the notebooks from the GitHub site and run them on your own computer.
\end{quote}

\texttt{plotly} is a Python package developed by the company \href{https://www.plotly.com}{Plot.ly} to interface with their interactive Javascript library either locally or via their web service. Plot.ly also develops an R package to interface with their products as well. It provides an intuitive syntax and ease of use, and is probably the more popular package for interactive graphics from both R and Python.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ plotly.express }\ImportTok{as}\NormalTok{ px}

\NormalTok{fig }\OperatorTok{=}\NormalTok{ px.scatter(mtcars, x }\OperatorTok{=} \StringTok{'hp'}\NormalTok{, y }\OperatorTok{=} \StringTok{'mpg'}\NormalTok{)}
\NormalTok{fig.show()}
\end{Highlighting}
\end{Shaded}

\texttt{bokeh} is an interactive visualization package developed by Anaconda. It is quite powerful, but its code can be rather verbose and granular

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ bokeh.plotting }\ImportTok{import}\NormalTok{ figure, output_file}
\ImportTok{from}\NormalTok{ bokeh.io }\ImportTok{import}\NormalTok{ output_notebook, show}
\NormalTok{output_notebook()}
\NormalTok{p }\OperatorTok{=}\NormalTok{ figure()}
\NormalTok{p.xaxis.axis_label }\OperatorTok{=} \StringTok{'Horsepower'}
\NormalTok{p.yaxis.axis_label }\OperatorTok{=} \StringTok{'Miles per gallon'}

\NormalTok{p.circle(mtcars[}\StringTok{'hp'}\NormalTok{], mtcars[}\StringTok{'mpg'}\NormalTok{], size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}\OperatorTok{;}

\NormalTok{show(p)}
\end{Highlighting}
\end{Shaded}

\texttt{altair} that leverages ideas from Javascript plotting libraries and a distinctive code syntax that may appeal to some

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ altair }\ImportTok{as}\NormalTok{ alt}

\NormalTok{alt.Chart(mtcars).mark_point().encode(}
\NormalTok{    x}\OperatorTok{=}\StringTok{'hp'}\NormalTok{,}
\NormalTok{    y}\OperatorTok{=}\StringTok{'mpg'}
\NormalTok{).interactive()}
\end{Highlighting}
\end{Shaded}

We won't focus on these dynamic packages in this workshop in the interests of time, but you can avail of several online resources for these.

\begin{longtable}[]{@{}ll@{}}
\toprule
Package & Resources\tabularnewline
\midrule
\endhead
plotly & \href{https://plotly.com/python/}{Fundamentals}\tabularnewline
bokeh & \href{https://mybinder.org/v2/gh/bokeh/bokeh-notebooks/master?filepath=tutorial\%2F00\%20-\%20Introduction\%20and\%20Setup.ipynb}{Tutorial}\tabularnewline
altair & \href{https://altair-viz.github.io/getting_started/overview.html}{Overview}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{univariate-plots}{%
\section{Univariate plots}\label{univariate-plots}}

We will be introducing plotting and code from 3 modules: \texttt{matplotlib}, \texttt{seaborn} and \texttt{pandas}. As we go forth, you may ask the question, which one should I learn? Chris Moffitt has the following advice.

A pathway to learning (\href{https://pbpython.com/effective-matplotlib.html}{Chris Moffit})

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Learn the basic matplotlib terminology, specifically what is a \texttt{Figure} and an \texttt{Axes} .
\item
  Always use the object-oriented interface. Get in the habit of using it from the start of your analysis. (\emph{not really getting into this, but basically don't use the Matlab form I'll show at the end, if you don't have to})
\item
  Start your visualizations with basic pandas plotting.
\item
  Use seaborn for the more complex statistical visualizations.
\item
  Use matplotlib to customize the pandas or seaborn visualization.
\end{enumerate}

\hypertarget{pandas}{%
\subsection{pandas}\label{pandas}}

\hypertarget{histogram}{%
\subsubsection{Histogram}\label{histogram}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.plot.hist(y }\OperatorTok{=} \StringTok{'mpg'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = self.plt.figure(figsize=self.figsize)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\CommentTok{# mtcars.plot(y = 'mpg', kind = 'hist')}
\CommentTok{#mtcars['mpg'].plot(kind = 'hist')}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-8-1} \end{center}

\hypertarget{bar-plot}{%
\subsubsection{Bar plot}\label{bar-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\StringTok{'cyl'}\NormalTok{].value_counts().plot.bar()}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-9-1} \end{center}

\hypertarget{density-plot}{%
\subsubsection{Density plot}\label{density-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\StringTok{'mpg'}\NormalTok{].plot( kind }\OperatorTok{=} \StringTok{'density'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-10-1} \end{center}

\hypertarget{seaborn}{%
\subsection{seaborn}\label{seaborn}}

\hypertarget{histogram-1}{%
\subsubsection{Histogram}\label{histogram-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax }\OperatorTok{=}\NormalTok{ sns.distplot(mtcars[}\StringTok{'mpg'}\NormalTok{], kde}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-11-1} \end{center}

\hypertarget{bar-plot-1}{%
\subsubsection{Bar plot}\label{bar-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.countplot(data }\OperatorTok{=}\NormalTok{ mtcars, x }\OperatorTok{=} \StringTok{'cyl'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-12-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/diamonds.csv.gz'}\NormalTok{)}
\NormalTok{ordered_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{,}\StringTok{'J'}\NormalTok{]}
\NormalTok{sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'color'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'count'}\NormalTok{, color }\OperatorTok{=} \StringTok{'blue'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-13-1} \end{center}

\hypertarget{density-plot-1}{%
\subsubsection{Density plot}\label{density-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(mtcars[}\StringTok{'mpg'}\NormalTok{], hist}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-14-1} \end{center}

\hypertarget{bivariate-plots}{%
\section{Bivariate plots}\label{bivariate-plots}}

\hypertarget{pandas-1}{%
\subsection{pandas}\label{pandas-1}}

\hypertarget{scatter-plot}{%
\subsubsection{Scatter plot}\label{scatter-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/diamonds.csv.gz'}\NormalTok{)}
\NormalTok{diamonds.plot(x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'scatter'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = self.plt.figure(figsize=self.figsize)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-15-1} \end{center}

\hypertarget{box-plot}{%
\subsubsection{Box plot}\label{box-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds.boxplot(column }\OperatorTok{=} \StringTok{'price'}\NormalTok{, by }\OperatorTok{=} \StringTok{'color'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/pandas/plotting/_matplotlib/tools.py:184: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(**fig_kw)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-16-1} \end{center}

\hypertarget{seaborn-1}{%
\subsection{seaborn}\label{seaborn-1}}

\hypertarget{scatter-plot-1}{%
\subsubsection{Scatter plot}\label{scatter-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.regplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, fit_reg}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-17-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.scatterplot(data}\OperatorTok{=}\NormalTok{diamonds, x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, linewidth}\OperatorTok{=}\DecValTok{0}\NormalTok{)}\OperatorTok{;} 
\CommentTok{# We set the linewidth to 0, otherwise the lines around the circles}
\CommentTok{# appear white and wash out the figure. Try with any positive }
\CommentTok{# value of linewidth}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-12-1} \end{center}

\hypertarget{box-plot-1}{%
\subsubsection{Box plot}\label{box-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered_color }\OperatorTok{=}\NormalTok{ [}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{,}\StringTok{'J'}\NormalTok{]}
\NormalTok{sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'color'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, }
\NormalTok{            order }\OperatorTok{=}\NormalTok{ ordered_color, color }\OperatorTok{=} \StringTok{'blue'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'box'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-18-1} \end{center}

\hypertarget{violin-plot}{%
\subsubsection{Violin plot}\label{violin-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'color'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, }
\NormalTok{                kind }\OperatorTok{=} \StringTok{'violin'}\NormalTok{, order }\OperatorTok{=}\NormalTok{ ordered_color)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-19-1} \end{center}

\hypertarget{barplot-categorical-vs-continuous}{%
\subsubsection{Barplot (categorical vs continuous)}\label{barplot-categorical-vs-continuous}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{'D'}\NormalTok{,}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{]}
\NormalTok{sns.barplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'color'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, order }\OperatorTok{=}\NormalTok{ ordered_colors)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-20-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.barplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'cut'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-21-1} \end{center}

\hypertarget{joint-plot}{%
\subsubsection{Joint plot}\label{joint-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:1676: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  f = plt.figure(figsize=(height, height))
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-22-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'reg'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:1676: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  f = plt.figure(figsize=(height, height))
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-23-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{'carat'}\NormalTok{, y }\OperatorTok{=} \StringTok{'price'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'hex'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:1676: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  f = plt.figure(figsize=(height, height))
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-24-1} \end{center}

\hypertarget{facets-and-multivariate-data}{%
\section{Facets and multivariate data}\label{facets-and-multivariate-data}}

The basic idea in this section is to see how we can visualize more than two variables at a time. We will see two strategies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Put multiple graphs on the same frame, with each graph referring to a level of a 3rd variable
\item
  Create a grid of separate graphs, with each graph referring to a level of a 3rd variable
\end{enumerate}

This strategy also can work any time we need to visualize the data corresponding to different levels of a variable, say by gender or race or country.

In this example we're going to start with 4 time series, labelled A, B, C, D.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/ts.csv'}\NormalTok{)}
\NormalTok{ts.dt }\OperatorTok{=}\NormalTok{ pd.to_datetime(ts.dt) }\CommentTok{# convert this column to a datetime object}
\NormalTok{ts.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          dt kind     value
0 2000-01-01    A  1.442521
1 2000-01-02    A  1.981290
2 2000-01-03    A  1.586494
3 2000-01-04    A  1.378969
4 2000-01-05    A -0.277937
\end{verbatim}

For one strategy we will employ, it is actually a bit easier to change this to a wide data form, using \texttt{pivot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfp }\OperatorTok{=}\NormalTok{ ts.pivot(index }\OperatorTok{=} \StringTok{'dt'}\NormalTok{, columns }\OperatorTok{=} \StringTok{'kind'}\NormalTok{, values }\OperatorTok{=} \StringTok{'value'}\NormalTok{)}
\NormalTok{dfp.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
kind               A         B         C         D
dt                                                
2000-01-01  1.442521  1.808741  0.437415  0.096980
2000-01-02  1.981290  2.277020  0.706127 -1.523108
2000-01-03  1.586494  3.474392  1.358063 -3.100735
2000-01-04  1.378969  2.906132  0.262223 -2.660599
2000-01-05 -0.277937  3.489553  0.796743 -3.417402
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfp.plot(ax}\OperatorTok{=}\NormalTok{ax)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-27-1} \end{center}

This creates 4 separate time series plots, one for each of the columns labeled A, B, C and D. The x-axis is determined by \texttt{dfp.index}, which during the pivoting operation, we deemed was the values of \texttt{dt} in the original data.

Using \texttt{seaborn}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(data }\OperatorTok{=}\NormalTok{ dfp)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-28-1} \end{center}

However, we can achieve this same plot using the original data, and \texttt{seaborn}, in rather short order

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(data }\OperatorTok{=}\NormalTok{ ts, x }\OperatorTok{=} \StringTok{'dt'}\NormalTok{, y }\OperatorTok{=} \StringTok{'value'}\NormalTok{, hue }\OperatorTok{=} \StringTok{'kind'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-29-1} \end{center}

In this plot, assigning a variable to \texttt{hue} tells seaborn to draw lines (in this case) of different hues based on values of that variable.

We can use a bit more granular and explicit code for this as well. This allows us a bit more control of the plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(ts, hue }\OperatorTok{=} \StringTok{'kind'}\NormalTok{, height }\OperatorTok{=} \DecValTok{5}\NormalTok{, aspect }\OperatorTok{=} \FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.plot, }\StringTok{'dt'}\NormalTok{, }\StringTok{'value'}\NormalTok{).add_legend()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<seaborn.axisgrid.FacetGrid object at 0x12fbc59a0>

findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.ax.}\BuiltInTok{set}\NormalTok{(xlabel }\OperatorTok{=} \StringTok{'Date'}\NormalTok{,}
\NormalTok{        ylabel }\OperatorTok{=} \StringTok{'Value'}\NormalTok{,}
\NormalTok{        title }\OperatorTok{=} \StringTok{'Time series'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}

\CommentTok{## All of this code chunk needs to be run at one time, otherwise you get weird errors. This}
\CommentTok{## is true for many plotting commands which are composed of multiple commands. }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-30-1} \end{center}

The \texttt{FacetGrid} tells \texttt{seaborn} that we're going to layer graphs, with layers based on \texttt{hue} and the hues being determined by values of \texttt{kind}. Notice that we can add a few more details like the aspect ratio of the plot and so on. The documentation for \href{https://seaborn.pydata.org/generated/seaborn.FacetGrid.html}{FacetGrid}, which we will also use for facets below, may be helpful in finding all the options you can control.

We can also show more than one kind of layer on a single graph

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmri }\OperatorTok{=}\NormalTok{ sns.load_dataset(}\StringTok{'fmri'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'seaborn-notebook'}\NormalTok{)}
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{'timepoint'}\NormalTok{, y }\OperatorTok{=} \StringTok{'signal'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-32-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{'timepoint'}\NormalTok{, y }\OperatorTok{=} \StringTok{'signal'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, kind }\OperatorTok{=} \StringTok{'line'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-33-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{'timepoint'}\NormalTok{, y }\OperatorTok{=} \StringTok{'signal'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, kind }\OperatorTok{=} \StringTok{'line'}\NormalTok{, hue }\OperatorTok{=}\StringTok{'event'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-34-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{'timepoint'}\NormalTok{, y }\OperatorTok{=} \StringTok{'signal'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, hue }\OperatorTok{=} \StringTok{'region'}\NormalTok{, }
\NormalTok{            style }\OperatorTok{=} \StringTok{'event'}\NormalTok{, kind }\OperatorTok{=} \StringTok{'line'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-35-1} \end{center}

Here we use color to show the region, and line style (solid vs dashed) to show the event.

\hypertarget{scatter-plots-by-group}{%
\subsubsection{Scatter plots by group}\label{scatter-plots-by-group}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(diamonds, hue }\OperatorTok{=} \StringTok{'color'}\NormalTok{, height }\OperatorTok{=} \FloatTok{7.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.scatter, }\StringTok{'carat'}\NormalTok{, }\StringTok{'price'}\NormalTok{).add_legend()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-36-1} \end{center}

Notice that this arranges the colors and values for the \texttt{color} variable in random order. If we have a preferred order we can impose that using the option \texttt{hue\_order}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clarity_ranking }\OperatorTok{=}\NormalTok{ [}\StringTok{"I1"}\NormalTok{, }\StringTok{"SI2"}\NormalTok{, }\StringTok{"SI1"}\NormalTok{, }\StringTok{"VS2"}\NormalTok{, }\StringTok{"VS1"}\NormalTok{, }\StringTok{"VVS2"}\NormalTok{, }\StringTok{"VVS1"}\NormalTok{, }\StringTok{"IF"}\NormalTok{]}
\NormalTok{sns.scatterplot(x}\OperatorTok{=}\StringTok{"carat"}\NormalTok{, y}\OperatorTok{=}\StringTok{"price"}\NormalTok{,}
\NormalTok{                hue}\OperatorTok{=}\StringTok{"clarity"}\NormalTok{, size}\OperatorTok{=}\StringTok{"depth"}\NormalTok{,}
\NormalTok{                hue_order}\OperatorTok{=}\NormalTok{clarity_ranking,}
\NormalTok{                sizes}\OperatorTok{=}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{), linewidth}\OperatorTok{=}\DecValTok{0}\NormalTok{,}
\NormalTok{                data}\OperatorTok{=}\NormalTok{diamonds)}\OperatorTok{;}
\NormalTok{plt.show() }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-37-1} \end{center}

\hypertarget{facets}{%
\subsection{Facets}\label{facets}}

Facets or trellis graphics is a visualization method where we draw multiple plots in a grid, with each plot corresponding to unique values of a particular variable or combinations of variables. This has also been called \emph{small multiples}.

We'll proceed with an example using the \texttt{iris} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/iris.csv'}\NormalTok{)}
\NormalTok{iris.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   sepal_length  sepal_width  petal_length  petal_width species
0           5.1          3.5           1.4          0.2  setosa
1           4.9          3.0           1.4          0.2  setosa
2           4.7          3.2           1.3          0.2  setosa
3           4.6          3.1           1.5          0.2  setosa
4           5.0          3.6           1.4          0.2  setosa
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(iris, col }\OperatorTok{=} \StringTok{'species'}\NormalTok{, hue }\OperatorTok{=} \StringTok{'species'}\NormalTok{, height }\OperatorTok{=} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.scatter, }\StringTok{'sepal_width'}\NormalTok{, }\StringTok{'sepal_length'}\NormalTok{).add_legend()}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-39-1} \end{center}

Here we use \texttt{FacetGrid} to indicate that we're creating multiple subplots by specifying the option \texttt{col} (for column). So this code says we are going to create one plot per level of species, arranged as separate columns (or in effect along one row). You could also specify \texttt{row} which would arrange the plots one to a row, or, in effect, in one column.

The \texttt{map} function says, take the facets I've defined and stored in \texttt{g}, and in each one, plot a scatter plot with \texttt{sepal\_width} on the x-axis and \texttt{sepal\_length} on the y-axis.

We could also use \texttt{relplot} for a more compact solution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ iris, }
\NormalTok{            col }\OperatorTok{=} \StringTok{'species'}\NormalTok{, hue }\OperatorTok{=} \StringTok{'species'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-40-1} \end{center}

A bit more of a complicated example, using the \texttt{fmri} data, where we're coloring lines based on the subject, and creating a 2-d grid, where region of the brain in along columns and event type is along rows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x}\OperatorTok{=}\StringTok{"timepoint"}\NormalTok{, y}\OperatorTok{=}\StringTok{"signal"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"subject"}\NormalTok{,}
\NormalTok{            col}\OperatorTok{=}\StringTok{"region"}\NormalTok{, row}\OperatorTok{=}\StringTok{"event"}\NormalTok{, height}\OperatorTok{=}\DecValTok{3}\NormalTok{,}
\NormalTok{            kind}\OperatorTok{=}\StringTok{"line"}\NormalTok{, estimator}\OperatorTok{=}\VariableTok{None}\NormalTok{, data}\OperatorTok{=}\NormalTok{fmri)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-41-1} \end{center}

In the following example, we want to show how each subject fares for each of the two events, just within the frontal region. We let \texttt{seaborn} figure out the layout, only specifying that we'll be going along rows (``by column'') and also saying we'll wrap around to the beginning once we've got to 5 columns. Note we use the \texttt{query} function to filter the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x}\OperatorTok{=}\StringTok{"timepoint"}\NormalTok{, y}\OperatorTok{=}\StringTok{"signal"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"event"}\NormalTok{, style}\OperatorTok{=}\StringTok{"event"}\NormalTok{,}
\NormalTok{            col}\OperatorTok{=}\StringTok{"subject"}\NormalTok{, col_wrap}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{            height}\OperatorTok{=}\DecValTok{3}\NormalTok{, aspect}\OperatorTok{=}\NormalTok{.}\DecValTok{75}\NormalTok{, linewidth}\OperatorTok{=}\FloatTok{2.5}\NormalTok{,}
\NormalTok{            kind}\OperatorTok{=}\StringTok{"line"}\NormalTok{, data}\OperatorTok{=}\NormalTok{fmri.query(}\StringTok{"region == 'frontal'"}\NormalTok{))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:333: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=figsize)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-42-1} \end{center}

In the following example we want to compare the distribution of price from the diamonds dataset by color, and so it makes sense to create density plots of the price distribution and stack them one below the next so we can visually compare them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{,}\StringTok{'J'}\NormalTok{]}
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(data }\OperatorTok{=}\NormalTok{ diamonds, row }\OperatorTok{=} \StringTok{'color'}\NormalTok{, height }\OperatorTok{=} \FloatTok{1.7}\NormalTok{, }
\NormalTok{                  aspect }\OperatorTok{=} \DecValTok{4}\NormalTok{, row_order }\OperatorTok{=}\NormalTok{ ordered_colors)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(sns.kdeplot, }\StringTok{'price'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-43-1} \end{center}

You need to use \texttt{FacetGrid} to create sets of univariate plots since there is no particular method that allows univariate plots over a grid like \texttt{relplot} for bivariate plots.

\hypertarget{pairs-plots}{%
\subsection{Pairs plots}\label{pairs-plots}}

The pairs plot is a quick way to compare every pair of variables in a dataset (or at least, every pair of continuous variables) in a grid. You can specify what kind of univariate plot will be displayed on the diagonal locations on the grid, and which bivariate plots will be displayed on the off-diagonal locations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.pairplot(data}\OperatorTok{=}\NormalTok{iris)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:1292: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(len(y_vars), len(x_vars),
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-44-1} \end{center}

You can achieve more customization using \texttt{PairGrid}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.PairGrid(iris, diag_sharey}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:1292: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(len(y_vars), len(x_vars),
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g.map_upper(sns.scatterplot)}\OperatorTok{;}
\NormalTok{g.map_lower(sns.kdeplot, colors}\OperatorTok{=}\StringTok{"C0"}\NormalTok{)}\OperatorTok{;}
\NormalTok{g.map_diag(sns.kdeplot, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-45-1} \end{center}

\hypertarget{customizing-the-look}{%
\section{Customizing the look}\label{customizing-the-look}}

\hypertarget{themes}{%
\subsection{Themes}\label{themes}}

There are several \href{https://matplotlib.org/3.2.1/gallery/style_sheets/style_sheets_reference.html}{themes} available in the modern \texttt{matplotlib}, some of which borrow from \texttt{seaborn}. You can see the available themes and play around.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.available}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']
\end{verbatim}

See some examples below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'fivethirtyeight'}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
findfont: Font family ['Futura Medium'] not found. Falling back to DejaVu Sans.
\end{verbatim}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-47-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'bmh'}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-48-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'classic'}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-49-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'ggplot'}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-50-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'Solarize_Light2'}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{'sepal_width'}\NormalTok{, y }\OperatorTok{=} \StringTok{'sepal_length'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-51-1} \end{center}

\begin{quote}
One small syntax point. You may have noticed in your own work that you get a little annoying line in the output when you plot. You can prevent that from happening by putting a semi-colon (\texttt{;}) after the last plotting command
\end{quote}

\hypertarget{finer-control-with-matplotlib}{%
\section{Finer control with matplotlib}\label{finer-control-with-matplotlib}}

\begin{figure}
\centering
\includegraphics{graphs/matplotlib-anatomy.png}
\caption{\url{https://matplotlib.org/tutorials/introductory/usage.html\#sphx-glr-tutorials-introductory-usage-py}}
\end{figure}

As you can see from the figure, you can control each aspect of the plot displayed above using \texttt{matplotlib}. I won't go into the details, and will leave it to you to look at the \texttt{matplotlib} \href{https://matplotlib.org/contents.html}{documentation} and \href{https://matplotlib.org/gallery/index.html}{examples} if you need to customize at this level of granularity.

The following is an example using pure \texttt{matplotlib}. You can see how you can build up a plot. The crucial part here is that you need to run the code from each chunk together.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.ticker }\ImportTok{import}\NormalTok{ FuncFormatter}

\NormalTok{data }\OperatorTok{=}\NormalTok{ \{}\StringTok{'Barton LLC'}\NormalTok{: }\FloatTok{109438.50}\NormalTok{,}
        \StringTok{'Frami, Hills and Schmidt'}\NormalTok{: }\FloatTok{103569.59}\NormalTok{,}
        \StringTok{'Fritsch, Russel and Anderson'}\NormalTok{: }\FloatTok{112214.71}\NormalTok{,}
        \StringTok{'Jerde-Hilpert'}\NormalTok{: }\FloatTok{112591.43}\NormalTok{,}
        \StringTok{'Keeling LLC'}\NormalTok{: }\FloatTok{100934.30}\NormalTok{,}
        \StringTok{'Koepp Ltd'}\NormalTok{: }\FloatTok{103660.54}\NormalTok{,}
        \StringTok{'Kulas Inc'}\NormalTok{: }\FloatTok{137351.96}\NormalTok{,}
        \StringTok{'Trantow-Barrows'}\NormalTok{: }\FloatTok{123381.38}\NormalTok{,}
        \StringTok{'White-Trantow'}\NormalTok{: }\FloatTok{135841.99}\NormalTok{,}
        \StringTok{'Will LLC'}\NormalTok{: }\FloatTok{104437.60}\NormalTok{\}}
\NormalTok{group_data }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(data.values())}
\NormalTok{group_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(data.keys())}
\NormalTok{group_mean }\OperatorTok{=}\NormalTok{ np.mean(group_data)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{'default'}\NormalTok{)}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-53-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax.barh(group_names, group_data)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-54-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax.barh(group_names, group_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<BarContainer object of 10 artists>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax.}\BuiltInTok{set}\NormalTok{(xlim }\OperatorTok{=}\NormalTok{ [}\OperatorTok{-}\DecValTok{10000}\NormalTok{, }\DecValTok{140000}\NormalTok{], xlabel }\OperatorTok{=} \StringTok{'Total Revenue'}\NormalTok{, ylabel }\OperatorTok{=} \StringTok{'Company'}\NormalTok{, }
\NormalTok{       title }\OperatorTok{=} \StringTok{'Company Revenue'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-55-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax.barh(group_names, group_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<BarContainer object of 10 artists>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{labels }\OperatorTok{=}\NormalTok{ ax.get_xticklabels()}
\NormalTok{plt.setp(labels, rotation}\OperatorTok{=}\DecValTok{45}\NormalTok{, horizontalalignment}\OperatorTok{=}\StringTok{'right'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax.}\BuiltInTok{set}\NormalTok{(xlim}\OperatorTok{=}\NormalTok{[}\OperatorTok{-}\DecValTok{10000}\NormalTok{, }\DecValTok{140000}\NormalTok{], xlabel}\OperatorTok{=}\StringTok{'Total Revenue'}\NormalTok{, ylabel}\OperatorTok{=}\StringTok{'Company'}\NormalTok{,}
\NormalTok{       title}\OperatorTok{=}\StringTok{'Company Revenue'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-56-1} \end{center}

After you have created your figure, you do need to save it to disk so that you can use it in your Word or Markdown or PowerPoint document. You can see the formats available.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig.canvas.get_supported_filetypes()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'ps': 'Postscript', 'eps': 'Encapsulated Postscript', 'pdf': 'Portable Document Format', 'pgf': 'PGF code for LaTeX', 'png': 'Portable Network Graphics', 'raw': 'Raw RGBA bitmap', 'rgba': 'Raw RGBA bitmap', 'svg': 'Scalable Vector Graphics', 'svgz': 'Scalable Vector Graphics', 'jpg': 'Joint Photographic Experts Group', 'jpeg': 'Joint Photographic Experts Group', 'tif': 'Tagged Image File Format', 'tiff': 'Tagged Image File Format'}
\end{verbatim}

The type will be determined by the ending of the file name. You can add some options depending on the type. I'm showing an example of saving the figure to a PNG file. Typically I'll save figures to a vector graphics format like PDF, and then convert into other formats, since that results in minimal resolution loss. You of course have the option to save to your favorite format.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# fig.savefig('sales.png', dpi = 300, bbox_inches = 'tight') }
\end{Highlighting}
\end{Shaded}

\hypertarget{matlab-like-plotting}{%
\subsection{Matlab-like plotting}\label{matlab-like-plotting}}

\texttt{matplotlib} was originally developed to emulate Matlab. Though this kind of syntax is no longer recommended, it is still available and may be of use to those coming to Python from Matlab or Octave.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{plt.plot([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{])}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'some numbers'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-59-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{# evenly sampled time at 200ms intervals}
\NormalTok{t }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.}\NormalTok{, }\FloatTok{5.}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}

\CommentTok{# red dashes, blue squares and green triangles}
\NormalTok{plt.plot(t, t, }\StringTok{'r--'}\NormalTok{, t, t}\OperatorTok{**}\DecValTok{2}\NormalTok{, }\StringTok{'bs'}\NormalTok{, t, t}\OperatorTok{**}\DecValTok{3}\NormalTok{, }\StringTok{'g^'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-60-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ f(t):}
    \ControlFlowTok{return}\NormalTok{ np.exp(}\OperatorTok{-}\NormalTok{t) }\OperatorTok{*}\NormalTok{ np.cos(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi}\OperatorTok{*}\NormalTok{t)}

\NormalTok{t1 }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.0}\NormalTok{, }\FloatTok{5.0}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{t2 }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.0}\NormalTok{, }\FloatTok{5.0}\NormalTok{, }\FloatTok{0.02}\NormalTok{)}

\NormalTok{plt.figure()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.subplot(}\DecValTok{211}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot(t1, f(t1), }\StringTok{'bo'}\NormalTok{, t2, f(t2), }\StringTok{'k'}\NormalTok{)}\OperatorTok{;}

\NormalTok{plt.subplot(}\DecValTok{212}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot(t2, np.cos(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi}\OperatorTok{*}\NormalTok{t2), }\StringTok{'r--'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-61-1} \end{center}

\hypertarget{resources}{%
\section{Resources}\label{resources}}

A really nice online resource for learning data visualization in Python is the \href{https://python-graph-gallery.com/}{Python Graph Gallery}. This site has many examples of different kinds of plots using \texttt{pandas}, \texttt{seaborn} and \texttt{matplotlib}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reticulate}\OperatorTok{::}\KeywordTok{use_condaenv}\NormalTok{(}\StringTok{'ds'}\NormalTok{, }\DataTypeTok{required=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\hypertarget{statistical-analysis}{%
\chapter{Statistical analysis}\label{statistical-analysis}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Statistical analysis usually encompasses 3 activities in a data science workflow. These are (a) descriptive analysis, (b) hypothesis testing and (c) statistical modeling. Descriptive analysis refers to a description of the data, which includes computing summary statistics and drawing plots. Hypothesis testing usually refers to statistically seeing if two (or more) groups are different from each other based on some metrics. Modeling refers to fitting a curve to the data to describe the relationship patterns of different variables in a data set.

In terms of Python packages that can address these three tasks:

\begin{longtable}[]{@{}ll@{}}
\toprule
Task & Packages\tabularnewline
\midrule
\endhead
Descriptive statistics & pandas, numpy, matplotlib, seaborn\tabularnewline
Hypothesis testing & scipy, statsmodels\tabularnewline
Modeling & statsmodels, lifelines, scikit-learn\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{descriptive-statistics}{%
\section{Descriptive statistics}\label{descriptive-statistics}}

Descriptive statistics that are often computed are the mean, median, standard deviation, inter-quartile range, pairwise correlations, and the like. Most of these functions are available in \texttt{numpy}, and hence are available in \texttt{pandas}. We have already seen how we can compute these statistics and have even computed grouped statistics. For example, we will compute these using the diamonds dataset

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ scipy }\ImportTok{as}\NormalTok{ sc}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\NormalTok{sns.set_context(}\StringTok{'paper'}\NormalTok{)}
\NormalTok{sns.set_style(}\StringTok{'white'}\NormalTok{, \{}\StringTok{'font.family'}\NormalTok{: }\StringTok{'Future Medium'}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/diamonds.csv.gz'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds.groupby(}\StringTok{'color'}\NormalTok{)[}\StringTok{'price'}\NormalTok{].agg([np.mean, np.median, np.std])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              mean  median          std
color                                  
D      3169.954096  1838.0  3356.590935
E      3076.752475  1739.0  3344.158685
F      3724.886397  2343.5  3784.992007
G      3999.135671  2242.0  4051.102846
H      4486.669196  3460.0  4215.944171
I      5091.874954  3730.0  4722.387604
J      5323.818020  4234.0  4438.187251
\end{verbatim}

There were other examples we saw yesterday along these lines. Refer to both the \texttt{python\_tools\_ds} and \texttt{python\_pandas} documents

\hypertarget{classical-hypothesis-testing}{%
\section{Classical hypothesis testing}\label{classical-hypothesis-testing}}

Python has the tools to do classic hypothesis testing. Several functions are available in the \texttt{scipy.stats} module. The commonly used tests that are available are as follows:

\begin{longtable}[]{@{}ll@{}}
\toprule
Function & Test\tabularnewline
\midrule
\endhead
\texttt{ttest\_1samp} & One-sample t-test\tabularnewline
\texttt{ttest\_ind} & Two-sample t-test\tabularnewline
\texttt{ttest\_rel} & Paired t-test\tabularnewline
\texttt{wilcoxon} & Wilcoxon signed-rank test (nonparametric paired t-test)\tabularnewline
\texttt{mannwhitneyu} & Wilcoxon rank-sum test (nonparametric 2-sample t-test)\tabularnewline
\texttt{chi2\_contingency} & Chi-square test for independence\tabularnewline
\texttt{fisher\_exact} & Fisher's exact test on a 2x2 contingency table\tabularnewline
\texttt{f\_oneway} & One-way ANOVA\tabularnewline
\texttt{pearsonr} & Testing for correlation\tabularnewline
&\tabularnewline
\bottomrule
\end{longtable}

There are also several tests in \texttt{statsmodels.stats}

\begin{longtable}[]{@{}ll@{}}
\toprule
Functions & Tests\tabularnewline
\midrule
\endhead
\texttt{proportions\_ztest} & Test for difference in proportions\tabularnewline
\texttt{mcnemar} & McNemar's test\tabularnewline
\texttt{sign\_test} & Sign test\tabularnewline
\texttt{multipletests} & p-value correction for multiple tests\tabularnewline
\texttt{fdrcorrection} & p-value correction by FDR\tabularnewline
&\tabularnewline
\bottomrule
\end{longtable}

Let us look at a breast cancer proteomics experiment to illustrate this. The experimental data contains protein expression for over 12 thousand proteins, along with clinical data. We can ask, for example, whether a particular protein expression differs by ER status.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brca }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/brca.csv'}\NormalTok{)}
\NormalTok{brca.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Unnamed: 0 Complete TCGA ID  Gender  ...  NP_004065 NP_068752 NP_219494
0           0     TCGA-A2-A0CM  FEMALE  ...        NaN       NaN       NaN
1           1     TCGA-BH-A18Q  FEMALE  ...  -1.778435       NaN -3.069752
2           2     TCGA-A7-A0CE  FEMALE  ...        NaN       NaN       NaN
3           3     TCGA-D8-A142  FEMALE  ...        NaN       NaN       NaN
4           4     TCGA-AO-A0J6  FEMALE  ...        NaN       NaN -3.753616

[5 rows x 12585 columns]
\end{verbatim}

We will use both the t-test and the Wilcoxon rank-sum test, the nonparametric equivalent.

We will first do the classical t-test, that is available in the \texttt{scipy} package.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ scipy }\ImportTok{as}\NormalTok{ sc}
\ImportTok{import}\NormalTok{ statsmodels }\ImportTok{as}\NormalTok{ sm}
\NormalTok{test_probe }\OperatorTok{=} \StringTok{'NP_001193600'}

\NormalTok{tst }\OperatorTok{=}\NormalTok{ sc.stats.ttest_ind(brca[brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Positive'}\NormalTok{][test_probe], }\CommentTok{# Need [] since names have spaces}
\NormalTok{                   brca[brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Negative'}\NormalTok{][test_probe], }
\NormalTok{                  nan_policy }\OperatorTok{=} \StringTok{'omit'}\NormalTok{)}
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(tst.pvalue, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.277
\end{verbatim}

We will now do the Wilcoxon test, also known as the Mann-Whitney U test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tst }\OperatorTok{=}\NormalTok{ sc.stats.mannwhitneyu(brca[brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Positive'}\NormalTok{][test_probe], }\CommentTok{# Need [] since names have spaces}
\NormalTok{                   brca[brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Negative'}\NormalTok{][test_probe], }
\NormalTok{                  alternative }\OperatorTok{=} \StringTok{'two-sided'}\NormalTok{)}
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(tst.pvalue, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.996
\end{verbatim}

We will come back to this when we look at permutation tests below.

\hypertarget{simulation-and-inference}{%
\section{Simulation and inference}\label{simulation-and-inference}}

Hypothesis testing is one of the areas where statistics is often used. There are functions for a lot of the standard statistical tests in \texttt{scipy} and \texttt{statsmodels}. However, I'm going to take a little detour to see if we can get some understanding of hypothesis tests using the powerful simulation capabilities of Python. We'll visit the in-built functions available in \texttt{scipy} and \texttt{statsmodels} as well.

\hypertarget{simulation-and-hypothesis-testing}{%
\subsection{Simulation and hypothesis testing}\label{simulation-and-hypothesis-testing}}

\textbf{Question:} You have a coin and you flip it 100 times. You get 54 heads. How likely is it that you have a fair coin?

We can simulate this process, which is random, using Python. The process of heads and tails from coin tosses can be modeled as a \href{https://en.wikipedia.org/wiki/Binomial_distribution}{\textbf{binomial} distribution}. We can repeat this experiment many many times on our computer, making the assumption that we have a fair coin, and then seeing how likely what we observed is under that assumption.

\begin{quote}
Simulation under reasonable assumptions is a great way to understand our data and the underlying data generating processes. In the modern era, it has most famously been used by Nate Silver of ESPN to simulate national elections in the US. There are many examples in engineering where simulations are done to understand a technology and figure out its tolerances and weaknesses, like in aircraft testing. It is also commonly used in epidemic modeling to help understand how an epidemic would spread under different conditions.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{) }\CommentTok{# Seed the random number generator}

\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{) }\CommentTok{# Simulate 100,000 experiments of tossing a fair coin 100 times}

\NormalTok{sns.distplot(x, kde}\OperatorTok{=}\VariableTok{True}\NormalTok{, rug}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{plt.axvline(}\DecValTok{54}\NormalTok{, color }\OperatorTok{=} \StringTok{'r'}\NormalTok{)}\OperatorTok{;} \CommentTok{# What we observed}
\NormalTok{plt.xlabel(}\StringTok{'Number of heads'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We convert to pd.Series to take advantage of the `describe` function.}
\NormalTok{pd.Series(x).describe() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
count    100000.000000
mean         49.995590
std           5.011938
min          27.000000
25%          47.000000
50%          50.000000
75%          53.000000
max          72.000000
dtype: float64
\end{verbatim}

What we see from the histogram and the description of the data above is the patterns in data we would expect if we repeated this random experiment. We can already make some observations. First, we do see that the average number of heads we expect to get is 50, which validates that our experiment is using a fair coin. Second, we can reasonably get as few as 27 heads and as many as 72 heads even with a fair coin. In fact, we could look at what values we would expect to see 95\% of the time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.quantile(x, [}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([40., 60.])
\end{verbatim}

This says that 95\% of the time we'll see values between 40 and 60. (This is \textbf{not} a confidence interval. This is the actual results of a simulation study. A confidence interval would be computed based on a \textbf{single} experiment, assuming a binomial distribution. We'll come to that later).

So how likely would we be to see the 54 heads in 100 tosses assuming a fair coin? This can be computed as the proportion of experiments

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(x }\OperatorTok{>} \DecValTok{54}\NormalTok{) }\CommentTok{# convince yourself of this}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.18456
\end{verbatim}

This is what would be considered the \emph{p-value} for the test that the coin is fair.

\begin{quote}
The p-value of a statistical hypothesis test is the likelihood that we would see an outcome at least as extreme as we observed under the assumption that the null hypothesis (H0) that we chose is actually true.

In our case, that null hypothesis is that the coin we're tossing is fair. The p-value \textbf{only} gives evidence against the null hypothesis, but does \textbf{not} give evidence for the null hypothesis. In other words, if the p-value is small (smaller than some threshold we deem reasonable), then we can claim evidence against the null hypothesis, but if the p-value is large, we cannot say the null hypothesis is true.
\end{quote}

What happens if we increase the number of tosses, and we look at the proportion of heads. We observe 54\% heads.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}
\NormalTok{sns.distplot(x)}
\NormalTok{plt.axvline(}\FloatTok{0.54}\NormalTok{, color }\OperatorTok{=} \StringTok{'r'}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{'Proportion of heads'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.Series(x).describe()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
count    100000.000000
mean          0.499991
std           0.004994
min           0.478100
25%           0.496600
50%           0.500000
75%           0.503400
max           0.520300
dtype: float64
\end{verbatim}

Well, that changed the game significantly. If we up the number of coin tosses per experiment to 10,000, so 100-fold increase, then we do not see very much variation in the proportion of tosses that are heads.

\begin{quote}
This is expected behavior because of a statistical theorem called the \emph{Law of Large Numbers}, which essentially says that if you do larger and larger sized random experiments with the same experimental setup, your estimate of the true population parameter (in this case the true chance of getting a head, or 0.5 for a fair coin) will become more and more precise.
\end{quote}

Now we see that for a fair coin, we should reasonably see between 47.8\% and 52\% of tosses should be heads. This is quite an improvement from the 27\%-72\% range we saw with 100 tosses.

We can compute our p-value in the same way as before.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(x }\OperatorTok{>} \FloatTok{0.54}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.0
\end{verbatim}

So we would never see 54\% of our tosses be heads if we tossed a fair coin 10,000 times. Now, with a larger experiment, we would \textbf{reject} our null hypothesis H0 that we have a fair coin.

So same observation, but more data, changes our \emph{inference} from not having sufficient evidence to say that the coin isn't fair to saying that it isn't fair quite definitively. This is directly due to the increased precision of our estimates and thus our ability to differentiate between much smaller differences in the truth.

Let's see a bit more about what's going on here. Suppose we assume that the coin's true likelihood of getting a head is really 0.55, so a very small bias towards heads.

\begin{quote}
Food for thought: Is the difference between 0.50 and 0.54 worth worrying about? It probably depends.
\end{quote}

We're going to compare what we would reasonably see over many repeated experiments given the coin has a 0.50 (fair) and a 0.55 (slightly biased) chance of a head. First, we'll do experiments of 100 tosses of a coin.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x11 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{100} \CommentTok{# Getting proportion of heads}
\NormalTok{x12 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.55}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{100} 

\NormalTok{sns.distplot(x11, label }\OperatorTok{=} \StringTok{'Fair'}\NormalTok{)}
\NormalTok{sns.distplot(x12, label }\OperatorTok{=} \StringTok{'Biased'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<matplotlib.axes._subplots.AxesSubplot object at 0x12e19b040>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.xlabel(}\StringTok{'Proportion of heads'}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We see that there is a great deal of overlap in the potential outcomes over 100,000 repetitions of these experiments, so we have a lot of uncertainty about which model (fair or biased) is the truth.

Now, if we up our experiment to 10,000 tosses of each coin, and again repeat the experiment 100,000 times,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x21 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}
\NormalTok{x22 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.55}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}

\NormalTok{sns.distplot(x21, label }\OperatorTok{=} \StringTok{'Fair'}\NormalTok{)}
\NormalTok{sns.distplot(x22, label }\OperatorTok{=} \StringTok{'Biased'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<matplotlib.axes._subplots.AxesSubplot object at 0x12e19b040>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.xlabel(}\StringTok{'Proportion of heads'}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We now find almost no overlap between the potential outcomes, so we can very easily distinguish the two models. This is part of what gathering more data (number of tosses) buys you.

We typically measure this ability to distinguish between two models using concepts of \emph{statistical power}, which is the likelihood that we would find an observation at least as extreme as what we observed, under the \textbf{alternative} model (in this case, the biased coin model). We can calculate the statistical power quite easily for the two sets of simulated experiments. Remember, we observed 54\% heads in our one instance of each experiment that we actually observed. By doing simulations, we're ``playing God'' and seeing what could have happened, but in practice we only do the experiment once (how many clinical trials of an expensive drug would you really want to do?).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pval1 }\OperatorTok{=}\NormalTok{ np.mean(x11 }\OperatorTok{>} \FloatTok{0.54}\NormalTok{)}
\NormalTok{pval2 }\OperatorTok{=}\NormalTok{ np.mean(x21 }\OperatorTok{>} \FloatTok{0.54}\NormalTok{)}

\NormalTok{power1 }\OperatorTok{=}\NormalTok{ np.mean(x12 }\OperatorTok{>} \FloatTok{0.54}\NormalTok{)}
\NormalTok{power2 }\OperatorTok{=}\NormalTok{ np.mean(x22 }\OperatorTok{>} \FloatTok{0.54}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{'The p-value when n=100 is '}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(pval1, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The p-value when n=100 is  0.18
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{'The p-value when n=10,000 is '}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(pval2, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The p-value when n=10,000 is  0.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{'Statistical power when n=100 is '}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(power1, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Statistical power when n=100 is  0.54
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{'Statistical power when n=10,000 is '}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(power2, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Statistical power when n=10,000 is  0.98
\end{verbatim}

So as \emph{n} goes up, the p-value for the same experimental outcome goes down and the statistical power goes up. This is a general rule with increasing sample size.

This idea can be used to design a two-armed experiment. Suppose we are looking at the difference in proportion of mice who gained weight between a wild-type mouse and a knockout variant. Since mice are expensive, let's limit the number of mice we'll use in each arm to 10. We expect 30\% of the wild-type mice to gain weight, and expect a higher proportion of the knockouts will gain weight. This is again the setup for a binomial experiment, with the number of ``coin tosses'' being 10 for each of the arms. We're going to do two sets of experiments, one for the WT and one for the KO, and see the difference in proportions of weight gain (`heads') between them, and repeat it 100,000 times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{N }\OperatorTok{=} \DecValTok{10}
\NormalTok{weight_gain_wt0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{# Get proportion}
\NormalTok{weight_gain_ko0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{# Assume first (null hypothesis) that there is no difference}

\NormalTok{diff_weight_gain0 }\OperatorTok{=}\NormalTok{ weight_gain_ko0 }\OperatorTok{-}\NormalTok{ weight_gain_wt0}
\NormalTok{sns.distplot(diff_weight_gain0, kde}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;} \CommentTok{# Since we only have 10 mice each, this histogram is not very smooth. }
                                           \CommentTok{# No matter!}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/04-python-stat-14-1} \end{center}

We usually design the actual test by choosing a cutoff in the difference in proportions and stating that we will reject the null hypothesis if our observed difference exceeds this cutoff. We choose the cutoff so that the p-value of the cutoff is some pre-determined error rate, typically 0.05 or 5\% (This is not golden or set in stone. We'll discuss this later). Let's find that cutoff from this simulation. This will correspond to the 95th percentile of this simulated distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(np.quantile(diff_weight_gain0, }\FloatTok{0.95}\NormalTok{), }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.3
\end{verbatim}

This means that at least 5\% of the values will be 0.3 or bigger. In fact, this proportion is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(diff_weight_gain0 }\OperatorTok{>} \FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.06673
\end{verbatim}

So we'll take 0.3 as the cutoff for our test (It's fine if the Type 1 error is more than 0.05. If we take the next largest value in the simulation, we dip below 0.05). We're basically done specifying the testing rule.

What we (and reviewers) like to know at this point is, what is the difference level for which you might get 80\% power. The thinking is that if the true difference was, say, \emph{p \textgreater{} 0} rather than 0 (under the null hypothesis), we would reject the null hypothesis, i.e., get our observed difference to be more than 0.3, at least 80\% of the time. We want to find out how big that value of \emph{p} is. In other words, what is the level of difference in proportions at which we can be reasonably certain that our test will REJECT H0, given our sample size, when the true difference in proportions is \emph{p}. Another way of saying this is how big does the difference in true proportions have to be before we would be fairly confident statistically of distinguishing that we have a difference between the two groups given our chosen sample size, i.e., fairly small overlaps in the two competing distributions.

We can also do this using simulation, by keeping the WT group at 0.3, increasing the KO group gradually, simulating the distribution of the difference in proportion and seeing at what point we get to a statistical power of about 80\%. Recall, we've already determined that our test will reject H0 when the observed difference is greater than 0.3

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{=}\NormalTok{ np.linspace(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{power }\OperatorTok{=}\NormalTok{ np.zeros(}\BuiltInTok{len}\NormalTok{(p1))}
\ControlFlowTok{for}\NormalTok{ i, p }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(p1):}
\NormalTok{    weight_gain_wt1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    weight_gain_ko1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, p, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    diff_weight_gain1 }\OperatorTok{=}\NormalTok{ weight_gain_ko1 }\OperatorTok{-}\NormalTok{ weight_gain_wt1}
\NormalTok{    power[i] }\OperatorTok{=}\NormalTok{ np.mean(diff_weight_gain1 }\OperatorTok{>} \FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(p1, power)}
\NormalTok{plt.axhline(}\FloatTok{0.8}\NormalTok{, color }\OperatorTok{=} \StringTok{'black'}\NormalTok{, linestyle }\OperatorTok{=} \StringTok{'--'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'Statistical power'}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{'Proportion in KO mice'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(p1[np.argmin(np.}\BuiltInTok{abs}\NormalTok{(power }\OperatorTok{-} \FloatTok{0.8}\NormalTok{))] }\OperatorTok{-} \FloatTok{0.3}\NormalTok{, }\DecValTok{2}\NormalTok{) }\CommentTok{# Find the location in the p1 array where power is closest to 0.8}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.48
\end{verbatim}

So to get to 80\% power, we would need the true difference in proportion to be 0.48, or that at least 78\% of KO mice should gain weight on average. This is quite a big difference, and its probably not very interesting scientifically to look for such a big difference, since it's quite unlikely.

If we could afford 100 mice per arm, what would this look like?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{N }\OperatorTok{=} \DecValTok{100}
\NormalTok{weight_gain_wt0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{# Get proportion}
\NormalTok{weight_gain_ko0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{# Assume first (null hypothesis) that there is no difference}

\NormalTok{diff_weight_gain0 }\OperatorTok{=}\NormalTok{ weight_gain_ko0 }\OperatorTok{-}\NormalTok{ weight_gain_wt0}
\NormalTok{cutoff }\OperatorTok{=}\NormalTok{ np.quantile(diff_weight_gain0, }\FloatTok{0.95}\NormalTok{)}

\NormalTok{p1 }\OperatorTok{=}\NormalTok{ np.linspace(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{power }\OperatorTok{=}\NormalTok{ np.zeros(}\BuiltInTok{len}\NormalTok{(p1))}
\ControlFlowTok{for}\NormalTok{ i, p }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(p1):}
\NormalTok{    weight_gain_wt1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    weight_gain_ko1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, p, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    diff_weight_gain1 }\OperatorTok{=}\NormalTok{ weight_gain_ko1 }\OperatorTok{-}\NormalTok{ weight_gain_wt1}
\NormalTok{    power[i] }\OperatorTok{=}\NormalTok{ np.mean(diff_weight_gain1 }\OperatorTok{>}\NormalTok{ cutoff)}

\NormalTok{sns.lineplot(p1, power)}
\NormalTok{plt.axhline(}\FloatTok{0.8}\NormalTok{, color }\OperatorTok{=} \StringTok{'black'}\NormalTok{, linestyle }\OperatorTok{=} \StringTok{'--'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'Statistical power'}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{'Proportion in KO mice'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(p1[np.argmin(np.}\BuiltInTok{abs}\NormalTok{(power }\OperatorTok{-} \FloatTok{0.8}\NormalTok{))] }\OperatorTok{-} \FloatTok{0.3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.17
\end{verbatim}

The minimum detectable difference for 80\% power is now down to 0.17, so we'd need the KO mice in truth to show weight gain 47\% of the time, compared to 30\% in WT mice. This is more reasonable scientifically as a query.

\hypertarget{a-permutation-test}{%
\subsection{A permutation test}\label{a-permutation-test}}

A permutation test is a 2-group test that asks whether two groups are different with respect to some metric. We'll use the same proteomic data set as before.

The idea about a permutation test is that, if there is truly no difference then it shouldn't make a difference if we shuffled the labels of ER status over the study individuals. That's literally what we will do. We will do this several times, and look at the average difference in expression each time. This will form the null distribution under our assumption of no differences by ER status. We'll then see where our observed data falls, and then be able to compute a p-value.

The difference between the simulations we just did and a permutation test is that the permutation test is based only on the observed data. No particular models are assumed and no new data is simulated. All we're doing is shuffling the labels among the subjects, but keeping their actual data intact.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{10000}

\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{294}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.where(brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Positive'}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ brca[test_probe].to_numpy()}

\NormalTok{obs_diff }\OperatorTok{=}\NormalTok{ np.nanmean(y[x}\OperatorTok{==}\DecValTok{1}\NormalTok{]) }\OperatorTok{-}\NormalTok{ np.nanmean(y[x}\OperatorTok{==-}\DecValTok{1}\NormalTok{])}

\NormalTok{diffs }\OperatorTok{=}\NormalTok{ np.zeros(nsim)}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(nsim):}
\NormalTok{    x1 }\OperatorTok{=}\NormalTok{ rng.permutation(x)}
\NormalTok{    diffs[i] }\OperatorTok{=}\NormalTok{ np.nanmean(y[x1}\OperatorTok{==}\DecValTok{1}\NormalTok{]) }\OperatorTok{-}\NormalTok{ np.nanmean(y[x1 }\OperatorTok{==} \DecValTok{-1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(diffs)}
\NormalTok{plt.axvline(x }\OperatorTok{=}\NormalTok{ obs_diff, color }\OperatorTok{=}\StringTok{'r'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.axvline(x }\OperatorTok{=} \OperatorTok{-}\NormalTok{obs_diff, color }\OperatorTok{=} \StringTok{'r'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pval }\OperatorTok{=}\NormalTok{ np.mean(np.}\BuiltInTok{abs}\NormalTok{(diffs) }\OperatorTok{>}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(obs_diff))}
\SpecialStringTok{f"P-value from permutation test is }\SpecialCharTok{\{}\NormalTok{pval}\SpecialCharTok{\}}\SpecialStringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'P-value from permutation test is 0.2606'
\end{verbatim}

This is pretty close to what we got from the t-test.

Note that what we've done here is the two-sided test to see how extreme our observation would be in either direction. That is why we've taken the absolute values above, and drawn both the
observed value and it's negative on the graph.

\hypertarget{testing-many-proteins}{%
\subsection{Testing many proteins}\label{testing-many-proteins}}

We could do the permutation test all the proteins using the array operations in \texttt{numpy}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expr_names }\OperatorTok{=}\NormalTok{ [u }\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in} \BuiltInTok{list}\NormalTok{(brca.columns) }\ControlFlowTok{if}\NormalTok{ u.find(}\StringTok{'NP'}\NormalTok{) }\OperatorTok{>} \DecValTok{-1}\NormalTok{] }
            \CommentTok{# Find all column names with NP}

\NormalTok{exprs }\OperatorTok{=}\NormalTok{ brca[expr_names] }\CommentTok{# Extract the protein data}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.where(brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Positive'}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{obs_diffs }\OperatorTok{=}\NormalTok{ exprs[x}\OperatorTok{==}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}\OperatorTok{-}\NormalTok{exprs[x}\OperatorTok{==-}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{1000}
\NormalTok{diffs }\OperatorTok{=}\NormalTok{ np.zeros((nsim, exprs.shape[}\DecValTok{1}\NormalTok{]))}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(nsim):}
\NormalTok{    x1 }\OperatorTok{=}\NormalTok{ rng.permutation(x)}
\NormalTok{    diffs[i,:] }\OperatorTok{=}\NormalTok{exprs[x1}\OperatorTok{==}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{) }\OperatorTok{-}\NormalTok{ exprs[x1}\OperatorTok{==-}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvals }\OperatorTok{=}\NormalTok{ np.zeros(exprs.shape[}\DecValTok{1}\NormalTok{])}
\BuiltInTok{len}\NormalTok{(pvals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
12395
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(pvals)):}
\NormalTok{    pvals[i] }\OperatorTok{=}\NormalTok{ np.mean(np.}\BuiltInTok{abs}\NormalTok{(diffs[:,i]) }\OperatorTok{>}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(obs_diffs.iloc[i]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:2: RuntimeWarning: invalid value encountered in greater
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(pvals)}\OperatorTok{;}
\NormalTok{plt.title(}\StringTok{'Results of permutation test'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/04-python-stat-31-1} \end{center}

This plot shows that there is probably some proteins which are differentially expressed between ER+ and ER- patients. (If no proteins had any difference, this histogram would be flat, since the p-values would be uniformly distributed). The ideas around Gene Set Enrichment Analysis (GSEA) can also be applied here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exprs_shortlist }\OperatorTok{=}\NormalTok{ [u }\ControlFlowTok{for}\NormalTok{ i, u }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(}\BuiltInTok{list}\NormalTok{(exprs.columns)) }
                   \ControlFlowTok{if}\NormalTok{ pvals[i] }\OperatorTok{<} \FloatTok{0.0001}\NormalTok{ ]}

\BuiltInTok{len}\NormalTok{(exprs_shortlist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
896
\end{verbatim}

This means that, if we considered a p-value cutoff for screening at 0.0001, we would select 896 of the 12395 proteins for further study. Note that if none of the proteins had any effect, we'd expect 0.0001 x 12395 or 13 proteins to have a p-value smaller than 0.0001.

We could also do the same thing using both the t-test and the Mann-Whitney test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groups }\OperatorTok{=}\NormalTok{ np.where(brca[}\StringTok{'ER Status'}\NormalTok{]}\OperatorTok{==}\StringTok{'Positive'}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{pvals_t }\OperatorTok{=}\NormalTok{ np.zeros(exprs.shape[}\DecValTok{1}\NormalTok{])}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(exprs.shape[}\DecValTok{1}\NormalTok{]):}
\NormalTok{    stat, pvals_t[i] }\OperatorTok{=}\NormalTok{ sc.stats.ttest_ind(exprs.iloc[groups}\OperatorTok{==}\DecValTok{1}\NormalTok{, i],}
\NormalTok{                              exprs.iloc[groups}\OperatorTok{==}\DecValTok{0}\NormalTok{, i],}
\NormalTok{                              nan_policy }\OperatorTok{=} \StringTok{'omit'}\NormalTok{)}
\NormalTok{sns.distplot(pvals_t)}\OperatorTok{;}
\NormalTok{plt.title(}\StringTok{'Results of t-test'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvals_w }\OperatorTok{=}\NormalTok{ np.zeros(exprs.shape[}\DecValTok{1}\NormalTok{])}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(exprs.shape[}\DecValTok{1}\NormalTok{]):}
\NormalTok{    stats, pvals_w[i] }\OperatorTok{=}\NormalTok{ sc.stats.mannwhitneyu(exprs.iloc[groups}\OperatorTok{==}\DecValTok{1}\NormalTok{,i], }
\NormalTok{                                            exprs.iloc[groups}\OperatorTok{==}\DecValTok{0}\NormalTok{, i],}
\NormalTok{                                             alternative}\OperatorTok{=}\StringTok{'two-sided'}\NormalTok{)}
\NormalTok{sns.distplot(pvals_w)}\OperatorTok{;}
\NormalTok{plt.title(}\StringTok{'Results of Wilcoxon test'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We can directly compare the graphs, which appear quite similar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{, sharex }\OperatorTok{=} \VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(pvals, ax }\OperatorTok{=}\NormalTok{ ax[}\DecValTok{0}\NormalTok{])}\OperatorTok{;}\NormalTok{ ax[}\DecValTok{0}\NormalTok{].set_ylabel(}\StringTok{'Permutation'}\NormalTok{)}\OperatorTok{;}
\NormalTok{sns.distplot(pvals_t, ax }\OperatorTok{=}\NormalTok{ ax[}\DecValTok{1}\NormalTok{])}\OperatorTok{;}\NormalTok{ ax[}\DecValTok{1}\NormalTok{].set_ylabel(}\StringTok{'t-test'}\NormalTok{)}\OperatorTok{;}
\NormalTok{sns.distplot(pvals_w, ax }\OperatorTok{=}\NormalTok{ ax[}\DecValTok{2}\NormalTok{])}\OperatorTok{;}\NormalTok{ ax[}\DecValTok{2}\NormalTok{].set_ylabel(}\StringTok{'Wilcoxon'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We can also compare how many proteins will be chosen if we employ a p-value cutoff of 0.0001

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvalues }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{'permutation'}\NormalTok{ : pvals, }\StringTok{'ttest'}\NormalTok{ : pvals_t,}
                           \StringTok{'wilcoxon'}\NormalTok{ : pvals_w\})}
\NormalTok{pvalues.}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ x: np.}\BuiltInTok{sum}\NormalTok{(x }\OperatorTok{<} \FloatTok{0.0001}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
permutation    896
ttest          499
wilcoxon       396
dtype: int64
\end{verbatim}

\begin{quote}
The \textbf{lambda function} employed above is an anonymous (un-named) function that
can be used on-the-fly. In the above statement, this function takes one (vector) argument \emph{x} and computes the number of \emph{x} values less than 0.0001. This function is then applied to each column of the \texttt{pvalues} dataset using the \texttt{apply} function.
\end{quote}

\hypertarget{getting-a-confidence-interval-using-the-bootstrap}{%
\subsection{Getting a confidence interval using the bootstrap}\label{getting-a-confidence-interval-using-the-bootstrap}}

We can use simulations to obtain a model-free confidence interval for particular parameters of interest based on our observed data. The technique we will demonstrate is called the bootstrap. The idea is that if we sample with replacement from our observed data to get another data set of the same size as the observed data, and compute our statistic of interest, and then repeat this process many times, then the distribution of our statistic that we will obtain this way will be very similar to the true sampling distribution of the statistic if we could ``play God''. This has strong theoretical foundations from work done by several researchers in the 80s and 90s.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose the number of simulations \texttt{nsim}
\item
  for each iteration (1,\ldots,nsim)

  \begin{itemize}
  \tightlist
  \item
    Simulate a dataset with replacement from the original data.
  \item
    compute and store the statistic
  \end{itemize}
\item
  Compute the 2.5th and 97.5th percential of the distribution of the statistic. This is your confidence interval.
\end{enumerate}

Let's see this in action. Suppose we tossed a coin 100 times. We're going to find a confidence interval for the proportion of heads from this coin.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.7}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,
       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,
       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,
       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1])
\end{verbatim}

This gives the sequence of heads (1) and tails (0), assuming the true probability of heads is 0.7.

We now create 100000 bootstrap samples from here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{100000}

\NormalTok{boots }\OperatorTok{=}\NormalTok{ np.random.choice(x, (}\BuiltInTok{len}\NormalTok{(x), nsim), replace }\OperatorTok{=} \VariableTok{True}\NormalTok{) }\CommentTok{# sample from the data}
\NormalTok{boot_estimates }\OperatorTok{=}\NormalTok{ boots.mean(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{) }\CommentTok{# compute mean of each sample, i.e proportion of heads}

\NormalTok{sns.distplot(boot_estimates)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.quantile(boot_estimates, (}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{)) }\CommentTok{# Find 2.5 and 97.5-th percentiles}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.66, 0.83])
\end{verbatim}

So our 95\% bootstrap confidence interval is (0.66, 0.83). Our true value of 0.7 certainly falls in it.

\hypertarget{regression-analysis}{%
\section{Regression analysis}\label{regression-analysis}}

\hypertarget{ordinary-least-squares-linear-regression}{%
\subsection{Ordinary least squares (linear) regression}\label{ordinary-least-squares-linear-regression}}

The regression modeling frameworks in Python are mainly in \texttt{statsmodels}, though some of it can be found in \texttt{scikit-learn} which we will see tomorrow. We will use the diamonds dataset for demonstration purposes. We will attempt to model the diamond price against several of the other diamond characteristics.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ statsmodels.api }\ImportTok{as}\NormalTok{ sm}
\ImportTok{import}\NormalTok{ statsmodels.formula.api }\ImportTok{as}\NormalTok{ smf }\CommentTok{# Use the formula interface to statsmodels}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'diamonds'}\NormalTok{,}\StringTok{'ggplot2'}\NormalTok{).data}
\NormalTok{mod1 }\OperatorTok{=}\NormalTok{ smf.ols(}\StringTok{'price ~ np.log(carat) + clarity + depth + cut * color'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ diamonds).fit()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1.summary()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.786
Model:                            OLS   Adj. R-squared:                  0.786
Method:                 Least Squares   F-statistic:                     4598.
Date:                Fri, 07 Aug 2020   Prob (F-statistic):               0.00
Time:                        00:57:33   Log-Likelihood:            -4.8222e+05
No. Observations:               53940   AIC:                         9.645e+05
Df Residuals:                   53896   BIC:                         9.649e+05
Df Model:                          43                                         
Covariance Type:            nonrobust                                         
===============================================================================================
                                  coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------------------
Intercept                    2745.0643    415.804      6.602      0.000    1930.085    3560.043
clarity[T.IF]                4916.7221     83.694     58.746      0.000    4752.681    5080.763
clarity[T.SI1]               2686.1493     71.397     37.623      0.000    2546.210    2826.088
clarity[T.SI2]               2060.8180     71.809     28.699      0.000    1920.072    2201.564
clarity[T.VS1]               3710.1759     72.891     50.900      0.000    3567.309    3853.043
clarity[T.VS2]               3438.3999     71.792     47.894      0.000    3297.687    3579.112
clarity[T.VVS1]              4540.1420     77.314     58.724      0.000    4388.606    4691.678
clarity[T.VVS2]              4343.0545     75.136     57.803      0.000    4195.788    4490.321
cut[T.Good]                   708.5981    161.869      4.378      0.000     391.334    1025.862
cut[T.Ideal]                 1198.2067    149.690      8.005      0.000     904.812    1491.601
cut[T.Premium]               1147.1417    152.896      7.503      0.000     847.464    1446.820
cut[T.Very Good]             1011.3463    152.977      6.611      0.000     711.510    1311.183
color[T.E]                    -59.4094    190.227     -0.312      0.755    -432.256     313.437
color[T.F]                    -86.0097    178.663     -0.481      0.630    -436.191     264.172
color[T.G]                   -370.6455    178.642     -2.075      0.038    -720.784     -20.507
color[T.H]                   -591.0922    179.786     -3.288      0.001    -943.474    -238.710
color[T.I]                  -1030.7417    201.485     -5.116      0.000   -1425.655    -635.829
color[T.J]                  -1210.6501    223.111     -5.426      0.000   -1647.949    -773.351
cut[T.Good]:color[T.E]        -30.3553    212.126     -0.143      0.886    -446.123     385.413
cut[T.Ideal]:color[T.E]      -211.3711    195.630     -1.080      0.280    -594.807     172.065
cut[T.Premium]:color[T.E]     -91.3261    199.440     -0.458      0.647    -482.230     299.578
cut[T.Very Good]:color[T.E]   -45.2968    199.656     -0.227      0.821    -436.625     346.031
cut[T.Good]:color[T.F]       -365.4060    202.035     -1.809      0.071    -761.397      30.585
cut[T.Ideal]:color[T.F]      -198.0428    184.498     -1.073      0.283    -559.661     163.575
cut[T.Premium]:color[T.F]    -322.8527    188.465     -1.713      0.087    -692.246      46.540
cut[T.Very Good]:color[T.F]  -186.0519    189.090     -0.984      0.325    -556.670     184.566
cut[T.Good]:color[T.G]        -93.0430    202.404     -0.460      0.646    -489.757     303.671
cut[T.Ideal]:color[T.G]       -65.8579    183.980     -0.358      0.720    -426.461     294.745
cut[T.Premium]:color[T.G]      35.4302    187.596      0.189      0.850    -332.260     403.121
cut[T.Very Good]:color[T.G]   -81.2595    188.786     -0.430      0.667    -451.282     288.764
cut[T.Good]:color[T.H]        137.0235    205.696      0.666      0.505    -266.142     540.189
cut[T.Ideal]:color[T.H]       -83.4763    186.060     -0.449      0.654    -448.155     281.202
cut[T.Premium]:color[T.H]     -44.4372    189.378     -0.235      0.814    -415.620     326.745
cut[T.Very Good]:color[T.H]   -43.2485    190.851     -0.227      0.821    -417.318     330.821
cut[T.Good]:color[T.I]        331.4048    228.614      1.450      0.147    -116.681     779.490
cut[T.Ideal]:color[T.I]       106.2368    208.391      0.510      0.610    -302.210     514.684
cut[T.Premium]:color[T.I]     357.1453    212.341      1.682      0.093     -59.045     773.335
cut[T.Very Good]:color[T.I]   149.1555    213.697      0.698      0.485    -269.693     568.004
cut[T.Good]:color[T.J]       -406.8484    256.938     -1.583      0.113    -910.448      96.752
cut[T.Ideal]:color[T.J]      -330.0602    234.063     -1.410      0.159    -788.826     128.706
cut[T.Premium]:color[T.J]    -156.8065    236.860     -0.662      0.508    -621.055     307.442
cut[T.Very Good]:color[T.J]  -381.5722    238.799     -1.598      0.110    -849.620      86.475
np.log(carat)                6630.7799     15.605    424.923      0.000    6600.195    6661.365
depth                          -0.7353      5.961     -0.123      0.902     -12.418      10.948
==============================================================================
Omnibus:                    13993.592   Durbin-Watson:                   0.134
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            34739.732
Skew:                           1.432   Prob(JB):                         0.00
Kurtosis:                       5.693   Cond. No.                     7.08e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 7.08e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
"""
\end{verbatim}

This is the basic syntax for modeling in statsmodels using the \emph{formula} interface. This formula interface mimics the way regression formula are written in R. We will use this formula interface here since it allows for a more concise expression of the regression formula, and handles several things, as we will see.

\begin{quote}
\texttt{statsmodels} provides a traditional input syntax as well, where you
specify the dependent or \emph{endogenous} variable \emph{y} as a vector array, and the
independent or \emph{exogenous} variables \emph{X} as a numerical matrix. The typical syntax would be \texttt{mod2\ =\ sm.OLS(y,\ X).fit()}. The formula interface,
which uses the Python package \textbf{patsy}, takes care of the conversions, as
well as modifying the design matrix to accommodate interactions and
transformations.
\end{quote}

Let's go through and parse it.

One thing you notice is that we've written a formula inside the model

\begin{verbatim}
mod1 = smf.glm('price ~ np.log(carat) + clarity + depth + cut * color', 
    data = diamonds).fit()
\end{verbatim}

This formula will read as
``price depends on log(carat), clarity, depth, cut and color, and the interaction of cut and color''. Underneath a lot is going on.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  color, clarity, and cut are all categorical variables. They actually need to be expanded into dummy variables, so we will have one column for each category level, which is 1 when the diamond is of that category and 0 otherwise. We typically use the \textbf{treatment} contrast formulation, which deems one category (usually the first) to be the reference category, and so creates one less dummy variable than the number of category levels, corresponding to the reference level.
\item
  An intercept term is added
\item
  The variable \texttt{carat} is transformed using \texttt{np.log}, i.e.~the natural logarithm available in the \texttt{numpy} package. Generally, any valid Python function can be used here, even ones you create.
\item
  Interactions are computed. The syntax \texttt{cut\ *\ color} is a shortcut for \texttt{cut\ +\ color\ +\ cut:color}, where the \texttt{:} denotes interaction.
\item
  The dummy variables are concatenated to the continuous variables
\item
  The model is run
\end{enumerate}

To see the full design matrix we can drop down and use \textbf{patsy} functions:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ patsy}
\NormalTok{f }\OperatorTok{=}\NormalTok{ mod1.model.formula}
\NormalTok{y,X }\OperatorTok{=}\NormalTok{ patsy.dmatrices(f, data }\OperatorTok{=}\NormalTok{ diamonds, return_type }\OperatorTok{=} \StringTok{'dataframe'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\emph{X} is the full design matrix with all the transformations and dummy variables and interactions computed, as specified by the formula.

Suppose we wanted the Ideal cut of diamond to be the reference level for the \texttt{cut} variable. We could specify this within the formula quite simply as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod2 }\OperatorTok{=}\NormalTok{ smf.ols(}\StringTok{'price ~ np.log(carat) + clarity + depth + C(cut, Treatment("Ideal")) * color'}\NormalTok{, data }\OperatorTok{=}\NormalTok{ diamonds).fit()}
\end{Highlighting}
\end{Shaded}

This syntax says that we consider \texttt{cut} to be a categorical variable,
from which we will create dummy variables using \emph{treatment} contrasts,
using Ideal as the reference level.

\hypertarget{logistic-regression}{%
\subsection{Logistic regression}\label{logistic-regression}}

Logistic regression is the usual regression method used when you have
binary outcomes, e.g., Yes/No, Negative/Positive, etc.

Logistic regression does exist as an individual method in \textbf{scikit-learn}, whic we will see in the Machine Learning module. However, it resides in its more traditional form within the \emph{generalized linear model} framework in \textbf{statsmodels}

We will use a dataset based on deaths from the Titanic disaster in 1912.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'Titanic'}\NormalTok{,}\StringTok{'Stat2Data'}\NormalTok{).data}
\NormalTok{titanic.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1313 entries, 0 to 1312
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Name      1313 non-null   object 
 1   PClass    1313 non-null   object 
 2   Age       756 non-null    float64
 3   Sex       1313 non-null   object 
 4   Survived  1313 non-null   int64  
 5   SexCode   1313 non-null   int64  
dtypes: float64(1), int64(2), object(3)
memory usage: 61.7+ KB
\end{verbatim}

We will model \texttt{Survived} on the age, sex and passenger class of passengers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod_logistic }\OperatorTok{=}\NormalTok{ smf.glm(}\StringTok{'Survived ~ Age + Sex + PClass'}\NormalTok{, data}\OperatorTok{=}\NormalTok{titanic,}
\NormalTok{  family }\OperatorTok{=}\NormalTok{ sm.families.Binomial()).fit()}
\NormalTok{mod_logistic.summary()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'statsmodels.iolib.summary.Summary'>
"""
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               Survived   No. Observations:                  756
Model:                            GLM   Df Residuals:                      751
Model Family:                Binomial   Df Model:                            4
Link Function:                  logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -347.57
Date:                Fri, 07 Aug 2020   Deviance:                       695.14
Time:                        00:57:35   Pearson chi2:                     813.
No. Iterations:                     5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          z      P>|z|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         1.8664      0.217      8.587      0.000       1.440       2.292
Sex[T.male]      -2.6314      0.202    -13.058      0.000      -3.026      -2.236
PClass[T.1st]     1.8933      0.208      9.119      0.000       1.486       2.300
PClass[T.2nd]     0.6013      0.148      4.052      0.000       0.310       0.892
PClass[T.3rd]    -0.6282      0.132     -4.754      0.000      -0.887      -0.369
Age              -0.0392      0.008     -5.144      0.000      -0.054      -0.024
=================================================================================
"""
\end{verbatim}

The \texttt{family\ =\ sm.families.Binomial()} tells us that we're fitting a logistic
regression, since we are stating that the outcomes are from a Binomial distribution. (See the \href{https://www.statsmodels.org/stable/glm.html\#families}{API documentation} for a list of available distributions for GLMs).

The coefficients in a logistic regression are the \emph{log-odds ratios}. To get the odds ratios, we would need to exponentiate them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.exp(mod_logistic.params.drop(}\StringTok{'Intercept'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Sex[T.male]      0.071981
PClass[T.1st]    6.640989
PClass[T.2nd]    1.824486
PClass[T.3rd]    0.533574
Age              0.961581
dtype: float64
\end{verbatim}

\begin{quote}
The intercept term in a logistic regression is \textbf{not} a log-odds ratio, so we omit it by using the \texttt{drop} function.
\end{quote}

\hypertarget{survival-analysis}{%
\subsection{Survival analysis}\label{survival-analysis}}

Survival analysis or reliability analysis deals typically with data on
time to an event, where this time can be \emph{censored} at the end of observation. Examples include time to death for cancer patients, time to failure of a car transmission, etc. Censoring would mean that the subject is still alive/working when we last observed.

A common regression method for survival data is Cox proportional hazards regression. As an example, we will use a data set from a VA lung cancer study.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{veteran }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'veteran'}\NormalTok{, }\StringTok{'survival'}\NormalTok{).data}

\NormalTok{mod_cph }\OperatorTok{=}\NormalTok{ smf.phreg(}\StringTok{'time ~ C(trt) + celltype + age + C(prior)'}\NormalTok{,}
\NormalTok{  data }\OperatorTok{=}\NormalTok{ veteran, status }\OperatorTok{=}\NormalTok{ veteran.status).fit()}
\NormalTok{mod_cph.summary()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'statsmodels.iolib.summary2.Summary'>
"""
                              Results: PHReg
===========================================================================
Model:                         PH Reg            Sample size:           137
Dependent variable:            time              Num. events:           128
Ties:                          Breslow                                     
---------------------------------------------------------------------------
                       log HR log HR SE   HR      t    P>|t|  [0.025 0.975]
---------------------------------------------------------------------------
C(trt)[T.2]            0.1734    0.2016 1.1893  0.8600 0.3898 0.8011 1.7655
celltype[T.large]     -0.8817    0.2962 0.4141 -2.9761 0.0029 0.2317 0.7400
celltype[T.smallcell] -0.0956    0.2649 0.9088 -0.3609 0.7182 0.5407 1.5275
celltype[T.squamous]  -1.1738    0.2997 0.3092 -3.9173 0.0001 0.1718 0.5563
C(prior)[T.10]         0.0378    0.2064 1.0385  0.1833 0.8546 0.6930 1.5563
age                    0.0042    0.0096 1.0042  0.4401 0.6598 0.9855 1.0233
===========================================================================
Confidence intervals are for the hazard ratios
"""
\end{verbatim}

\begin{quote}
For survival regression, we need to input the status of the subject
at time of last follow-up, coded as 1 for failure/death, 0 for censored.
\end{quote}

\textbf{Question:} Why did I use \texttt{C(trt)} instead of \texttt{trt} in the formula?

We can do a few more basic things for this data. First, let's draw the
survival curve, which plots the proportion of subjects still alive against time, using the Kaplan-Meier method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf }\OperatorTok{=}\NormalTok{ sm.duration.SurvfuncRight(veteran.time, veteran.status)}
\NormalTok{sf.plot()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/statsmodels/graphics/utils.py:55: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.grid(}\VariableTok{True}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.xlabel(}\StringTok{'Time'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'Proportion alive'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-25-1} \end{center}

Suppose we now want to see if there is any difference between treatment groups.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf1 }\OperatorTok{=}\NormalTok{ sm.duration.SurvfuncRight(veteran.time[veteran.trt}\OperatorTok{==}\DecValTok{1}\NormalTok{], veteran.status[veteran.trt}\OperatorTok{==}\DecValTok{1}\NormalTok{], title}\OperatorTok{=}\StringTok{'Treatment 1'}\NormalTok{)}
\NormalTok{sf2 }\OperatorTok{=}\NormalTok{ sm.duration.SurvfuncRight(veteran.time[veteran.trt}\OperatorTok{==}\DecValTok{2}\NormalTok{], veteran.status[veteran.trt}\OperatorTok{==}\DecValTok{2}\NormalTok{], title}\OperatorTok{=}\StringTok{'Treatment 2'}\NormalTok{)}

\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<string>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.grid(}\VariableTok{True}\NormalTok{)}
\NormalTok{sf1.plot(ax)}\OperatorTok{;} \CommentTok{# Draw on previously defined axis}
\NormalTok{sf2.plot(ax)}\OperatorTok{;}

\NormalTok{plt.xlabel(}\StringTok{'Time'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'Proportion alive'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.legend(loc}\OperatorTok{=}\StringTok{'upper right'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-26-1} \end{center}

We could also perform a statistical test (the \emph{log-rank test}) to see
if there is a statistical difference between these two curves.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chisq, pval }\OperatorTok{=}\NormalTok{ sm.duration.survdiff(veteran.time, veteran.status, veteran.trt)}
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(pval,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.928
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reticulate}\OperatorTok{::}\KeywordTok{use_condaenv}\NormalTok{(}\StringTok{'ds'}\NormalTok{, }\DataTypeTok{required=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\hypertarget{machine-learning-using-python}{%
\chapter{Machine Learning using Python}\label{machine-learning-using-python}}

\hypertarget{scikit-learn}{%
\section{Scikit-learn}\label{scikit-learn}}

Scikit-learn (\texttt{sklearn}) is the main Python package for machine learning. It is a widely-used and well-regarded package. However, there are a couple of challenges to using it given the usual \texttt{pandas}-based data munging pipeline.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{sklearn} requires that all inputs be numeric, and in fact, \texttt{numpy} arrays.
\item
  \texttt{sklearn} requires that all categorical variables by replaced by 0/1 dummy variables
\item
  \texttt{sklearn} requires us to separate the predictors from the outcome. We need to have one \texttt{X} matrix for the predictors and one \texttt{y} vector for the outcome.
\end{enumerate}

The big issue, of course, is the first point. Given we used \texttt{pandas} precisely because we wanted to be able to keep heterogenous data. We have to be able to convert non-numeric data to numeric. \texttt{pandas} does help us out with this problem.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First of all, we know that all \texttt{pandas} Series and DataFrame objects can be converted to \texttt{numpy} arrays using the \texttt{values} or \texttt{to\_numpy} functions.
\item
  Second, we can easily extract a single variable from the data set using either the usual extracton methods or the
  \texttt{pop} function.
\item
  Third, \texttt{pandas} gives us a way to convert all categorical values to numeric dummy variables using the \texttt{get\_dummies} function. This is actually a more desirable solution than what you will see in cyberspace, which is to use the
  \texttt{OneHotEncoder} function from \texttt{sklearn}.

  \begin{itemize}
  \tightlist
  \item
    This is generally fine since many machine learning models look for interactions internally and don't need them to be overtly specified. The main exceptions to this are linear and logistic regression. For those, we can use the formula methods described in the Statistical Modeling module to generate the appropriately transformed design matrix.
  \item
    If the outcome variable is not numeric, we can \texttt{LabelEncoder} function from the \texttt{sklearn.preprocessing} submodule to convert it.
  \end{itemize}
\end{enumerate}

I just threw a bunch of jargon at you. Let's see what this means.

\hypertarget{transforming-the-outcometarget}{%
\subsection{Transforming the outcome/target}\label{transforming-the-outcometarget}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ sklearn}
\ImportTok{import}\NormalTok{ statsmodels.api }\ImportTok{as}\NormalTok{ sm}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}

\NormalTok{iris }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'iris'}\NormalTok{).data}
\NormalTok{iris.head()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species
0           5.1          3.5           1.4          0.2  setosa
1           4.9          3.0           1.4          0.2  setosa
2           4.7          3.2           1.3          0.2  setosa
3           4.6          3.1           1.5          0.2  setosa
4           5.0          3.6           1.4          0.2  setosa
\end{verbatim}

Let's hit the first issue first. We need to separate out the outcome (the variable we want to predict) from the predictors (in this case the sepal and petal measurements).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ iris[}\StringTok{'Species'}\NormalTok{]}
\NormalTok{X }\OperatorTok{=}\NormalTok{ iris.drop(}\StringTok{'Species'}\NormalTok{, axis }\OperatorTok{=} \DecValTok{1}\NormalTok{) }\CommentTok{# drops column, makes a copy}
\end{Highlighting}
\end{Shaded}

Another way to do this is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ iris.pop(}\StringTok{'Species'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you look at this, \texttt{iris} now only has 4 columns. So we could just use \texttt{iris} after the \texttt{pop} application, as the predictor set

We still have to update \texttt{y} to become numeric. This is where the \texttt{sklearn} functions start to be handy

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ LabelEncoder}
\NormalTok{le }\OperatorTok{=}\NormalTok{ LabelEncoder()}
\NormalTok{y }\OperatorTok{=}\NormalTok{ le.fit_transform(y)}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
\end{verbatim}

Let's talk about this code, since it's very typical of the way the \texttt{sklearn}
code works. First, we import a method (\texttt{LabelEncoder}) from the appropriate
\texttt{sklearn} module. The second line, \texttt{le\ =\ LabelEncoder()} works to ``turn on'' the
method. This is like taking a power tool off the shelf and plugging it in to a
socket. It's now ready to work. The third line does the actual work. The
\texttt{fit\_transform} function transforms the data you input into it based on the
method it is then attached to.

\begin{quote}
Let's make a quick analogy. You can plug in both a power washer and a
jackhammer to get them ready to go. You can then apply each of them to your
driveway. They ``transform'' the driveway in different ways depending on which
tool is used. The washer would ``transform'' the driveway by cleaning it, while
the jackhammer would transform the driveway by breaking it.
\end{quote}

There's an interesting invisible quirk to the code, though. The object \texttt{le} also got transformed during this
process. There were pieces added to it during the \texttt{fit\_transform} process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le }\OperatorTok{=}\NormalTok{ LabelEncoder()}
\NormalTok{d1 }\OperatorTok{=} \BuiltInTok{dir}\NormalTok{(le)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ le.fit_transform( pd.read_csv(}\StringTok{'data/iris.csv'}\NormalTok{)[}\StringTok{'species'}\NormalTok{])}
\NormalTok{d2 }\OperatorTok{=} \BuiltInTok{dir}\NormalTok{(le)}
\BuiltInTok{set}\NormalTok{(d2).difference(}\BuiltInTok{set}\NormalTok{(d1)) }\CommentTok{# set of things in d2 but not in d1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'classes_'}
\end{verbatim}

So we see that there is a new component added, called \texttt{classes\_}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le.classes_}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['setosa', 'versicolor', 'virginica'], dtype=object)
\end{verbatim}

So the original labels aren't destroyed; they are being stored. This can be useful.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le.inverse_transform([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['setosa', 'versicolor', 'versicolor', 'virginica', 'setosa'],
      dtype=object)
\end{verbatim}

So we can transform back from the numeric to the labels. Keep this in hand, since it will prove useful after
we have done some predictions using a ML model, which will give numeric predictions.

\hypertarget{transforming-the-predictors}{%
\subsection{Transforming the predictors}\label{transforming-the-predictors}}

Let's look at a second example. The \texttt{diamonds} dataset has several categorical variables that would need to be transformed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/diamonds.csv.gz'}\NormalTok{)}

\NormalTok{y }\OperatorTok{=}\NormalTok{ diamonds.pop(}\StringTok{'price'}\NormalTok{).values}
\NormalTok{X }\OperatorTok{=}\NormalTok{ pd.get_dummies(diamonds)}

\CommentTok{# Alternatively}
\CommentTok{# import patsy}
\CommentTok{# f = '~ np.log(carat) +  + clarity + depth + cut * color'}
\CommentTok{# X = patsy.dmatrix(f, data=diamonds)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 53940 entries, 0 to 53939
Data columns (total 26 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   carat          53940 non-null  float64
 1   depth          53940 non-null  float64
 2   table          53940 non-null  float64
 3   x              53940 non-null  float64
 4   y              53940 non-null  float64
 5   z              53940 non-null  float64
 6   cut_Fair       53940 non-null  uint8  
 7   cut_Good       53940 non-null  uint8  
 8   cut_Ideal      53940 non-null  uint8  
 9   cut_Premium    53940 non-null  uint8  
 10  cut_Very Good  53940 non-null  uint8  
 11  color_D        53940 non-null  uint8  
 12  color_E        53940 non-null  uint8  
 13  color_F        53940 non-null  uint8  
 14  color_G        53940 non-null  uint8  
 15  color_H        53940 non-null  uint8  
 16  color_I        53940 non-null  uint8  
 17  color_J        53940 non-null  uint8  
 18  clarity_I1     53940 non-null  uint8  
 19  clarity_IF     53940 non-null  uint8  
 20  clarity_SI1    53940 non-null  uint8  
 21  clarity_SI2    53940 non-null  uint8  
 22  clarity_VS1    53940 non-null  uint8  
 23  clarity_VS2    53940 non-null  uint8  
 24  clarity_VVS1   53940 non-null  uint8  
 25  clarity_VVS2   53940 non-null  uint8  
dtypes: float64(6), uint8(20)
memory usage: 3.5 MB
\end{verbatim}

So everything is now numeric!!. Let's take a peek inside.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X.columns}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Index(['carat', 'depth', 'table', 'x', 'y', 'z', 'cut_Fair', 'cut_Good',
       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_D', 'color_E',
       'color_F', 'color_G', 'color_H', 'color_I', 'color_J', 'clarity_I1',
       'clarity_IF', 'clarity_SI1', 'clarity_SI2', 'clarity_VS1',
       'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2'],
      dtype='object')
\end{verbatim}

So, it looks like the continuous variables remain intact, but the categorical variables got exploded out. Each
variable name has a level with it, which represents the particular level it is representing. Each of these
variables, called dummy variables, are numerical 0/1 variables. For example, \texttt{color\_F} is 1 for those diamonds which have color F, and 0 otherwise.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.crosstab(X[}\StringTok{'color_F'}\NormalTok{], diamonds[}\StringTok{'color'}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
color       D     E     F      G     H     I     J
color_F                                           
0        6775  9797     0  11292  8304  5422  2808
1           0     0  9542      0     0     0     0
\end{verbatim}

\hypertarget{supervised-learning}{%
\section{Supervised Learning}\label{supervised-learning}}

We will first look at supervised learning methods.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.26\columnwidth}\raggedright
ML method\strut
\end{minipage} & \begin{minipage}[b]{0.68\columnwidth}\raggedright
Code to call it\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Decision Tree\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.tree.DecisionTreeClassifier}, \texttt{sklearn.tree.DecisionTreeRegressor}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Random Forest\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.ensemble.RandomForestClassifier}, \texttt{sklearn.ensemble.RandomForestRegressor}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Linear Regression\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.linear\_model.LinearRegression}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Logistic Regression\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.linear\_model.LogisticRegression}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Support Vector Machines\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.svm.LinearSVC}, \texttt{sklearn.svm.LinearSVR}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

The general method that the code will follow is :

\begin{verbatim}
from sklearn.... import Machine
machine = Machine(*parameters*)
machine.fit(X, y)
\end{verbatim}

\hypertarget{a-quick-example}{%
\subsection{A quick example}\label{a-quick-example}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeRegressor}

\NormalTok{lm }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{dt }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor()}
\end{Highlighting}
\end{Shaded}

Lets manufacture some data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{200}\NormalTok{)}
\NormalTok{y }\OperatorTok{=} \DecValTok{2} \OperatorTok{+} \DecValTok{3}\OperatorTok{*}\NormalTok{x }\OperatorTok{-} \DecValTok{5}\OperatorTok{*}\NormalTok{(x}\OperatorTok{**}\DecValTok{2}\NormalTok{)}
\NormalTok{d }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{'x'}\NormalTok{: x\})}

\NormalTok{lm.fit(d,y)}\OperatorTok{;}
\NormalTok{dt.fit(d, y)}\OperatorTok{;}

\NormalTok{p1 }\OperatorTok{=}\NormalTok{ lm.predict(d)}
\NormalTok{p2 }\OperatorTok{=}\NormalTok{ dt.predict(d)}

\NormalTok{d[}\StringTok{'y'}\NormalTok{] }\OperatorTok{=}\NormalTok{ y}
\NormalTok{d[}\StringTok{'lm'}\NormalTok{] }\OperatorTok{=}\NormalTok{ p1}
\NormalTok{d[}\StringTok{'dt'}\NormalTok{] }\OperatorTok{=}\NormalTok{ p2}

\NormalTok{D }\OperatorTok{=}\NormalTok{ pd.melt(d, id_vars }\OperatorTok{=} \StringTok{'x'}\NormalTok{)}

\NormalTok{sns.relplot(data}\OperatorTok{=}\NormalTok{D, x }\OperatorTok{=} \StringTok{'x'}\NormalTok{, y }\OperatorTok{=} \StringTok{'value'}\NormalTok{, hue }\OperatorTok{=} \StringTok{'variable'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/05-python-learning-15-1} \end{center}

\hypertarget{a-data-analytic-example}{%
\subsection{A data analytic example}\label{a-data-analytic-example}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read_csv(}\StringTok{'data/diamonds.csv.gz'}\NormalTok{)}
\NormalTok{diamonds.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 53940 entries, 0 to 53939
Data columns (total 10 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   carat    53940 non-null  float64
 1   cut      53940 non-null  object 
 2   color    53940 non-null  object 
 3   clarity  53940 non-null  object 
 4   depth    53940 non-null  float64
 5   table    53940 non-null  float64
 6   price    53940 non-null  int64  
 7   x        53940 non-null  float64
 8   y        53940 non-null  float64
 9   z        53940 non-null  float64
dtypes: float64(6), int64(1), object(3)
memory usage: 4.1+ MB
\end{verbatim}

First, lets separate out the outcome (price) and the predictors

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ diamonds.pop(}\StringTok{'price'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For many machine learning problems, it is useful to scale the numeric predictors so that they have mean 0 and
variance 1. First we need to separate out the categorical and numeric variables

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ diamonds.select_dtypes(include }\OperatorTok{=} \StringTok{'number'}\NormalTok{)}
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ diamonds.select_dtypes(exclude }\OperatorTok{=} \StringTok{'number'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now let's scale the columns of \texttt{d1}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ scale}

\NormalTok{bl }\OperatorTok{=}\NormalTok{ scale(d1)}
\NormalTok{bl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[-1.19816781, -0.17409151, -1.09967199, -1.58783745, -1.53619556,
        -1.57112919],
       [-1.24036129, -1.36073849,  1.58552871, -1.64132529, -1.65877419,
        -1.74117497],
       [-1.19816781, -3.38501862,  3.37566251, -1.49869105, -1.45739502,
        -1.74117497],
       ...,
       [-0.20662095,  0.73334442,  1.13799526, -0.06343409, -0.04774083,
         0.03013526],
       [ 0.13092691, -0.52310533,  0.24292836,  0.37338325,  0.33750627,
         0.28520393],
       [-0.10113725,  0.31452784, -1.09967199,  0.08811478,  0.11861587,
         0.14349912]])
\end{verbatim}

Woops!! We get a \texttt{numpy} array, not a \texttt{DataFrame}!!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bl }\OperatorTok{=}\NormalTok{ pd.DataFrame(scale(d1))}
\NormalTok{bl.columns }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(d1.columns)}
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ bl}
\end{Highlighting}
\end{Shaded}

Now, let's recode the categorical variables into dummy variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ pd.get_dummies(d2)}
\end{Highlighting}
\end{Shaded}

and put them back together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{=}\NormalTok{ pd.concat([d1,d2], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next we need to split the data into a training set and a test set. Usually we do this as an 80/20 split.
The purpose of the test set is to see how well the model works on an ``external'' data set. We don't touch the
test set until we're done with all our model building in the training set. We usually do the split using
random numbers. We'll put 40,000 observations in the training set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(X.index)}
\NormalTok{np.random.shuffle(ind)}

\NormalTok{X_train, y_train }\OperatorTok{=}\NormalTok{ X.loc[ind[:}\DecValTok{40000}\NormalTok{],:], y[ind[:}\DecValTok{40000}\NormalTok{]]}
\NormalTok{X_test, y_test }\OperatorTok{=}\NormalTok{ X.loc[ind[}\DecValTok{40000}\NormalTok{:],:], y[ind[}\DecValTok{40000}\NormalTok{:]]}
\end{Highlighting}
\end{Shaded}

There is another way to do this

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model_selection }\ImportTok{import}\NormalTok{ train_test_split}

\NormalTok{X_train, X_test, y_train, y_test }\OperatorTok{=}\NormalTok{ train_test_split(X, y , test_size }\OperatorTok{=} \FloatTok{0.2}\NormalTok{, random_state}\OperatorTok{=} \DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we will fit our models to the training data. Let's use a decision tree model, a random forest model, and a linear regression.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeRegressor}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestRegressor}

\NormalTok{lm }\OperatorTok{=}\NormalTok{ LinearRegression()}\OperatorTok{;}
\NormalTok{dt }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor()}\OperatorTok{;}
\NormalTok{rf }\OperatorTok{=}\NormalTok{ RandomForestRegressor()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Now we will use our training data to fit the models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit(X_train, y_train)}\OperatorTok{;}
\NormalTok{dt.fit(X_train, y_train)}\OperatorTok{;}
\NormalTok{rf.fit(X_train, y_train)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We now need to see how well the model fit the data. We'll use the R2 statistic to be our metric of choice to evaluate the model fit.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{  r2_score}

\NormalTok{pd.DataFrame(\{}
  \StringTok{'Model'}\NormalTok{: [}\StringTok{'Linear regression'}\NormalTok{,}\StringTok{'Decision tree'}\NormalTok{,}\StringTok{'Random forest'}\NormalTok{],}
  \StringTok{'R2'}\NormalTok{: [r2_score(y_train, lm.predict(X_train)),}
\NormalTok{    r2_score(y_train, dt.predict(X_train)),}
\NormalTok{    r2_score(y_train, rf.predict(X_train))]}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
               Model        R2
0  Linear regression  0.920264
1      Decision tree  0.999997
2      Random forest  0.997332
\end{verbatim}

This is pretty amazing. However, we know that if we try and predict using the same data we used to train
the model, we get better than expected results. One way to get a better idea about the true performance of the
model when we will try it on external data is to do cross-validation.

\hypertarget{visualizing-a-decision-tree}{%
\subsection{Visualizing a decision tree}\label{visualizing-a-decision-tree}}

\textbf{scikit-learn} provides a decent way of visualizing a decision tree using a program called \emph{Graphviz}, which is a dedicated graph and network visualization program.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ graphviz}
\ImportTok{from}\NormalTok{ sklearn }\ImportTok{import}\NormalTok{ tree}

\NormalTok{dt }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor(max_depth}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{dt.fit(X_train, y_train)}\OperatorTok{;}
\NormalTok{dot_data }\OperatorTok{=}\NormalTok{ tree.export_graphviz(dt, out_file}\OperatorTok{=}\VariableTok{None}\NormalTok{, }
\NormalTok{                                feature_names }\OperatorTok{=}\NormalTok{ X_train.columns,}
\NormalTok{                                filled}\OperatorTok{=}\VariableTok{True}\NormalTok{, rounded}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{graph }\OperatorTok{=}\NormalTok{ graphviz.Source(dot_data)}\OperatorTok{;}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{graphs/image} \end{center}

\hypertarget{cross-validation}{%
\subsection{Cross-validation}\label{cross-validation}}

In cross-validation, we split the dataset up into 5 equal parts randomly. We then train the
model using 4 parts and predict the data on the 5th part. We do for all possible groups of 4 parts. We then
consider the overall performance of prediction.

\includegraphics{graphs/CV5.png}

There is nothing special about the 5 splits. If you use 5 splits, it is called 5-fold cross-validation (CV), if you use 10 splits, it is 10-fold CV. If you use all but one subject as training data, and that one subject as test data, and cycle through all the subjects, that is called leave-one-out CV (LOOCV). All these methods are widely used, but 5- and 10-fold CV are often used as a balance between effectiveness and computational efficiency.

\textbf{scikit-learn} makes this pretty easy, using the \texttt{cross\_val\_score} function.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model_selection }\ImportTok{import}\NormalTok{ cross_val_score}
\NormalTok{cv_score }\OperatorTok{=}\NormalTok{ cross_val_score(dt, X_train, y_train, cv}\OperatorTok{=}\DecValTok{5}\NormalTok{, scoring}\OperatorTok{=}\StringTok{'r2'}\NormalTok{)}
\SpecialStringTok{f"CV error = }\SpecialCharTok{\{np.}\BuiltInTok{round}\NormalTok{(np.mean(cv_score), }\DecValTok{3}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'CV error = 0.874'
\end{verbatim}

\hypertarget{improving-models-through-cross-validation}{%
\subsection{Improving models through cross-validation}\label{improving-models-through-cross-validation}}

The cross-validation error, as we've seen, gives us a better estimate of
how well our model predicts on new data. We can use this to tune models by tweaking their parameters to get models that reasonably will perform better.

Each model that we fit has a set of parameters that govern how it proceeds
to fit the data. These can bee seen using the \texttt{get\_params} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dt.get_params()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': None, 'splitter': 'best'}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le.get_params()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{}
\end{verbatim}

\begin{quote}
Linear regression is entirely determined by the functional form of
the prediction equation,i.e., the ``formula'' we use. It doesn't have any parameters to tune per se. Improving a linear regression involves playing
with the different predictors and transforming them to improve the predictions. This involve subjects called \emph{regression diagnostics} and
\emph{feature engineering} that we will leave to Google for now.
\end{quote}

We can tune different parameters for the decision tree to try and see if
some combination of parameters can improve predictions. One way to do this,
since we're using a computer, is a grid search. This means that we can set out sets of values of the parameters we want to tune, and the computer will go through every combination of those values to see how the model
performs, and will provide the ``best'' model.

We would specify the values as a dictionary to the function \texttt{GridSearchCV}, which would optimize based on the cross-validation error.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model_selection }\ImportTok{import}\NormalTok{ GridSearchCV}
\ImportTok{import}\NormalTok{ numpy.random }\ImportTok{as}\NormalTok{ rnd}
\NormalTok{rnd.RandomState(}\DecValTok{39358}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
RandomState(MT19937) at 0x12E702240
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{param_grid }\OperatorTok{=}\NormalTok{ \{}\StringTok{'max_depth'}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{], }\StringTok{'min_samples_leaf'}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{],}
  \StringTok{'max_features'}\NormalTok{ : [}\StringTok{'auto'}\NormalTok{,}\StringTok{'sqrt'}\NormalTok{]\}}

\NormalTok{clf }\OperatorTok{=}\NormalTok{ GridSearchCV(dt, param_grid, scoring }\OperatorTok{=} \StringTok{'r2'}\NormalTok{, cv }\OperatorTok{=} \DecValTok{5}\NormalTok{) }\CommentTok{# Tuning dt}
\NormalTok{clf.fit(X_train, y_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
GridSearchCV(cv=5, estimator=DecisionTreeRegressor(max_depth=3),
             param_grid={'max_depth': [1, 3, 5, 7, 10],
                         'max_features': ['auto', 'sqrt'],
                         'min_samples_leaf': [1, 5, 10, 20]},
             scoring='r2')
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf.best_estimator_}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(clf.best_score_)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9646124761424748
\end{verbatim}

So how does this do on the test set?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OperatorTok{=}\NormalTok{ clf.best_estimator_.predict(X_test)}
\NormalTok{r2_score(y_test, p)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9658307829343006
\end{verbatim}

So this predictor is doing slightly better on the test set than the training set. This is often an indicator that the model is overfitting on the data. This is probable here, given the extremely high R2 values for this model.

\hypertarget{feature-selection}{%
\subsection{Feature selection}\label{feature-selection}}

We can also use cross-validation to do recursive feature selection (or
backwards elimination), based on a predictive score. This is different
from usual stepwise selection methods which are based on a succession of
hypothesis tests.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.feature_selection }\ImportTok{import}\NormalTok{ RFECV}

\NormalTok{selector }\OperatorTok{=}\NormalTok{ RFECV(lm, cv }\OperatorTok{=} \DecValTok{5}\NormalTok{, scoring }\OperatorTok{=} \StringTok{'r2'}\NormalTok{)}
\NormalTok{selector }\OperatorTok{=}\NormalTok{ selector.fit(X_train, y_train)}
\NormalTok{selector.support_}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([ True, False, False,  True, False, False,  True, False,  True,
        True,  True,  True,  True,  True,  True, False,  True,  True,
        True,  True, False,  True,  True,  True,  True,  True])
\end{verbatim}

The support gives the set of predictors (True) that are finally selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X_train.columns[selector.support_]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Index(['carat', 'x', 'cut_Fair', 'cut_Ideal', 'cut_Premium', 'cut_Very Good',
       'color_D', 'color_E', 'color_F', 'color_G', 'color_I', 'color_J',
       'clarity_I1', 'clarity_IF', 'clarity_SI2', 'clarity_VS1', 'clarity_VS2',
       'clarity_VVS1', 'clarity_VVS2'],
      dtype='object')
\end{verbatim}

This is indicating that the best predictive model for the linear regression includes carat, cut, color and clarity, and width of the stone.

\hypertarget{logistic-regression}{%
\subsection{Logistic regression}\label{logistic-regression}}

We noted that logistic regression is available both through \textbf{statsmodels} and through \textbf{scikit-learn}. Let's now try to fit a
logistic regression model using \textbf{scikit-learn}. We will use the same
Titanic dataset we used earlier.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ statsmodels.api }\ImportTok{as}\NormalTok{ sm}
\ImportTok{import}\NormalTok{ statsmodels.formula.api }\ImportTok{as}\NormalTok{ smf}
\ImportTok{from}\NormalTok{ sklearn.linear_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\NormalTok{titanic }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'Titanic'}\NormalTok{,}\StringTok{'Stat2Data'}\NormalTok{).data.dropna()}
\NormalTok{titanic.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
Int64Index: 756 entries, 0 to 1312
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Name      756 non-null    object 
 1   PClass    756 non-null    object 
 2   Age       756 non-null    float64
 3   Sex       756 non-null    object 
 4   Survived  756 non-null    int64  
 5   SexCode   756 non-null    int64  
dtypes: float64(1), int64(2), object(3)
memory usage: 41.3+ KB
\end{verbatim}

We will model \texttt{Survived} on the age, sex and passenger class of passengers.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model_selection }\ImportTok{import}\NormalTok{ train_test_split}

\NormalTok{X }\OperatorTok{=}\NormalTok{ pd.get_dummies(titanic[[}\StringTok{'Age'}\NormalTok{,}\StringTok{'Sex'}\NormalTok{,}\StringTok{'PClass'}\NormalTok{]], drop_first}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ titanic.Survived}

\NormalTok{X_train, X_test, y_train, y_test }\OperatorTok{=}\NormalTok{ train_test_split(X, y , test_size }\OperatorTok{=} \FloatTok{0.2}\NormalTok{, random_state}\OperatorTok{=} \DecValTok{40}\NormalTok{) }\CommentTok{# 80/20 split}

\NormalTok{lrm }\OperatorTok{=}\NormalTok{ LogisticRegression()}
\NormalTok{lrm.fit(X_train, y_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
LogisticRegression()
\end{verbatim}

There are a few differences that are now evident between this model and
the model we fit using \textbf{statsmodels}. As a reminder, we fit this model again below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic1 }\OperatorTok{=}\NormalTok{ titanic.loc[X_train.index,:]}
\NormalTok{titanic2 }\OperatorTok{=}\NormalTok{ titanic.loc[X_test.index,:]}
\NormalTok{mod_logistic }\OperatorTok{=}\NormalTok{ smf.glm(}\StringTok{'Survived ~ Age + Sex + PClass'}\NormalTok{, data}\OperatorTok{=}\NormalTok{titanic1,}
\NormalTok{  family }\OperatorTok{=}\NormalTok{ sm.families.Binomial()).fit()}
\NormalTok{mod_logistic.summary()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'statsmodels.iolib.summary.Summary'>
"""
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               Survived   No. Observations:                  604
Model:                            GLM   Df Residuals:                      599
Model Family:                Binomial   Df Model:                            4
Link Function:                  logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -282.34
Date:                Fri, 07 Aug 2020   Deviance:                       564.68
Time:                        00:58:15   Pearson chi2:                     666.
No. Iterations:                     5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          z      P>|z|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         3.6795      0.440      8.362      0.000       2.817       4.542
Sex[T.male]      -2.5138      0.221    -11.353      0.000      -2.948      -2.080
PClass[T.2nd]    -1.2057      0.290     -4.155      0.000      -1.774      -0.637
PClass[T.3rd]    -2.5974      0.305     -8.528      0.000      -3.194      -2.000
Age              -0.0367      0.008     -4.385      0.000      -0.053      -0.020
=================================================================================
"""
\end{verbatim}

We can see the objects that are available to us from the two models using
\texttt{dir(lrm)} and \texttt{dir(mod\_logistic)}. We find that \texttt{lrm} does not give us
any parameter estimates, p-values or summary methods. It is much leaner, and, in line with other machine learning models, emphasizes predictions. So if you want to find associations between predictors and outcome, you will have to use the \textbf{statsmodels} version.

Let's compare the predictions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.clf()}
\NormalTok{p1 }\OperatorTok{=}\NormalTok{ lrm.predict_proba(X_test)[:,}\DecValTok{1}\NormalTok{]}
\NormalTok{p2 }\OperatorTok{=}\NormalTok{ mod_logistic.predict(titanic2)}

\NormalTok{plt.plot(p1, p2, }\StringTok{'.'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], }\StringTok{':'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.xlabel(}\StringTok{'scikit-learn'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'statsmodels'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.title(}\StringTok{'Predictions'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-40-1} \end{center}

First note that the prediction functions work a bit differently. For \texttt{lrm} we have to explicitly ask for the probability predictions, whereas those are automatically provided for \texttt{mod\_logistic}. We also find that the predictions aren't exactly the same. This is because \texttt{lrm}, by default, runs a penalized regression using the lasso criteria (L2 norm), rather than the non-penalized version that \texttt{mod\_logistic} runs. We can specify no penalty for \texttt{lrm} and can see much closer agreement between the two models.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lrm }\OperatorTok{=}\NormalTok{ LogisticRegression(penalty}\OperatorTok{=}\StringTok{'none'}\NormalTok{)}
\NormalTok{lrm.fit(X_train, y_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
LogisticRegression(penalty='none')
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{=}\NormalTok{ lrm.predict_proba(X_test)[:,}\DecValTok{1}\NormalTok{]}

\NormalTok{plt.clf()}
\NormalTok{plt.plot(p1, p2, }\StringTok{'.'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], }\StringTok{':'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.xlabel(}\StringTok{'scikit-learn'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{'statsmodels'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.title(}\StringTok{'Predictions'}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-41-1} \end{center}

\hypertarget{unsupervised-learning}{%
\section{Unsupervised learning}\label{unsupervised-learning}}

Unsupervised learning is a class of machine learning methods where we are just trying to identify patterns in the data without any labels. This is in contrast to \emph{supervised learning}, which are the modeling methods we have discussed above.

Most unsupervised learning methods fall broadly into a set of algorithms called \emph{cluster analysis}. \textbf{scikit-learn} provides several clustering algorithms.

\includegraphics{graphs/cluster_choice.png}

We will demonstrate the two more popular choices -- K-Means and Agglomerative clustering (also known as hierarchical clustering). We will use the classic Fisher's Iris data for this demonstration.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ statsmodels.api }\ImportTok{as}\NormalTok{ sm}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}

\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans, AgglomerativeClustering}

\NormalTok{iris }\OperatorTok{=}\NormalTok{ sm.datasets.get_rdataset(}\StringTok{'iris'}\NormalTok{).data}
\NormalTok{sns.relplot(data}\OperatorTok{=}\NormalTok{iris, x }\OperatorTok{=} \StringTok{'Sepal.Length'}\NormalTok{,y }\OperatorTok{=} \StringTok{'Sepal.Width'}\NormalTok{, hue }\OperatorTok{=} \StringTok{'Species'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

The K-Means algorithm takes a pre-specified number of clusters as input, and then tries to find contiguous regions of the data to parse into clusters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{km }\OperatorTok{=}\NormalTok{ KMeans(n_clusters }\OperatorTok{=} \DecValTok{3}\NormalTok{)}
\NormalTok{km.fit(iris[[}\StringTok{'Sepal.Length'}\NormalTok{,}\StringTok{'Sepal.Width'}\NormalTok{]])}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{km.labels_}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1,
       2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1,
       1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1,
       1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2], dtype=int32)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris[}\StringTok{'km_labels'}\NormalTok{] }\OperatorTok{=}\NormalTok{ km.labels_}
\NormalTok{iris[}\StringTok{'km_labels'}\NormalTok{] }\OperatorTok{=}\NormalTok{ iris.km_labels.astype(}\StringTok{'category'}\NormalTok{)}

\NormalTok{sns.relplot(data}\OperatorTok{=}\NormalTok{iris, x }\OperatorTok{=} \StringTok{'Sepal.Length'}\NormalTok{, y }\OperatorTok{=} \StringTok{'Sepal.Width'}\NormalTok{, }
\NormalTok{           hue }\OperatorTok{=} \StringTok{'km_labels'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

Agglomerative clustering takes a different approach. It starts by coalescing individual points successively, based on a distance metric and a principle for how to coalesce groups of points (called \emph{linkage}). The number of clusters can then be determined either visually or via different cutoffs.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hc }\OperatorTok{=}\NormalTok{ AgglomerativeClustering(distance_threshold}\OperatorTok{=}\DecValTok{0}\NormalTok{, n_clusters}\OperatorTok{=}\VariableTok{None}\NormalTok{, }
\NormalTok{                             linkage}\OperatorTok{=}\StringTok{'complete'}\NormalTok{)}

\NormalTok{hc.fit(iris[[}\StringTok{'Sepal.Length'}\NormalTok{,}\StringTok{'Sepal.Width'}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
AgglomerativeClustering(distance_threshold=0, linkage='complete',
                        n_clusters=None)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hc.linkage}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'complete'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.cluster.hierarchy }\ImportTok{import}\NormalTok{ dendrogram}

\CommentTok{## The following is from https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html}
\KeywordTok{def}\NormalTok{ plot_dendrogram(model, }\OperatorTok{**}\NormalTok{kwargs):}
    \CommentTok{# Create linkage matrix and then plot the dendrogram}

    \CommentTok{# create the counts of samples under each node}
\NormalTok{    counts }\OperatorTok{=}\NormalTok{ np.zeros(model.children_.shape[}\DecValTok{0}\NormalTok{])}
\NormalTok{    n_samples }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(model.labels_)}
    \ControlFlowTok{for}\NormalTok{ i, merge }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(model.children_):}
\NormalTok{        current_count }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{for}\NormalTok{ child_idx }\KeywordTok{in}\NormalTok{ merge:}
            \ControlFlowTok{if}\NormalTok{ child_idx }\OperatorTok{<}\NormalTok{ n_samples:}
\NormalTok{                current_count }\OperatorTok{+=} \DecValTok{1}  \CommentTok{# leaf node}
            \ControlFlowTok{else}\NormalTok{:}
\NormalTok{                current_count }\OperatorTok{+=}\NormalTok{ counts[child_idx }\OperatorTok{-}\NormalTok{ n_samples]}
\NormalTok{        counts[i] }\OperatorTok{=}\NormalTok{ current_count}

\NormalTok{    linkage_matrix }\OperatorTok{=}\NormalTok{ np.column_stack([model.children_, model.distances_,}
\NormalTok{                                      counts]).astype(}\BuiltInTok{float}\NormalTok{)}

    \CommentTok{# Plot the corresponding dendrogram}
\NormalTok{    dendrogram(linkage_matrix, }\OperatorTok{**}\NormalTok{kwargs)}

\NormalTok{plot_dendrogram(hc, truncate_mode}\OperatorTok{=}\StringTok{'level'}\NormalTok{, p}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Number of points in node (or index of point if no parenthesis)."}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-48-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hc }\OperatorTok{=}\NormalTok{ AgglomerativeClustering( n_clusters}\OperatorTok{=}\DecValTok{3}\NormalTok{,}
\NormalTok{                             linkage}\OperatorTok{=}\StringTok{'average'}\NormalTok{)}

\NormalTok{hc.fit(iris[[}\StringTok{'Sepal.Length'}\NormalTok{,}\StringTok{'Sepal.Width'}\NormalTok{]])}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hc.labels_}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1,
       2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1,
       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris[}\StringTok{'hc_labels'}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.Series(hc.labels_).astype(}\StringTok{'category'}\NormalTok{)}

\NormalTok{sns.relplot(data}\OperatorTok{=}\NormalTok{iris, x }\OperatorTok{=} \StringTok{'Sepal.Length'}\NormalTok{, y}\OperatorTok{=} \StringTok{'Sepal.Width'}\NormalTok{, }
\NormalTok{           hue }\OperatorTok{=} \StringTok{'hc_labels'}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
/Users/abhijit/opt/miniconda3/envs/ds/lib/python3.8/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(nrow, ncol, **kwargs)
\end{verbatim}

\begin{quote}
Play around with different linkage methods to see how these clusters change.
\end{quote}

\hypertarget{string-manipulation}{%
\chapter{String manipulation}\label{string-manipulation}}

String manipulation is one of Python's strong suites. It comes built in with methods for strings, and the \texttt{re} module (for \emph{regular expressions}) ups that power many fold.

Strings are objects that we typically see in quotes. We can also check if a variable is a string.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \StringTok{'Les Miserable'}

\BuiltInTok{type}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'str'>
\end{verbatim}

Strings are a little funny. They look like they are one thing, but they can act like lists. In some sense they
are really a container of characters. So we can have

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
13
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'Les '
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{3}\NormalTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
' Mi'
\end{verbatim}

The rules are basically the same as lists. To make this explicit, let's consider the word `bare'.
In terms of positions, we can write this out.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\endhead
index & 0 & 1 & 2 & 3\tabularnewline
string & b & a & r & e\tabularnewline
neg index & -4 & -3 & -2 & -1\tabularnewline
& & & &\tabularnewline
\bottomrule
\end{longtable}

We can also slices strings (and lists for that matter) in intervals. So, going back to \texttt{a},

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[::}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'LsMsrbe'
\end{verbatim}

slices every other character.

Strings come with several methods to manipulate them natively.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'White Knight'}\NormalTok{.capitalize()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'White knight'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{"It's just a flesh wound"}\NormalTok{.count(}\StringTok{'u'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'Almond'}\NormalTok{.endswith(}\StringTok{'nd'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
True
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'White Knight'}\NormalTok{.lower()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'white knight'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'White Knight'}\NormalTok{.upper()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'WHITE KNIGHT'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'flesh wound'}\NormalTok{.replace(}\StringTok{'flesh'}\NormalTok{,}\StringTok{'bullet'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'bullet wound'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{' This is my song   '}\NormalTok{.strip()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'This is my song'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'Hello, hello, hello'}\NormalTok{.split(}\StringTok{','}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
['Hello', ' hello', ' hello']
\end{verbatim}

One of the most powerful string methods is \texttt{join}. This allows us to take a list of characters, and then
put them together using a particular separator.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{' '}\NormalTok{.join([}\StringTok{'This'}\NormalTok{,}\StringTok{'is'}\NormalTok{,}\StringTok{'my'}\NormalTok{,}\StringTok{'song'}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'This is my song'
\end{verbatim}

Also recall that we are allowed ``string arithmetic''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'g'} \OperatorTok{+} \StringTok{'a'} \OperatorTok{+} \StringTok{'f'} \OperatorTok{+} \StringTok{'f'} \OperatorTok{+} \StringTok{'e'}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'gaffe'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{'a '}\OperatorTok{*}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'a a a a a '
\end{verbatim}

\hypertarget{string-formatting}{%
\subsection{String formatting}\label{string-formatting}}

In older code, you will see a formal format statement.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var }\OperatorTok{=} \StringTok{'horse'}
\NormalTok{var2 }\OperatorTok{=} \StringTok{'car'}

\NormalTok{s }\OperatorTok{=} \StringTok{'Get off my }\SpecialCharTok{\{\}}\StringTok{!'}

\NormalTok{s.}\BuiltInTok{format}\NormalTok{(var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'Get off my horse!'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s.}\BuiltInTok{format}\NormalTok{(var2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'Get off my car!'
\end{verbatim}

This is great for templates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{template_string }\OperatorTok{=} \StringTok{"""}
\SpecialCharTok{\{country\}}\StringTok{, our native village}
\StringTok{There was a }\SpecialCharTok{\{species\}}\StringTok{ tree.}
\StringTok{We used to sleep under it.}
\StringTok{"""}

\BuiltInTok{print}\NormalTok{(template_string.}\BuiltInTok{format}\NormalTok{(country}\OperatorTok{=}\StringTok{'India'}\NormalTok{, species }\OperatorTok{=} \StringTok{'banyan'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

India, our native village
There was a banyan tree.
We used to sleep under it.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(template_string.}\BuiltInTok{format}\NormalTok{(country }\OperatorTok{=} \StringTok{'Canada'}\NormalTok{, species }\OperatorTok{=} \StringTok{'maple'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Canada, our native village
There was a maple tree.
We used to sleep under it.
\end{verbatim}

In Python 3.6+, the concept of \texttt{f-strings} or formatted strings was introduced. They can be easier to read, faster and have better performance.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{country }\OperatorTok{=} \StringTok{'USA'}
\SpecialStringTok{f"This is my }\SpecialCharTok{\{}\NormalTok{country}\SpecialCharTok{\}}\SpecialStringTok{!"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'This is my USA!'
\end{verbatim}

\hypertarget{regular-expressions}{%
\section{Regular expressions}\label{regular-expressions}}

Regular expressions are amazingly powerful tools for string search and manipulation. They are available in pretty much every
computer language in some form or the other. I'll provide a short and far from comprehensive introduction here. The website \href{https://regex101.com}{regex101.com} is a really good resource to learn and check your regular expressions.

\hypertarget{pattern-matching}{%
\subsection{Pattern matching}\label{pattern-matching}}

\begin{longtable}[]{@{}ll@{}}
\toprule
Syntax & Description\tabularnewline
\midrule
\endhead
\texttt{.} & Matches any one character\tabularnewline
\texttt{\^{}} & Matches from the beginning of a string\tabularnewline
\texttt{\$} & Matches to the end of a string\tabularnewline
\texttt{*} & Matches 0 or more repetitions of the previous character\tabularnewline
\texttt{+} & Matches 1 or more repetitions of the previous character\tabularnewline
\texttt{?} & Matches 0 or 1 repetitions of the previous character\tabularnewline
\texttt{\{m\}} & Matches \texttt{m} repetitions of the previous character\tabularnewline
\texttt{\{m,n\}} & Matches any number from \texttt{m} to \texttt{n} of the previous character\tabularnewline
\texttt{\textbackslash{}} & Escape character\tabularnewline
\texttt{{[}\ {]}} & A set of characters (e.g.~\texttt{{[}A-Z{]}} will match any capital letter)\tabularnewline
\texttt{(\ )} & Matches the pattern exactly\tabularnewline
\texttt{\textbar{}} & OR\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{biopython}{%
\chapter{BioPython}\label{biopython}}

BioPython is a package aimed at bioinformatics work. As with many Python packages, it is opinionated towards the needs of the developers, so might not meet everyone's needs.

You can install BioPython using \texttt{conda\ install\ biopython}.

We'll do a short example

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ Bio.Seq }\ImportTok{import}\NormalTok{ Seq}

\CommentTok{#create a sequence object}
\NormalTok{my_seq }\OperatorTok{=}\NormalTok{ Seq(}\StringTok{"CATGTAGACTAG"}\NormalTok{)}

\CommentTok{#print out some details about it}
\BuiltInTok{print}\NormalTok{(}\StringTok{"seq }\SpecialCharTok{%s}\StringTok{ is }\SpecialCharTok{%i}\StringTok{ bases long"} \OperatorTok{%}\NormalTok{ (my_seq, }\BuiltInTok{len}\NormalTok{(my_seq)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
seq CATGTAGACTAG is 12 bases long
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"reverse complement is }\SpecialCharTok{%s}\StringTok{"} \OperatorTok{%}\NormalTok{ my_seq.reverse_complement())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
reverse complement is CTAGTCTACATG
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"protein translation is }\SpecialCharTok{%s}\StringTok{"} \OperatorTok{%}\NormalTok{ my_seq.translate())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
protein translation is HVD*
\end{verbatim}

BioPython has capabilities for querying databases like \texttt{Entrez}, read sequences, do alignments using FASTA, and the like.

\end{document}
